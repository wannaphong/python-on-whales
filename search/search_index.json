{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"A Docker client for Python, designed to be fun and intuitive! Works on Linux, macOS and Windows, for Python 3.7 and above. The docs can be found at this address: https://gabrieldemarmiesse.github.io/python-on-whales/ The GitHub repo can be found at this address: https://github.com/gabrieldemarmiesse/python-on-whales How to install? pip install python-on-whales Some cool examples Start by doing from python_on_whales import docker and then: docker run hello-world -> docker.run(\"hello-world\") docker pull ubuntu -> docker.pull(\"ubuntu\") docker build ./ -> docker.build(\"./\") docker compose up my_service -> docker.compose.up([\"my_service\"]) docker image ls -> docker.image.list() docker ps -> docker.ps() You get the idea \ud83d\ude42 it's the same as the CLI we all know and love. >>> from python_on_whales import docker >>> output = docker.run(\"hello-world\") >>> print(output) Hello from Docker! This message shows that your installation appears to be working correctly. ... >>> from python_on_whales import docker >>> print(docker.run(\"nvidia/cuda:11.0-base\", [\"nvidia-smi\"], gpus=\"all\")) +-----------------------------------------------------------------------------+ | NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla T4 On | 00000000:00:1E.0 Off | 0 | | N/A 34C P8 9W / 70W | 0MiB / 15109MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ >>> from python_on_whales import docker >>> my_docker_image = docker.pull(\"ubuntu:20.04\") 20.04: Pulling from library/ubuntu e6ca3592b144: Downloading [=============> ] 7.965MB/28.56MB 534a5505201d: Download complete 990916bd23bb: Download complete >>> print(my_docker_image.repo_tags) ['ubuntu:20.04'] >>> my_docker_image.remove() >>> from python_on_whales import docker >>> my_image = docker.build(\".\", tags=\"some_name\") # uses Buildx/buildkit by default [+] Building 1.6s (17/17) FINISHED => [internal] load build definition from Dockerfile 0.0s => => transferring dockerfile: 32B 0.0s => [internal] load .dockerignore 0.0s => => transferring context: 2B 0.0s => [internal] load metadata for docker.io/library/python:3.6 1.4s => [python_dependencies 1/5] FROM docker.io/library/python:3.6@sha256:29328c59adb9ee6acc7bea8eb86d0cb14033c85 0.0s => [internal] load build context 0.1s => => transferring context: 72.86kB 0.0s => CACHED [python_dependencies 2/5] RUN pip install typeguard pydantic requests tqdm 0.0s => CACHED [python_dependencies 3/5] COPY tests/test-requirements.txt /tmp/ 0.0s => CACHED [python_dependencies 4/5] COPY requirements.txt /tmp/ 0.0s => CACHED [python_dependencies 5/5] RUN pip install -r /tmp/test-requirements.txt -r /tmp/requirements.txt 0.0s => CACHED [tests_ubuntu_install_without_buildx 1/7] RUN apt-get update && apt-get install -y apt-tr 0.0s => CACHED [tests_ubuntu_install_without_buildx 2/7] RUN curl -fsSL https://download.docker.com/linux/ubuntu/g 0.0s => CACHED [tests_ubuntu_install_without_buildx 3/7] RUN add-apt-repository \"deb [arch=amd64] https://downl 0.0s => CACHED [tests_ubuntu_install_without_buildx 4/7] RUN apt-get update && apt-get install -y docker-ce- 0.0s => CACHED [tests_ubuntu_install_without_buildx 5/7] WORKDIR /python-on-whales 0.0s => CACHED [tests_ubuntu_install_without_buildx 6/7] COPY . . 0.0s => CACHED [tests_ubuntu_install_without_buildx 7/7] RUN pip install -e . 0.0s => exporting to image 0.1s => => exporting layers 0.0s => => writing image sha256:e1c2382d515b097ebdac4ed189012ca3b34ab6be65ba0c650421ebcac8b70a4d 0.0s => => naming to docker.io/library/some_image_name Main features 1 to 1 mapping between the CLI interface and the Python API. No need to look in the docs what is the name of the function/argument you need. Support for the latest Docker features: Docker buildx/buildkit , docker run --gpu=all ... Support for Docker stack, services and Swarm (same API as the command line). Progress bars and progressive outputs when pulling, pushing, loading, building... Support for some other CLI commands that are not in Docker-py : docker cp , docker run --cpus ... and more. Nice SSH support for remote daemons. Docker object as Python objects: Container, Images, Volumes, Services... and their attributes are updated in real-time! Each Docker object can be used as a context manager. When getting out of the context, the Docker object is removed automatically, even if an exception occurs. A fully typed API (Mypy and IDE-friendly) compatible with pathlib and os.path All Docker objects and the Docker client are safe to use with multithreading and multiprocessing. Display the commands called and the environment variables used by setting the environment variable PYTHON_ON_WHALES_DEBUG=1 . Why another project? Why not build on Docker-py? In a sense this project is built on top of Docker-py because the implementation, the organisation and the API is inspired from the project, but the codebases could not be the same. Two major differences do not permit that: 1) The API is quite different. The aim of Python on Whales is to provide a 1-to-1 mapping between the Docker command line and Python, so that users don't even have to open the docs to do write code. 2) While Docker-py is a complete re-implementation of the Docker client binary (written in Go), Python on whales sits on top of the Docker client binary, which makes implementing new features much easier and safer. For example, it's unlikely that docker-py supports Buildx/buildkit anytime soon because rewriting a large Go codebase in Python is hard work. Should I use Docker-py or Python on Whales? Well, it's written in each project's description! Docker-py: A Python library for the Docker Engine API Python on whales: An awesome Python wrapper for an awesome Docker CLI If you need to talk to the Docker engine directly, you need to do low level operations, use docker-py. Some good example would be writing the code to control docker from an IDE, or if the speed of Docker calls is very important. If you don't want to depend on the Docker CLI binary (~50MB), use docker-py. If you wanted to call the docker command line from Python, do high level operations, use Python on Whales. For example if you want to write your CI logic in Python rather than in bash (a very good choice \ud83d\ude09). Some commands are only available in Python on whales too: docker.buildx.build(...) , docker.stack.deploy(...) ... Use the right tool for the right job \ud83d\ude42 Where is the project now? Where is it going? sub-command Functions implemented Progress buildx 10/11 compose 18/23 config 4/4 container 22/24 context 4/6 image 12/13 manifest 0/4 network 7/7 node 7/7 plugins 10/10 secret 4/4 service 7/9 stack 5/5 swarm 8/8 system 3/4 trust 0/3 volume 7/7 Take those numbers with a grain of salt. The functions don't all need the same amount of work to be implemented. Contributing Any and all PRs are welcome. Please see this documentation . What about the license? It's a MIT license, so quite permissive. The license can be found in the git repository .","title":"Home"},{"location":"#how-to-install","text":"pip install python-on-whales","title":"How to install?"},{"location":"#some-cool-examples","text":"Start by doing from python_on_whales import docker and then: docker run hello-world -> docker.run(\"hello-world\") docker pull ubuntu -> docker.pull(\"ubuntu\") docker build ./ -> docker.build(\"./\") docker compose up my_service -> docker.compose.up([\"my_service\"]) docker image ls -> docker.image.list() docker ps -> docker.ps() You get the idea \ud83d\ude42 it's the same as the CLI we all know and love. >>> from python_on_whales import docker >>> output = docker.run(\"hello-world\") >>> print(output) Hello from Docker! This message shows that your installation appears to be working correctly. ... >>> from python_on_whales import docker >>> print(docker.run(\"nvidia/cuda:11.0-base\", [\"nvidia-smi\"], gpus=\"all\")) +-----------------------------------------------------------------------------+ | NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla T4 On | 00000000:00:1E.0 Off | 0 | | N/A 34C P8 9W / 70W | 0MiB / 15109MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ >>> from python_on_whales import docker >>> my_docker_image = docker.pull(\"ubuntu:20.04\") 20.04: Pulling from library/ubuntu e6ca3592b144: Downloading [=============> ] 7.965MB/28.56MB 534a5505201d: Download complete 990916bd23bb: Download complete >>> print(my_docker_image.repo_tags) ['ubuntu:20.04'] >>> my_docker_image.remove() >>> from python_on_whales import docker >>> my_image = docker.build(\".\", tags=\"some_name\") # uses Buildx/buildkit by default [+] Building 1.6s (17/17) FINISHED => [internal] load build definition from Dockerfile 0.0s => => transferring dockerfile: 32B 0.0s => [internal] load .dockerignore 0.0s => => transferring context: 2B 0.0s => [internal] load metadata for docker.io/library/python:3.6 1.4s => [python_dependencies 1/5] FROM docker.io/library/python:3.6@sha256:29328c59adb9ee6acc7bea8eb86d0cb14033c85 0.0s => [internal] load build context 0.1s => => transferring context: 72.86kB 0.0s => CACHED [python_dependencies 2/5] RUN pip install typeguard pydantic requests tqdm 0.0s => CACHED [python_dependencies 3/5] COPY tests/test-requirements.txt /tmp/ 0.0s => CACHED [python_dependencies 4/5] COPY requirements.txt /tmp/ 0.0s => CACHED [python_dependencies 5/5] RUN pip install -r /tmp/test-requirements.txt -r /tmp/requirements.txt 0.0s => CACHED [tests_ubuntu_install_without_buildx 1/7] RUN apt-get update && apt-get install -y apt-tr 0.0s => CACHED [tests_ubuntu_install_without_buildx 2/7] RUN curl -fsSL https://download.docker.com/linux/ubuntu/g 0.0s => CACHED [tests_ubuntu_install_without_buildx 3/7] RUN add-apt-repository \"deb [arch=amd64] https://downl 0.0s => CACHED [tests_ubuntu_install_without_buildx 4/7] RUN apt-get update && apt-get install -y docker-ce- 0.0s => CACHED [tests_ubuntu_install_without_buildx 5/7] WORKDIR /python-on-whales 0.0s => CACHED [tests_ubuntu_install_without_buildx 6/7] COPY . . 0.0s => CACHED [tests_ubuntu_install_without_buildx 7/7] RUN pip install -e . 0.0s => exporting to image 0.1s => => exporting layers 0.0s => => writing image sha256:e1c2382d515b097ebdac4ed189012ca3b34ab6be65ba0c650421ebcac8b70a4d 0.0s => => naming to docker.io/library/some_image_name","title":"Some cool examples"},{"location":"#main-features","text":"1 to 1 mapping between the CLI interface and the Python API. No need to look in the docs what is the name of the function/argument you need. Support for the latest Docker features: Docker buildx/buildkit , docker run --gpu=all ... Support for Docker stack, services and Swarm (same API as the command line). Progress bars and progressive outputs when pulling, pushing, loading, building... Support for some other CLI commands that are not in Docker-py : docker cp , docker run --cpus ... and more. Nice SSH support for remote daemons. Docker object as Python objects: Container, Images, Volumes, Services... and their attributes are updated in real-time! Each Docker object can be used as a context manager. When getting out of the context, the Docker object is removed automatically, even if an exception occurs. A fully typed API (Mypy and IDE-friendly) compatible with pathlib and os.path All Docker objects and the Docker client are safe to use with multithreading and multiprocessing. Display the commands called and the environment variables used by setting the environment variable PYTHON_ON_WHALES_DEBUG=1 .","title":"Main features"},{"location":"#why-another-project-why-not-build-on-docker-py","text":"In a sense this project is built on top of Docker-py because the implementation, the organisation and the API is inspired from the project, but the codebases could not be the same. Two major differences do not permit that: 1) The API is quite different. The aim of Python on Whales is to provide a 1-to-1 mapping between the Docker command line and Python, so that users don't even have to open the docs to do write code. 2) While Docker-py is a complete re-implementation of the Docker client binary (written in Go), Python on whales sits on top of the Docker client binary, which makes implementing new features much easier and safer. For example, it's unlikely that docker-py supports Buildx/buildkit anytime soon because rewriting a large Go codebase in Python is hard work.","title":"Why another project? Why not build on Docker-py?"},{"location":"#should-i-use-docker-py-or-python-on-whales","text":"Well, it's written in each project's description! Docker-py: A Python library for the Docker Engine API Python on whales: An awesome Python wrapper for an awesome Docker CLI If you need to talk to the Docker engine directly, you need to do low level operations, use docker-py. Some good example would be writing the code to control docker from an IDE, or if the speed of Docker calls is very important. If you don't want to depend on the Docker CLI binary (~50MB), use docker-py. If you wanted to call the docker command line from Python, do high level operations, use Python on Whales. For example if you want to write your CI logic in Python rather than in bash (a very good choice \ud83d\ude09). Some commands are only available in Python on whales too: docker.buildx.build(...) , docker.stack.deploy(...) ... Use the right tool for the right job \ud83d\ude42","title":"Should I use Docker-py or Python on Whales?"},{"location":"#where-is-the-project-now-where-is-it-going","text":"sub-command Functions implemented Progress buildx 10/11 compose 18/23 config 4/4 container 22/24 context 4/6 image 12/13 manifest 0/4 network 7/7 node 7/7 plugins 10/10 secret 4/4 service 7/9 stack 5/5 swarm 8/8 system 3/4 trust 0/3 volume 7/7 Take those numbers with a grain of salt. The functions don't all need the same amount of work to be implemented.","title":"Where is the project now? Where is it going?"},{"location":"#contributing","text":"Any and all PRs are welcome. Please see this documentation .","title":"Contributing"},{"location":"#what-about-the-license","text":"It's a MIT license, so quite permissive. The license can be found in the git repository .","title":"What about the license?"},{"location":"docker_client/","text":"The Docker client object DockerClient python_on_whales.DockerClient( config=None, context=None, debug=None, host=None, log_level=None, tls=None, tlscacert=None, tlscert=None, tlskey=None, tlsverify=None, client_config=None, compose_files=[], compose_profiles=[], compose_env_file=None, compose_project_name=None, ) Creates a Docker client Note that from python_on_whales import docker print(docker.run(\"hello-world\")) is equivalent to from python_on_whales import DockerClient docker = DockerClient() print(docker.run(\"hello-world\") Arguments config Optional[Union[str, pathlib.Path]] : Location of client config files (default \"~/.docker\") context Optional[str] : Name of the context to use to connect to the daemon (overrides DOCKER_HOST env var and default context set with \"docker context use\") debug Optional[bool] : Enable debug mode host Optional[str] : Daemon socket(s) to connect to log_level Optional[str] : Set the logging level (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\") (default \"info\") tls Optional[bool] : Use TLS; implied by tlsverify tlscacert Optional[Union[str, pathlib.Path]] : Trust certs signed only by this CA (default \"~/.docker/ca.pem\") compose_files List[Union[str, pathlib.Path]] : Docker compose yaml file compose_profiles List[str] : List of compose profiles to use. Take a look at the documentation for profiles . compose_env_file Optional[Union[str, pathlib.Path]] : .env file containing the environments variables to inject into the compose project. By default, it uses ./.env . compose_project_name Optional[str] : The name of the compose project. It will be prefixed to networks, volumes and containers created by compose. login docker.login(server=None, username=None, password=None) Log in to a Docker registry. If no server is specified, the default is defined by the daemon. Arguments server Optional[str] : The server to log into. For example, with a self-hosted registry it might be something like server=\"192.168.0.10:5000\" username Optional[str] : The username password Optional[str] : The password login_ecr docker.login_ecr(aws_access_key_id=None, aws_secret_access_key=None, region_name=None) Login to the aws ECR registry. Credentials are taken from the environment variables as defined in the aws docs . If you don't have a profile or your environment variables configured, you can also use the function arguments aws_access_key_id , aws_secret_access_key , region_name . Behind the scenes, those arguments are passed directly to botocore.session.get_session().create_client(...) You need botocore to run this function. Use pip install botocore to install it. logout docker.logout(server=None) Logout from a Docker registry Arguments server Optional[str] : The server to logout from. For example, with a self-hosted registry it might be something like server=\"192.168.0.10:5000\" version docker.version() Not yet implemented get_docker_client_binary_path python_on_whales.get_docker_client_binary_path() Return the path of the docker client binary file. If None is returned, the docker client binary is not available and must be downloaded. Returns Optional[Path] , The path of the docker client binary file. Note that if you use python-on-whales normally, the docker client binary is downloaded automatically if needed. So you only need this function if you want to bypass the automatic download process. Sub-commands docker.buildx docker.compose docker.config docker.container docker.context docker.image docker.manifest docker.network docker.node docker.secret docker.service docker.stack docker.swarm docker.system docker.trust docker.volume Other commands They're actually aliases docker.build docker.commit docker.copy docker.create docker.diff docker.execute docker.export docker.images docker.import_ docker.info docker.kill docker.load docker.logs docker.pause docker.ps docker.pull docker.push docker.rename docker.restart docker.remove docker.run docker.save docker.start docker.stats docker.stop docker.tag docker.top docker.unpause docker.update docker.wait About multithreading and multiprocessing Behind the scenes, Python on whales calls the Docker command line interface with subprocess. The Python on whales client does not store any intermediate state so it's safe to use with multithreading. The Docker objects store some intermediate states (the attributes that you would normally get with docker ... inspect but no logic in the codebase depends on those attributes. They're just here so that users can look at them. So you can share them between process/threads and pickle containers, images, networks... The Docker daemon works with its own objects internally and handles concurrent and conflicting requests. For example, if you create two containers with the same name from different threads, only one will succeed. If you pull the same docker image from multiple processes/threads, the Docker daemon will only pull the image and layers once. Just be careful with some scenario similar to this one Thread 1: my_container = docker.run(..., detach=True) ... # my_container finishes ... Thread 2: docker.container.prune() ... Thread 1: docker.logs(my_container) # will fail because the container was removed by thread 2 In the end, unless you use this type of logic in your code, Python-on-whales is safe to use with multithreading and multiprocessing. The Docker CLI Python-on-whales needs the Docker CLI to work (unlike docker-py). Most of the time, users already have the CLI installed on their machines. It's possible to verify that the CLI is there by doing docker --help in the command line. Sometimes, the CLI might not be available on the system, it can happen if you want to control Docker from within a container with -v /var/run/docker.sock:/var/run/docker.sock , or if you want to connect to a remote daemon with the host argument. In this case, when using python-on-whales, the CLI will be downloaded automatically (it's a single binary), and will be put in pathlib.Path.home() / \".cache/python-on-whales/docker\" Since it's not in the PATH and was not downloaded with the package manager, it's only seen and used by python-on-whales. If you want to trigger the download manually (to avoid downloading the CLI at runtime), you can run from your shell: python-on-whales download-cli","title":"Docker client"},{"location":"docker_client/#the-docker-client-object","text":"","title":"The Docker client object"},{"location":"docker_client/#dockerclient","text":"python_on_whales.DockerClient( config=None, context=None, debug=None, host=None, log_level=None, tls=None, tlscacert=None, tlscert=None, tlskey=None, tlsverify=None, client_config=None, compose_files=[], compose_profiles=[], compose_env_file=None, compose_project_name=None, ) Creates a Docker client Note that from python_on_whales import docker print(docker.run(\"hello-world\")) is equivalent to from python_on_whales import DockerClient docker = DockerClient() print(docker.run(\"hello-world\") Arguments config Optional[Union[str, pathlib.Path]] : Location of client config files (default \"~/.docker\") context Optional[str] : Name of the context to use to connect to the daemon (overrides DOCKER_HOST env var and default context set with \"docker context use\") debug Optional[bool] : Enable debug mode host Optional[str] : Daemon socket(s) to connect to log_level Optional[str] : Set the logging level (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\") (default \"info\") tls Optional[bool] : Use TLS; implied by tlsverify tlscacert Optional[Union[str, pathlib.Path]] : Trust certs signed only by this CA (default \"~/.docker/ca.pem\") compose_files List[Union[str, pathlib.Path]] : Docker compose yaml file compose_profiles List[str] : List of compose profiles to use. Take a look at the documentation for profiles . compose_env_file Optional[Union[str, pathlib.Path]] : .env file containing the environments variables to inject into the compose project. By default, it uses ./.env . compose_project_name Optional[str] : The name of the compose project. It will be prefixed to networks, volumes and containers created by compose.","title":"DockerClient"},{"location":"docker_client/#login","text":"docker.login(server=None, username=None, password=None) Log in to a Docker registry. If no server is specified, the default is defined by the daemon. Arguments server Optional[str] : The server to log into. For example, with a self-hosted registry it might be something like server=\"192.168.0.10:5000\" username Optional[str] : The username password Optional[str] : The password","title":"login"},{"location":"docker_client/#login_ecr","text":"docker.login_ecr(aws_access_key_id=None, aws_secret_access_key=None, region_name=None) Login to the aws ECR registry. Credentials are taken from the environment variables as defined in the aws docs . If you don't have a profile or your environment variables configured, you can also use the function arguments aws_access_key_id , aws_secret_access_key , region_name . Behind the scenes, those arguments are passed directly to botocore.session.get_session().create_client(...) You need botocore to run this function. Use pip install botocore to install it.","title":"login_ecr"},{"location":"docker_client/#logout","text":"docker.logout(server=None) Logout from a Docker registry Arguments server Optional[str] : The server to logout from. For example, with a self-hosted registry it might be something like server=\"192.168.0.10:5000\"","title":"logout"},{"location":"docker_client/#version","text":"docker.version() Not yet implemented","title":"version"},{"location":"docker_client/#get_docker_client_binary_path","text":"python_on_whales.get_docker_client_binary_path() Return the path of the docker client binary file. If None is returned, the docker client binary is not available and must be downloaded. Returns Optional[Path] , The path of the docker client binary file. Note that if you use python-on-whales normally, the docker client binary is downloaded automatically if needed. So you only need this function if you want to bypass the automatic download process.","title":"get_docker_client_binary_path"},{"location":"docker_client/#sub-commands","text":"docker.buildx docker.compose docker.config docker.container docker.context docker.image docker.manifest docker.network docker.node docker.secret docker.service docker.stack docker.swarm docker.system docker.trust docker.volume","title":"Sub-commands"},{"location":"docker_client/#other-commands","text":"They're actually aliases docker.build docker.commit docker.copy docker.create docker.diff docker.execute docker.export docker.images docker.import_ docker.info docker.kill docker.load docker.logs docker.pause docker.ps docker.pull docker.push docker.rename docker.restart docker.remove docker.run docker.save docker.start docker.stats docker.stop docker.tag docker.top docker.unpause docker.update docker.wait","title":"Other commands"},{"location":"docker_client/#about-multithreading-and-multiprocessing","text":"Behind the scenes, Python on whales calls the Docker command line interface with subprocess. The Python on whales client does not store any intermediate state so it's safe to use with multithreading. The Docker objects store some intermediate states (the attributes that you would normally get with docker ... inspect but no logic in the codebase depends on those attributes. They're just here so that users can look at them. So you can share them between process/threads and pickle containers, images, networks... The Docker daemon works with its own objects internally and handles concurrent and conflicting requests. For example, if you create two containers with the same name from different threads, only one will succeed. If you pull the same docker image from multiple processes/threads, the Docker daemon will only pull the image and layers once. Just be careful with some scenario similar to this one Thread 1: my_container = docker.run(..., detach=True) ... # my_container finishes ... Thread 2: docker.container.prune() ... Thread 1: docker.logs(my_container) # will fail because the container was removed by thread 2 In the end, unless you use this type of logic in your code, Python-on-whales is safe to use with multithreading and multiprocessing.","title":"About multithreading and multiprocessing"},{"location":"docker_client/#the-docker-cli","text":"Python-on-whales needs the Docker CLI to work (unlike docker-py). Most of the time, users already have the CLI installed on their machines. It's possible to verify that the CLI is there by doing docker --help in the command line. Sometimes, the CLI might not be available on the system, it can happen if you want to control Docker from within a container with -v /var/run/docker.sock:/var/run/docker.sock , or if you want to connect to a remote daemon with the host argument. In this case, when using python-on-whales, the CLI will be downloaded automatically (it's a single binary), and will be put in pathlib.Path.home() / \".cache/python-on-whales/docker\" Since it's not in the PATH and was not downloaded with the package manager, it's only seen and used by python-on-whales. If you want to trigger the download manually (to avoid downloading the CLI at runtime), you can run from your shell: python-on-whales download-cli","title":"The Docker CLI"},{"location":"docker_objects/builders/","text":"Docker builders The Buildx builders objects. Don't use the constructor directly. Instead use from python_on_whales import docker my_builder = docker.buildx.inspect(\"my-builder\") # or my_builder = docker.buildx.create() For type hints, use this from python_on_whales import Builder Attributes It attributes are the same that you get with the command line: docker buildx inspect ... Only a few are available at the moment In [1]: from python_on_whales import docker In [2]: my_builder = docker.buildx.create() In [4]: def super_print(obj): ...: print(f\"type={type(obj)}, value={obj}\") ...: In [4]: super_print(builder.name) type = <class 'str'>, value = objective_nash In [5]: super_print(builder.driver) type = <class 'str'>, value = docker-container Methods reload Builder.reload() remove Builder.remove() Removes this builder. After this operation the builder cannot be used anymore. If you use the builder as a context manager, it will call this function when you exit the context manager. from python_on_whales import docker buildx_builder = docker.buildx.create(use=True) with buildx_builder: docker.build(\".\") # now the variable buildx_builder is not usable since we're out of the context manager. # the .remove() method was called behind the scenes # since it was the current builder, 'default' is now the current builder.","title":"Builders"},{"location":"docker_objects/builders/#docker-builders","text":"The Buildx builders objects. Don't use the constructor directly. Instead use from python_on_whales import docker my_builder = docker.buildx.inspect(\"my-builder\") # or my_builder = docker.buildx.create() For type hints, use this from python_on_whales import Builder","title":"Docker builders"},{"location":"docker_objects/builders/#attributes","text":"It attributes are the same that you get with the command line: docker buildx inspect ... Only a few are available at the moment In [1]: from python_on_whales import docker In [2]: my_builder = docker.buildx.create() In [4]: def super_print(obj): ...: print(f\"type={type(obj)}, value={obj}\") ...: In [4]: super_print(builder.name) type = <class 'str'>, value = objective_nash In [5]: super_print(builder.driver) type = <class 'str'>, value = docker-container","title":"Attributes"},{"location":"docker_objects/builders/#methods","text":"","title":"Methods"},{"location":"docker_objects/builders/#reload","text":"Builder.reload()","title":"reload"},{"location":"docker_objects/builders/#remove","text":"Builder.remove() Removes this builder. After this operation the builder cannot be used anymore. If you use the builder as a context manager, it will call this function when you exit the context manager. from python_on_whales import docker buildx_builder = docker.buildx.create(use=True) with buildx_builder: docker.build(\".\") # now the variable buildx_builder is not usable since we're out of the context manager. # the .remove() method was called behind the scenes # since it was the current builder, 'default' is now the current builder.","title":"remove"},{"location":"docker_objects/configs/","text":"Docker configs Configs objects present in Swarm mode Don't use the constructor directly. Instead use from python_on_whales import docker my_config = docker.config.inspect(\"my-config-name\") # or my_config = docker.config.create(\"my_config_name\", \"my_config_file\") For type hints, use this from python_on_whales import Config def print_config_labels(config: Config): print(config.spec.labels) Attributes It attributes are the same that you get with the command line: docker config inspect ... To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: config = docker.config.create(\"my_config\", \"./config_file.cfg\", labels=dict(hello=\"world\")) In [3]: def super_print(obj): ...: print(f\"type={type(obj)}, value={obj}\") ...: In [4]: super_print(config.id) type = <class 'str'>, value = xldtm2anfj7takxrbzss1qj1j In [5]: super_print(config.version.index) type = <class 'int'>, value = 11 In [6]: super_print(config.created_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:02.130694+00:00 In [7]: super_print(config.updated_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:02.130694+00:00 In [8]: super_print(config.spec.name) type = <class 'str'>, value = my_config In [9]: super_print(config.spec.labels) type = <class 'dict'>, value = {'hello': 'world'} In [10]: super_print(config.spec.data) type = <class 'str'>, value = SGVsbG8gd29ybGQh In [11]: super_print(config.spec.templating) type = <class 'NoneType'>, value = None Methods reload Config.reload() remove Config.remove() Remove this config. Note that you can also use a python_on_whales.Config as a context manager to ensure it's removed even if an exception occurs.","title":"Configs"},{"location":"docker_objects/configs/#docker-configs","text":"Configs objects present in Swarm mode Don't use the constructor directly. Instead use from python_on_whales import docker my_config = docker.config.inspect(\"my-config-name\") # or my_config = docker.config.create(\"my_config_name\", \"my_config_file\") For type hints, use this from python_on_whales import Config def print_config_labels(config: Config): print(config.spec.labels)","title":"Docker configs"},{"location":"docker_objects/configs/#attributes","text":"It attributes are the same that you get with the command line: docker config inspect ... To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: config = docker.config.create(\"my_config\", \"./config_file.cfg\", labels=dict(hello=\"world\")) In [3]: def super_print(obj): ...: print(f\"type={type(obj)}, value={obj}\") ...: In [4]: super_print(config.id) type = <class 'str'>, value = xldtm2anfj7takxrbzss1qj1j In [5]: super_print(config.version.index) type = <class 'int'>, value = 11 In [6]: super_print(config.created_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:02.130694+00:00 In [7]: super_print(config.updated_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:02.130694+00:00 In [8]: super_print(config.spec.name) type = <class 'str'>, value = my_config In [9]: super_print(config.spec.labels) type = <class 'dict'>, value = {'hello': 'world'} In [10]: super_print(config.spec.data) type = <class 'str'>, value = SGVsbG8gd29ybGQh In [11]: super_print(config.spec.templating) type = <class 'NoneType'>, value = None","title":"Attributes"},{"location":"docker_objects/configs/#methods","text":"","title":"Methods"},{"location":"docker_objects/configs/#reload","text":"Config.reload()","title":"reload"},{"location":"docker_objects/configs/#remove","text":"Config.remove() Remove this config. Note that you can also use a python_on_whales.Config as a context manager to ensure it's removed even if an exception occurs.","title":"remove"},{"location":"docker_objects/containers/","text":"Docker containers Don't use the constructor directly. Instead use from python_on_whales import docker my_container = docker.container.inspect(\"my-container-name\") # for example: if my_container.state.running: my_container.kill() For type hints, use this from python_on_whales import Container def print_dodo(container: Container): print(container.execute([\"echo\", \"dodo\"])) Attributes It attributes are the same that you get with the command line: docker container inspect ... If you want to know the exact structure, you can go to the docker container inspect reference page and click on \"200 no error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: container = docker.run(\"ubuntu\", [\"sleep\", \"infinity\"], detach=True) In [4]: def super_print(obj): ...: print(f\"type={type(obj)}, value={obj}\") ...: In [4]: super_print(container.id) type = <class 'str'>, value = b5338112b414522bb3690facc2724c7e1de9fba01ba9e9f176e9ef430d5cf153 In [5]: super_print(container.created) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:15.697546+00:00 In [6]: super_print(container.path) type = <class 'str'>, value = sleep In [7]: super_print(container.args) type = <class 'list'>, value = ['infinity'] In [8]: super_print(container.state.status) type = <class 'str'>, value = running In [9]: super_print(container.state.running) type = <class 'bool'>, value = True In [10]: super_print(container.state.paused) type = <class 'bool'>, value = False In [11]: super_print(container.state.restarting) type = <class 'bool'>, value = False In [12]: super_print(container.state.oom_killed) type = <class 'bool'>, value = False In [13]: super_print(container.state.dead) type = <class 'bool'>, value = False In [14]: super_print(container.state.pid) type = <class 'int'>, value = 2651 In [15]: super_print(container.state.exit_code) type = <class 'int'>, value = 0 In [16]: super_print(container.state.error) type = <class 'str'>, value = In [17]: super_print(container.state.started_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:15.985213+00:00 In [18]: super_print(container.state.finished_at) type = <class 'datetime.datetime'>, value = 0001-01-01 00:00:00+00:00 In [19]: super_print(container.state.health) type = <class 'NoneType'>, value = None In [20]: super_print(container.image) type = <class 'str'>, value = sha256:54c9d81cbb440897908abdcaa98674db83444636c300170cfd211e40a66f704f In [21]: super_print(container.resolv_conf_path) type = <class 'str'>, value = /var/lib/docker/containers/b5338112b414522bb3690facc2724c7e1de9fba01ba9e9f176e9ef430d5cf153/resolv.conf In [22]: super_print(container.hostname_path) type = <class 'pathlib.PosixPath'>, value = /var/lib/docker/containers/b5338112b414522bb3690facc2724c7e1de9fba01ba9e9f176e9ef430d5cf153/hostname In [23]: super_print(container.hosts_path) type = <class 'pathlib.PosixPath'>, value = /var/lib/docker/containers/b5338112b414522bb3690facc2724c7e1de9fba01ba9e9f176e9ef430d5cf153/hosts In [24]: super_print(container.log_path) type = <class 'pathlib.PosixPath'>, value = /var/lib/docker/containers/b5338112b414522bb3690facc2724c7e1de9fba01ba9e9f176e9ef430d5cf153/b5338112b414522bb3690facc2724c7e1de9fba01ba9e9f176e9ef430d5cf153-json.log In [25]: super_print(container.node) type = <class 'NoneType'>, value = None In [26]: super_print(container.name) type = <class 'str'>, value = objective_chaum In [27]: super_print(container.restart_count) type = <class 'int'>, value = 0 In [28]: super_print(container.driver) type = <class 'str'>, value = overlay2 In [29]: super_print(container.platform) type = <class 'str'>, value = linux In [30]: super_print(container.mount_label) type = <class 'str'>, value = In [31]: super_print(container.process_label) type = <class 'str'>, value = In [32]: super_print(container.app_armor_profile) type = <class 'str'>, value = docker-default In [33]: super_print(container.exec_ids) type = <class 'NoneType'>, value = None In [34]: super_print(container.host_config.cpu_shares) type = <class 'int'>, value = 0 In [35]: super_print(container.host_config.memory) type = <class 'int'>, value = 0 In [36]: super_print(container.host_config.cgroup_parent) type = <class 'pathlib.PosixPath'>, value = . In [37]: super_print(container.host_config.blkio_weight) type = <class 'int'>, value = 0 In [38]: super_print(container.host_config.blkio_weight_device) type = <class 'list'>, value = [] In [39]: super_print(container.host_config.blkio_device_read_bps) type = <class 'NoneType'>, value = None In [40]: super_print(container.host_config.blkio_device_write_bps) type = <class 'NoneType'>, value = None In [41]: super_print(container.host_config.blkio_device_read_iops) type = <class 'NoneType'>, value = None In [42]: super_print(container.host_config.blkio_device_write_iops) type = <class 'NoneType'>, value = None In [43]: super_print(container.host_config.cpu_period) type = <class 'int'>, value = 0 In [44]: super_print(container.host_config.cpu_quota) type = <class 'int'>, value = 0 In [45]: super_print(container.host_config.cpu_realtime_period) type = <class 'int'>, value = 0 In [46]: super_print(container.host_config.cpu_realtime_runtime) type = <class 'int'>, value = 0 In [47]: super_print(container.host_config.cpuset_cpus) type = <class 'str'>, value = In [48]: super_print(container.host_config.cpuset_mems) type = <class 'str'>, value = In [49]: super_print(container.host_config.devices) type = <class 'list'>, value = [] In [50]: super_print(container.host_config.device_cgroup_rules) type = <class 'NoneType'>, value = None In [51]: super_print(container.host_config.device_requests) type = <class 'NoneType'>, value = None In [52]: super_print(container.host_config.kernel_memory) type = <class 'int'>, value = 0 In [53]: super_print(container.host_config.kernel_memory_tcp) type = <class 'int'>, value = 0 In [54]: super_print(container.host_config.memory_reservation) type = <class 'int'>, value = 0 In [55]: super_print(container.host_config.memory_swap) type = <class 'int'>, value = 0 In [56]: super_print(container.host_config.memory_swappiness) type = <class 'NoneType'>, value = None In [57]: super_print(container.host_config.nano_cpus) type = <class 'int'>, value = 0 In [58]: super_print(container.host_config.oom_kill_disable) type = <class 'bool'>, value = False In [59]: super_print(container.host_config.init) type = <class 'NoneType'>, value = None In [60]: super_print(container.host_config.pids_limit) type = <class 'NoneType'>, value = None In [61]: super_print(container.host_config.ulimits) type = <class 'NoneType'>, value = None In [62]: super_print(container.host_config.cpu_count) type = <class 'int'>, value = 0 In [63]: super_print(container.host_config.cpu_percent) type = <class 'int'>, value = 0 In [64]: super_print(container.host_config.binds) type = <class 'NoneType'>, value = None In [65]: super_print(container.host_config.container_id_file) type = <class 'pathlib.PosixPath'>, value = . In [66]: super_print(container.host_config.log_config.type) type = <class 'str'>, value = json-file In [67]: super_print(container.host_config.log_config.config) type = <class 'dict'>, value = {} In [68]: super_print(container.host_config.network_mode) type = <class 'str'>, value = default In [69]: super_print(container.host_config.port_bindings) type = <class 'dict'>, value = {} In [70]: super_print(container.host_config.restart_policy.name) type = <class 'str'>, value = no In [71]: super_print(container.host_config.restart_policy.maximum_retry_count) type = <class 'int'>, value = 0 In [72]: super_print(container.host_config.auto_remove) type = <class 'bool'>, value = False In [73]: super_print(container.host_config.volume_driver) type = <class 'str'>, value = In [74]: super_print(container.host_config.volumes_from) type = <class 'NoneType'>, value = None In [75]: super_print(container.host_config.mounts) type = <class 'NoneType'>, value = None In [76]: super_print(container.host_config.capabilities) type = <class 'NoneType'>, value = None In [77]: super_print(container.host_config.cap_add) type = <class 'NoneType'>, value = None In [78]: super_print(container.host_config.cap_drop) type = <class 'NoneType'>, value = None In [79]: super_print(container.host_config.dns) type = <class 'list'>, value = [] In [80]: super_print(container.host_config.dns_options) type = <class 'list'>, value = [] In [81]: super_print(container.host_config.dns_search) type = <class 'list'>, value = [] In [82]: super_print(container.host_config.extra_hosts) type = <class 'NoneType'>, value = None In [83]: super_print(container.host_config.group_add) type = <class 'NoneType'>, value = None In [84]: super_print(container.host_config.ipc_mode) type = <class 'str'>, value = private In [85]: super_print(container.host_config.cgroup) type = <class 'str'>, value = In [86]: super_print(container.host_config.links) type = <class 'NoneType'>, value = None In [87]: super_print(container.host_config.oom_score_adj) type = <class 'int'>, value = 0 In [88]: super_print(container.host_config.pid_mode) type = <class 'str'>, value = In [89]: super_print(container.host_config.privileged) type = <class 'bool'>, value = False In [90]: super_print(container.host_config.publish_all_ports) type = <class 'bool'>, value = False In [91]: super_print(container.host_config.readonly_rootfs) type = <class 'bool'>, value = False In [92]: super_print(container.host_config.security_opt) type = <class 'NoneType'>, value = None In [93]: super_print(container.host_config.storage_opt) type = <class 'NoneType'>, value = None In [94]: super_print(container.host_config.tmpfs) type = <class 'NoneType'>, value = None In [95]: super_print(container.host_config.uts_mode) type = <class 'str'>, value = In [96]: super_print(container.host_config.userns_mode) type = <class 'str'>, value = In [97]: super_print(container.host_config.shm_size) type = <class 'int'>, value = 67108864 In [98]: super_print(container.host_config.sysctls) type = <class 'NoneType'>, value = None In [99]: super_print(container.host_config.runtime) type = <class 'str'>, value = runc In [100]: super_print(container.host_config.console_size) type = <class 'tuple'>, value = (0, 0) In [101]: super_print(container.host_config.isolation) type = <class 'str'>, value = In [102]: super_print(container.host_config.masked_paths) type = <class 'list'>, value = [PosixPath('/proc/asound'), PosixPath('/proc/acpi'), PosixPath('/proc/kcore'), PosixPath('/proc/keys'), PosixPath('/proc/latency_stats'), PosixPath('/proc/timer_list'), PosixPath('/proc/timer_stats'), PosixPath('/proc/sched_debug'), PosixPath('/proc/scsi'), PosixPath('/sys/firmware')] In [103]: super_print(container.host_config.readonly_paths) type = <class 'list'>, value = [PosixPath('/proc/bus'), PosixPath('/proc/fs'), PosixPath('/proc/irq'), PosixPath('/proc/sys'), PosixPath('/proc/sysrq-trigger')] In [104]: super_print(container.graph_driver.name) type = <class 'str'>, value = overlay2 In [105]: super_print(container.graph_driver.data) type = <class 'dict'>, value = {'LowerDir': '/var/lib/docker/overlay2/a5425e491d6ce60a38a6314637f8e0d61571a95b7d1fd8dafbee4ac3b545e84d-init/diff:/var/lib/docker/overlay2/87ceeef0a34988e74061cfb2116147bf8f54b1b67e2bdb69b45dc0c5c1aba5a6/diff', 'MergedDir': '/var/lib/docker/overlay2/a5425e491d6ce60a38a6314637f8e0d61571a95b7d1fd8dafbee4ac3b545e84d/merged', 'UpperDir': '/var/lib/docker/overlay2/a5425e491d6ce60a38a6314637f8e0d61571a95b7d1fd8dafbee4ac3b545e84d/diff', 'WorkDir': '/var/lib/docker/overlay2/a5425e491d6ce60a38a6314637f8e0d61571a95b7d1fd8dafbee4ac3b545e84d/work'} In [106]: super_print(container.size_rw) type = <class 'NoneType'>, value = None In [107]: super_print(container.size_root_fs) type = <class 'NoneType'>, value = None In [108]: super_print(container.mounts) type = <class 'list'>, value = [] In [109]: super_print(container.config.hostname) type = <class 'str'>, value = b5338112b414 In [110]: super_print(container.config.domainname) type = <class 'str'>, value = In [111]: super_print(container.config.user) type = <class 'str'>, value = In [112]: super_print(container.config.attach_stdin) type = <class 'bool'>, value = False In [113]: super_print(container.config.attach_stdout) type = <class 'bool'>, value = False In [114]: super_print(container.config.attach_stderr) type = <class 'bool'>, value = False In [115]: super_print(container.config.exposed_ports) type = <class 'NoneType'>, value = None In [116]: super_print(container.config.tty) type = <class 'bool'>, value = False In [117]: super_print(container.config.open_stdin) type = <class 'bool'>, value = False In [118]: super_print(container.config.stdin_once) type = <class 'bool'>, value = False In [119]: super_print(container.config.env) type = <class 'list'>, value = ['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'] In [120]: super_print(container.config.cmd) type = <class 'list'>, value = ['sleep', 'infinity'] In [121]: super_print(container.config.healthcheck) type = <class 'NoneType'>, value = None In [122]: super_print(container.config.args_escaped) type = <class 'NoneType'>, value = None In [123]: super_print(container.config.image) type = <class 'str'>, value = ubuntu In [124]: super_print(container.config.volumes) type = <class 'NoneType'>, value = None In [125]: super_print(container.config.working_dir) type = <class 'pathlib.PosixPath'>, value = . In [126]: super_print(container.config.entrypoint) type = <class 'NoneType'>, value = None In [127]: super_print(container.config.network_disabled) type = <class 'NoneType'>, value = None In [128]: super_print(container.config.mac_address) type = <class 'NoneType'>, value = None In [129]: super_print(container.config.on_build) type = <class 'NoneType'>, value = None In [130]: super_print(container.config.labels) type = <class 'dict'>, value = {} In [131]: super_print(container.config.stop_signal) type = <class 'NoneType'>, value = None In [132]: super_print(container.config.stop_timeout) type = <class 'NoneType'>, value = None In [133]: super_print(container.config.shell) type = <class 'NoneType'>, value = None In [134]: super_print(container.network_settings.bridge) type = <class 'str'>, value = In [135]: super_print(container.network_settings.sandbox_id) type = <class 'str'>, value = 80b627e5c903b481bf9152040f9d47aed0c0e50d277088f09cd0ba07e34d53f4 In [136]: super_print(container.network_settings.hairpin_mode) type = <class 'bool'>, value = False In [137]: super_print(container.network_settings.link_local_ipv6_address) type = <class 'str'>, value = In [138]: super_print(container.network_settings.link_local_ipv6_prefix_length) type = <class 'int'>, value = 0 In [139]: super_print(container.network_settings.ports) type = <class 'dict'>, value = {} In [140]: super_print(container.network_settings.sandbox_key) type = <class 'pathlib.PosixPath'>, value = /var/run/docker/netns/80b627e5c903 In [141]: super_print(container.network_settings.secondary_ip_addresses) type = <class 'NoneType'>, value = None In [142]: super_print(container.network_settings.secondary_ipv6_addresses) type = <class 'NoneType'>, value = None In [143]: super_print(container.network_settings.endpoint_id) type = <class 'str'>, value = d9c7a6a47bd180c5d34ebdce0fc3cca43a33920c9b115c2f3b69a042fdadd423 In [144]: super_print(container.network_settings.gateway) type = <class 'str'>, value = 172.17.0.1 In [145]: super_print(container.network_settings.global_ipv6_address) type = <class 'str'>, value = In [146]: super_print(container.network_settings.global_ipv6_prefix_length) type = <class 'int'>, value = 0 In [147]: super_print(container.network_settings.ip_address) type = <class 'str'>, value = 172.17.0.2 In [148]: super_print(container.network_settings.ip_prefix_length) type = <class 'int'>, value = 16 In [149]: super_print(container.network_settings.ipv6_gateway) type = <class 'str'>, value = In [150]: super_print(container.network_settings.mac_address) type = <class 'str'>, value = 02:42:ac:11:00:02 In [151]: super_print(container.network_settings.networks) type = <class 'dict'>, value = {'bridge': NetworkInspectResult(ipam_config=None, links=None, aliases=None, network_id='d8bb8fd29211e5b644aa175971c706658d16be5e9b7e9a31e628d95ec21aff4a', endpoint_id='d9c7a6a47bd180c5d34ebdce0fc3cca43a33920c9b115c2f3b69a042fdadd423', gateway='172.17.0.1', ip_address='172.17.0.2', ip_prefix_length=16, ipv6_gateway='', global_ipv6_address='', global_ipv6_prefix_length=0, mac_address='02:42:ac:11:00:02', driver_options=None)} Methods commit Container.commit(tag=None, author=None, message=None, pause=True) Create a new image from the container's changes. Alias: docker.commit(...) See the docker.container.commit command for information about the arguments. copy_from Container.copy_from(container_path, local_path) copy_to Container.copy_to(local_path, container_path) diff Container.diff() Returns the diff of this container filesystem. See the docker.container.diff command for information about the arguments. execute Container.execute( command, detach=False, envs={}, env_files=[], interactive=False, privileged=False, tty=False, user=None, workdir=None, stream=False, ) Execute a command in this container See the docker.container.execute command for information about the arguments. exists Container.exists() Returns True if the docker container exists and False if it doesn't exists. If it doesn't exists, it most likely mean that it was removed. See the docker.container.exists command for information about the arguments. export Container.export(output) Export this container filesystem. See the docker.container.export command for information about the arguments. kill Container.kill(signal=None) Kill this container See the docker.container.kill command for information about the arguments. logs Container.logs(details=False, since=None, tail=None, timestamps=False, until=None) Returns the logs of the container See the docker.container.logs command for information about the arguments. pause Container.pause() Pause this container. See the docker.container.pause command for information about the arguments. reload Container.reload() remove Container.remove(force=False, volumes=False) Remove this container. See the docker.container.remove command for information about the arguments. rename Container.rename(new_name) Rename this container See the docker.container.rename command for information about the arguments. restart Container.restart(time=None) Restarts this container. See the docker.container.restart command for information about the arguments. start Container.start(attach=False, stream=False) Starts this container. See the docker.container.start command for information about the arguments. stop Container.stop(time=None) Stops this container. See the docker.container.stop command for information about the arguments. unpause Container.unpause() Unpause the container See the docker.container.unpause command for information about the arguments.","title":"Containers"},{"location":"docker_objects/containers/#docker-containers","text":"Don't use the constructor directly. Instead use from python_on_whales import docker my_container = docker.container.inspect(\"my-container-name\") # for example: if my_container.state.running: my_container.kill() For type hints, use this from python_on_whales import Container def print_dodo(container: Container): print(container.execute([\"echo\", \"dodo\"]))","title":"Docker containers"},{"location":"docker_objects/containers/#attributes","text":"It attributes are the same that you get with the command line: docker container inspect ... If you want to know the exact structure, you can go to the docker container inspect reference page and click on \"200 no error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: container = docker.run(\"ubuntu\", [\"sleep\", \"infinity\"], detach=True) In [4]: def super_print(obj): ...: print(f\"type={type(obj)}, value={obj}\") ...: In [4]: super_print(container.id) type = <class 'str'>, value = b5338112b414522bb3690facc2724c7e1de9fba01ba9e9f176e9ef430d5cf153 In [5]: super_print(container.created) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:15.697546+00:00 In [6]: super_print(container.path) type = <class 'str'>, value = sleep In [7]: super_print(container.args) type = <class 'list'>, value = ['infinity'] In [8]: super_print(container.state.status) type = <class 'str'>, value = running In [9]: super_print(container.state.running) type = <class 'bool'>, value = True In [10]: super_print(container.state.paused) type = <class 'bool'>, value = False In [11]: super_print(container.state.restarting) type = <class 'bool'>, value = False In [12]: super_print(container.state.oom_killed) type = <class 'bool'>, value = False In [13]: super_print(container.state.dead) type = <class 'bool'>, value = False In [14]: super_print(container.state.pid) type = <class 'int'>, value = 2651 In [15]: super_print(container.state.exit_code) type = <class 'int'>, value = 0 In [16]: super_print(container.state.error) type = <class 'str'>, value = In [17]: super_print(container.state.started_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:15.985213+00:00 In [18]: super_print(container.state.finished_at) type = <class 'datetime.datetime'>, value = 0001-01-01 00:00:00+00:00 In [19]: super_print(container.state.health) type = <class 'NoneType'>, value = None In [20]: super_print(container.image) type = <class 'str'>, value = sha256:54c9d81cbb440897908abdcaa98674db83444636c300170cfd211e40a66f704f In [21]: super_print(container.resolv_conf_path) type = <class 'str'>, value = /var/lib/docker/containers/b5338112b414522bb3690facc2724c7e1de9fba01ba9e9f176e9ef430d5cf153/resolv.conf In [22]: super_print(container.hostname_path) type = <class 'pathlib.PosixPath'>, value = /var/lib/docker/containers/b5338112b414522bb3690facc2724c7e1de9fba01ba9e9f176e9ef430d5cf153/hostname In [23]: super_print(container.hosts_path) type = <class 'pathlib.PosixPath'>, value = /var/lib/docker/containers/b5338112b414522bb3690facc2724c7e1de9fba01ba9e9f176e9ef430d5cf153/hosts In [24]: super_print(container.log_path) type = <class 'pathlib.PosixPath'>, value = /var/lib/docker/containers/b5338112b414522bb3690facc2724c7e1de9fba01ba9e9f176e9ef430d5cf153/b5338112b414522bb3690facc2724c7e1de9fba01ba9e9f176e9ef430d5cf153-json.log In [25]: super_print(container.node) type = <class 'NoneType'>, value = None In [26]: super_print(container.name) type = <class 'str'>, value = objective_chaum In [27]: super_print(container.restart_count) type = <class 'int'>, value = 0 In [28]: super_print(container.driver) type = <class 'str'>, value = overlay2 In [29]: super_print(container.platform) type = <class 'str'>, value = linux In [30]: super_print(container.mount_label) type = <class 'str'>, value = In [31]: super_print(container.process_label) type = <class 'str'>, value = In [32]: super_print(container.app_armor_profile) type = <class 'str'>, value = docker-default In [33]: super_print(container.exec_ids) type = <class 'NoneType'>, value = None In [34]: super_print(container.host_config.cpu_shares) type = <class 'int'>, value = 0 In [35]: super_print(container.host_config.memory) type = <class 'int'>, value = 0 In [36]: super_print(container.host_config.cgroup_parent) type = <class 'pathlib.PosixPath'>, value = . In [37]: super_print(container.host_config.blkio_weight) type = <class 'int'>, value = 0 In [38]: super_print(container.host_config.blkio_weight_device) type = <class 'list'>, value = [] In [39]: super_print(container.host_config.blkio_device_read_bps) type = <class 'NoneType'>, value = None In [40]: super_print(container.host_config.blkio_device_write_bps) type = <class 'NoneType'>, value = None In [41]: super_print(container.host_config.blkio_device_read_iops) type = <class 'NoneType'>, value = None In [42]: super_print(container.host_config.blkio_device_write_iops) type = <class 'NoneType'>, value = None In [43]: super_print(container.host_config.cpu_period) type = <class 'int'>, value = 0 In [44]: super_print(container.host_config.cpu_quota) type = <class 'int'>, value = 0 In [45]: super_print(container.host_config.cpu_realtime_period) type = <class 'int'>, value = 0 In [46]: super_print(container.host_config.cpu_realtime_runtime) type = <class 'int'>, value = 0 In [47]: super_print(container.host_config.cpuset_cpus) type = <class 'str'>, value = In [48]: super_print(container.host_config.cpuset_mems) type = <class 'str'>, value = In [49]: super_print(container.host_config.devices) type = <class 'list'>, value = [] In [50]: super_print(container.host_config.device_cgroup_rules) type = <class 'NoneType'>, value = None In [51]: super_print(container.host_config.device_requests) type = <class 'NoneType'>, value = None In [52]: super_print(container.host_config.kernel_memory) type = <class 'int'>, value = 0 In [53]: super_print(container.host_config.kernel_memory_tcp) type = <class 'int'>, value = 0 In [54]: super_print(container.host_config.memory_reservation) type = <class 'int'>, value = 0 In [55]: super_print(container.host_config.memory_swap) type = <class 'int'>, value = 0 In [56]: super_print(container.host_config.memory_swappiness) type = <class 'NoneType'>, value = None In [57]: super_print(container.host_config.nano_cpus) type = <class 'int'>, value = 0 In [58]: super_print(container.host_config.oom_kill_disable) type = <class 'bool'>, value = False In [59]: super_print(container.host_config.init) type = <class 'NoneType'>, value = None In [60]: super_print(container.host_config.pids_limit) type = <class 'NoneType'>, value = None In [61]: super_print(container.host_config.ulimits) type = <class 'NoneType'>, value = None In [62]: super_print(container.host_config.cpu_count) type = <class 'int'>, value = 0 In [63]: super_print(container.host_config.cpu_percent) type = <class 'int'>, value = 0 In [64]: super_print(container.host_config.binds) type = <class 'NoneType'>, value = None In [65]: super_print(container.host_config.container_id_file) type = <class 'pathlib.PosixPath'>, value = . In [66]: super_print(container.host_config.log_config.type) type = <class 'str'>, value = json-file In [67]: super_print(container.host_config.log_config.config) type = <class 'dict'>, value = {} In [68]: super_print(container.host_config.network_mode) type = <class 'str'>, value = default In [69]: super_print(container.host_config.port_bindings) type = <class 'dict'>, value = {} In [70]: super_print(container.host_config.restart_policy.name) type = <class 'str'>, value = no In [71]: super_print(container.host_config.restart_policy.maximum_retry_count) type = <class 'int'>, value = 0 In [72]: super_print(container.host_config.auto_remove) type = <class 'bool'>, value = False In [73]: super_print(container.host_config.volume_driver) type = <class 'str'>, value = In [74]: super_print(container.host_config.volumes_from) type = <class 'NoneType'>, value = None In [75]: super_print(container.host_config.mounts) type = <class 'NoneType'>, value = None In [76]: super_print(container.host_config.capabilities) type = <class 'NoneType'>, value = None In [77]: super_print(container.host_config.cap_add) type = <class 'NoneType'>, value = None In [78]: super_print(container.host_config.cap_drop) type = <class 'NoneType'>, value = None In [79]: super_print(container.host_config.dns) type = <class 'list'>, value = [] In [80]: super_print(container.host_config.dns_options) type = <class 'list'>, value = [] In [81]: super_print(container.host_config.dns_search) type = <class 'list'>, value = [] In [82]: super_print(container.host_config.extra_hosts) type = <class 'NoneType'>, value = None In [83]: super_print(container.host_config.group_add) type = <class 'NoneType'>, value = None In [84]: super_print(container.host_config.ipc_mode) type = <class 'str'>, value = private In [85]: super_print(container.host_config.cgroup) type = <class 'str'>, value = In [86]: super_print(container.host_config.links) type = <class 'NoneType'>, value = None In [87]: super_print(container.host_config.oom_score_adj) type = <class 'int'>, value = 0 In [88]: super_print(container.host_config.pid_mode) type = <class 'str'>, value = In [89]: super_print(container.host_config.privileged) type = <class 'bool'>, value = False In [90]: super_print(container.host_config.publish_all_ports) type = <class 'bool'>, value = False In [91]: super_print(container.host_config.readonly_rootfs) type = <class 'bool'>, value = False In [92]: super_print(container.host_config.security_opt) type = <class 'NoneType'>, value = None In [93]: super_print(container.host_config.storage_opt) type = <class 'NoneType'>, value = None In [94]: super_print(container.host_config.tmpfs) type = <class 'NoneType'>, value = None In [95]: super_print(container.host_config.uts_mode) type = <class 'str'>, value = In [96]: super_print(container.host_config.userns_mode) type = <class 'str'>, value = In [97]: super_print(container.host_config.shm_size) type = <class 'int'>, value = 67108864 In [98]: super_print(container.host_config.sysctls) type = <class 'NoneType'>, value = None In [99]: super_print(container.host_config.runtime) type = <class 'str'>, value = runc In [100]: super_print(container.host_config.console_size) type = <class 'tuple'>, value = (0, 0) In [101]: super_print(container.host_config.isolation) type = <class 'str'>, value = In [102]: super_print(container.host_config.masked_paths) type = <class 'list'>, value = [PosixPath('/proc/asound'), PosixPath('/proc/acpi'), PosixPath('/proc/kcore'), PosixPath('/proc/keys'), PosixPath('/proc/latency_stats'), PosixPath('/proc/timer_list'), PosixPath('/proc/timer_stats'), PosixPath('/proc/sched_debug'), PosixPath('/proc/scsi'), PosixPath('/sys/firmware')] In [103]: super_print(container.host_config.readonly_paths) type = <class 'list'>, value = [PosixPath('/proc/bus'), PosixPath('/proc/fs'), PosixPath('/proc/irq'), PosixPath('/proc/sys'), PosixPath('/proc/sysrq-trigger')] In [104]: super_print(container.graph_driver.name) type = <class 'str'>, value = overlay2 In [105]: super_print(container.graph_driver.data) type = <class 'dict'>, value = {'LowerDir': '/var/lib/docker/overlay2/a5425e491d6ce60a38a6314637f8e0d61571a95b7d1fd8dafbee4ac3b545e84d-init/diff:/var/lib/docker/overlay2/87ceeef0a34988e74061cfb2116147bf8f54b1b67e2bdb69b45dc0c5c1aba5a6/diff', 'MergedDir': '/var/lib/docker/overlay2/a5425e491d6ce60a38a6314637f8e0d61571a95b7d1fd8dafbee4ac3b545e84d/merged', 'UpperDir': '/var/lib/docker/overlay2/a5425e491d6ce60a38a6314637f8e0d61571a95b7d1fd8dafbee4ac3b545e84d/diff', 'WorkDir': '/var/lib/docker/overlay2/a5425e491d6ce60a38a6314637f8e0d61571a95b7d1fd8dafbee4ac3b545e84d/work'} In [106]: super_print(container.size_rw) type = <class 'NoneType'>, value = None In [107]: super_print(container.size_root_fs) type = <class 'NoneType'>, value = None In [108]: super_print(container.mounts) type = <class 'list'>, value = [] In [109]: super_print(container.config.hostname) type = <class 'str'>, value = b5338112b414 In [110]: super_print(container.config.domainname) type = <class 'str'>, value = In [111]: super_print(container.config.user) type = <class 'str'>, value = In [112]: super_print(container.config.attach_stdin) type = <class 'bool'>, value = False In [113]: super_print(container.config.attach_stdout) type = <class 'bool'>, value = False In [114]: super_print(container.config.attach_stderr) type = <class 'bool'>, value = False In [115]: super_print(container.config.exposed_ports) type = <class 'NoneType'>, value = None In [116]: super_print(container.config.tty) type = <class 'bool'>, value = False In [117]: super_print(container.config.open_stdin) type = <class 'bool'>, value = False In [118]: super_print(container.config.stdin_once) type = <class 'bool'>, value = False In [119]: super_print(container.config.env) type = <class 'list'>, value = ['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'] In [120]: super_print(container.config.cmd) type = <class 'list'>, value = ['sleep', 'infinity'] In [121]: super_print(container.config.healthcheck) type = <class 'NoneType'>, value = None In [122]: super_print(container.config.args_escaped) type = <class 'NoneType'>, value = None In [123]: super_print(container.config.image) type = <class 'str'>, value = ubuntu In [124]: super_print(container.config.volumes) type = <class 'NoneType'>, value = None In [125]: super_print(container.config.working_dir) type = <class 'pathlib.PosixPath'>, value = . In [126]: super_print(container.config.entrypoint) type = <class 'NoneType'>, value = None In [127]: super_print(container.config.network_disabled) type = <class 'NoneType'>, value = None In [128]: super_print(container.config.mac_address) type = <class 'NoneType'>, value = None In [129]: super_print(container.config.on_build) type = <class 'NoneType'>, value = None In [130]: super_print(container.config.labels) type = <class 'dict'>, value = {} In [131]: super_print(container.config.stop_signal) type = <class 'NoneType'>, value = None In [132]: super_print(container.config.stop_timeout) type = <class 'NoneType'>, value = None In [133]: super_print(container.config.shell) type = <class 'NoneType'>, value = None In [134]: super_print(container.network_settings.bridge) type = <class 'str'>, value = In [135]: super_print(container.network_settings.sandbox_id) type = <class 'str'>, value = 80b627e5c903b481bf9152040f9d47aed0c0e50d277088f09cd0ba07e34d53f4 In [136]: super_print(container.network_settings.hairpin_mode) type = <class 'bool'>, value = False In [137]: super_print(container.network_settings.link_local_ipv6_address) type = <class 'str'>, value = In [138]: super_print(container.network_settings.link_local_ipv6_prefix_length) type = <class 'int'>, value = 0 In [139]: super_print(container.network_settings.ports) type = <class 'dict'>, value = {} In [140]: super_print(container.network_settings.sandbox_key) type = <class 'pathlib.PosixPath'>, value = /var/run/docker/netns/80b627e5c903 In [141]: super_print(container.network_settings.secondary_ip_addresses) type = <class 'NoneType'>, value = None In [142]: super_print(container.network_settings.secondary_ipv6_addresses) type = <class 'NoneType'>, value = None In [143]: super_print(container.network_settings.endpoint_id) type = <class 'str'>, value = d9c7a6a47bd180c5d34ebdce0fc3cca43a33920c9b115c2f3b69a042fdadd423 In [144]: super_print(container.network_settings.gateway) type = <class 'str'>, value = 172.17.0.1 In [145]: super_print(container.network_settings.global_ipv6_address) type = <class 'str'>, value = In [146]: super_print(container.network_settings.global_ipv6_prefix_length) type = <class 'int'>, value = 0 In [147]: super_print(container.network_settings.ip_address) type = <class 'str'>, value = 172.17.0.2 In [148]: super_print(container.network_settings.ip_prefix_length) type = <class 'int'>, value = 16 In [149]: super_print(container.network_settings.ipv6_gateway) type = <class 'str'>, value = In [150]: super_print(container.network_settings.mac_address) type = <class 'str'>, value = 02:42:ac:11:00:02 In [151]: super_print(container.network_settings.networks) type = <class 'dict'>, value = {'bridge': NetworkInspectResult(ipam_config=None, links=None, aliases=None, network_id='d8bb8fd29211e5b644aa175971c706658d16be5e9b7e9a31e628d95ec21aff4a', endpoint_id='d9c7a6a47bd180c5d34ebdce0fc3cca43a33920c9b115c2f3b69a042fdadd423', gateway='172.17.0.1', ip_address='172.17.0.2', ip_prefix_length=16, ipv6_gateway='', global_ipv6_address='', global_ipv6_prefix_length=0, mac_address='02:42:ac:11:00:02', driver_options=None)}","title":"Attributes"},{"location":"docker_objects/containers/#methods","text":"","title":"Methods"},{"location":"docker_objects/containers/#commit","text":"Container.commit(tag=None, author=None, message=None, pause=True) Create a new image from the container's changes. Alias: docker.commit(...) See the docker.container.commit command for information about the arguments.","title":"commit"},{"location":"docker_objects/containers/#copy_from","text":"Container.copy_from(container_path, local_path)","title":"copy_from"},{"location":"docker_objects/containers/#copy_to","text":"Container.copy_to(local_path, container_path)","title":"copy_to"},{"location":"docker_objects/containers/#diff","text":"Container.diff() Returns the diff of this container filesystem. See the docker.container.diff command for information about the arguments.","title":"diff"},{"location":"docker_objects/containers/#execute","text":"Container.execute( command, detach=False, envs={}, env_files=[], interactive=False, privileged=False, tty=False, user=None, workdir=None, stream=False, ) Execute a command in this container See the docker.container.execute command for information about the arguments.","title":"execute"},{"location":"docker_objects/containers/#exists","text":"Container.exists() Returns True if the docker container exists and False if it doesn't exists. If it doesn't exists, it most likely mean that it was removed. See the docker.container.exists command for information about the arguments.","title":"exists"},{"location":"docker_objects/containers/#export","text":"Container.export(output) Export this container filesystem. See the docker.container.export command for information about the arguments.","title":"export"},{"location":"docker_objects/containers/#kill","text":"Container.kill(signal=None) Kill this container See the docker.container.kill command for information about the arguments.","title":"kill"},{"location":"docker_objects/containers/#logs","text":"Container.logs(details=False, since=None, tail=None, timestamps=False, until=None) Returns the logs of the container See the docker.container.logs command for information about the arguments.","title":"logs"},{"location":"docker_objects/containers/#pause","text":"Container.pause() Pause this container. See the docker.container.pause command for information about the arguments.","title":"pause"},{"location":"docker_objects/containers/#reload","text":"Container.reload()","title":"reload"},{"location":"docker_objects/containers/#remove","text":"Container.remove(force=False, volumes=False) Remove this container. See the docker.container.remove command for information about the arguments.","title":"remove"},{"location":"docker_objects/containers/#rename","text":"Container.rename(new_name) Rename this container See the docker.container.rename command for information about the arguments.","title":"rename"},{"location":"docker_objects/containers/#restart","text":"Container.restart(time=None) Restarts this container. See the docker.container.restart command for information about the arguments.","title":"restart"},{"location":"docker_objects/containers/#start","text":"Container.start(attach=False, stream=False) Starts this container. See the docker.container.start command for information about the arguments.","title":"start"},{"location":"docker_objects/containers/#stop","text":"Container.stop(time=None) Stops this container. See the docker.container.stop command for information about the arguments.","title":"stop"},{"location":"docker_objects/containers/#unpause","text":"Container.unpause() Unpause the container See the docker.container.unpause command for information about the arguments.","title":"unpause"},{"location":"docker_objects/images/","text":"Docker images Don't use the constructor directly. Instead use from python_on_whales import docker my_docker_image = docker.image.inspect(\"my-image-name\") # or my_docker_image = docker.pull(\"my-image-name\") For type hints, use this from python_on_whales import docker, Image def print_dodo(image: Image): print(docker.run(image, [\"echo\", \"dodo\"])) Attributes It attributes are the same that you get with the command line: docker image inspect ... To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: image = docker.pull(\"ubuntu\") 20.04: Pulling from library/ubuntu 6a5697faee43: Pull complete ba13d3bc422b: Pull complete a254829d9e55: Pull complete Digest: sha256:fff16eea1a8ae92867721d90c59a75652ea66d29c05294e6e2f898704bdb8cf1 Status: Downloaded newer image for ubuntu:latest docker.io/library/ubuntu:latest In [3]: def super_print(obj): ...: print(f\"type={type(obj)}, value={obj}\") ...: In [4]: super_print(image.id) type = <class 'str'>, value = sha256:54c9d81cbb440897908abdcaa98674db83444636c300170cfd211e40a66f704f In [5]: super_print(image.repo_tags) type = <class 'list'>, value = ['ubuntu:20.04', 'ubuntu:latest'] In [6]: super_print(image.repo_digests) type = <class 'list'>, value = ['ubuntu@sha256:669e010b58baf5beb2836b253c1fd5768333f0d1dbcb834f7c07a4dc93f474be'] In [7]: super_print(image.parent) type = <class 'str'>, value = In [8]: super_print(image.comment) type = <class 'str'>, value = In [9]: super_print(image.created) type = <class 'datetime.datetime'>, value = 2022-02-02 02:14:46.177066+00:00 In [10]: super_print(image.container) type = <class 'str'>, value = 3d4cc5cf7dc1af55a2be4440b5be4f96ea35516b98407a9b9446c218bb43818a In [11]: super_print(image.container_config) type = <class 'python_on_whales.components.container.models.ContainerConfig'>, value = hostname='3d4cc5cf7dc1' domainname='' user='' attach_stdin=False attach_stdout=False attach_stderr=False exposed_ports=None tty=False open_stdin=False stdin_once=False env=['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'] cmd=['/bin/sh', '-c', '#(nop) ', 'CMD [\"bash\"]'] healthcheck=None args_escaped=None image='sha256:b7032458728a84cd355ae42a8f7b323e29af86a22b211f4701363191b25fa805' volumes=None working_dir=PosixPath('.') entrypoint=None network_disabled=None mac_address=None on_build=None labels={} stop_signal=None stop_timeout=None shell=None In [12]: super_print(image.docker_version) type = <class 'str'>, value = 20.10.7 In [13]: super_print(image.author) type = <class 'str'>, value = In [14]: super_print(image.config) type = <class 'python_on_whales.components.container.models.ContainerConfig'>, value = hostname='' domainname='' user='' attach_stdin=False attach_stdout=False attach_stderr=False exposed_ports=None tty=False open_stdin=False stdin_once=False env=['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'] cmd=['bash'] healthcheck=None args_escaped=None image='sha256:b7032458728a84cd355ae42a8f7b323e29af86a22b211f4701363191b25fa805' volumes=None working_dir=PosixPath('.') entrypoint=None network_disabled=None mac_address=None on_build=None labels=None stop_signal=None stop_timeout=None shell=None In [15]: super_print(image.architecture) type = <class 'str'>, value = amd64 In [16]: super_print(image.os) type = <class 'str'>, value = linux In [17]: super_print(image.os_version) type = <class 'NoneType'>, value = None In [18]: super_print(image.size) type = <class 'int'>, value = 72772339 In [19]: super_print(image.virtual_size) type = <class 'int'>, value = 72772339 In [20]: super_print(image.graph_driver.name) type = <class 'str'>, value = overlay2 In [21]: super_print(image.graph_driver.data) type = <class 'dict'>, value = {'MergedDir': '/var/lib/docker/overlay2/87ceeef0a34988e74061cfb2116147bf8f54b1b67e2bdb69b45dc0c5c1aba5a6/merged', 'UpperDir': '/var/lib/docker/overlay2/87ceeef0a34988e74061cfb2116147bf8f54b1b67e2bdb69b45dc0c5c1aba5a6/diff', 'WorkDir': '/var/lib/docker/overlay2/87ceeef0a34988e74061cfb2116147bf8f54b1b67e2bdb69b45dc0c5c1aba5a6/work'} In [22]: super_print(image.root_fs.type) type = <class 'str'>, value = layers In [23]: super_print(image.root_fs.layers) type = <class 'list'>, value = ['sha256:36ffdceb4c77bf34325fb695e64ea447f688797f2f1e3af224c29593310578d2'] In [24]: super_print(image.root_fs.base_layer) type = <class 'NoneType'>, value = None In [25]: super_print(image.metadata) type = <class 'dict'>, value = {'LastTagTime': '0001-01-01T00:00:00Z'} Methods copy_from Image.copy_from(path_in_image, destination) Copy a file from a docker image in the local filesystem. See the docker.image.copy_from command for information about the arguments. copy_to Image.copy_to(local_path, path_in_image, new_tag=None) Copy a file from the local filesystem in a docker image to create a new docker image. As if you did a dockerfile with a COPY instruction. See the docker.image.copy_to command for information about the arguments. exists Image.exists() Returns True if the docker image exists and False if it doesn't exists. Note that you might have done docker.image.remove(\"some_tag\") and the image might still exists because python-on-whales references images by id, not by tag. See the docker.image.exists command for information about the arguments. reload Image.reload() remove Image.remove(force=False, prune=True) Remove this Docker image. See the docker.image.remove command for information about the arguments. save Image.save(output=None) Saves this Docker image in a tar. See the docker.image.save command for information about the arguments. tag Image.tag(new_tag) Add a tag to a Docker image. See the docker.image.tag command for information about the arguments.","title":"Images"},{"location":"docker_objects/images/#docker-images","text":"Don't use the constructor directly. Instead use from python_on_whales import docker my_docker_image = docker.image.inspect(\"my-image-name\") # or my_docker_image = docker.pull(\"my-image-name\") For type hints, use this from python_on_whales import docker, Image def print_dodo(image: Image): print(docker.run(image, [\"echo\", \"dodo\"]))","title":"Docker images"},{"location":"docker_objects/images/#attributes","text":"It attributes are the same that you get with the command line: docker image inspect ... To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: image = docker.pull(\"ubuntu\") 20.04: Pulling from library/ubuntu 6a5697faee43: Pull complete ba13d3bc422b: Pull complete a254829d9e55: Pull complete Digest: sha256:fff16eea1a8ae92867721d90c59a75652ea66d29c05294e6e2f898704bdb8cf1 Status: Downloaded newer image for ubuntu:latest docker.io/library/ubuntu:latest In [3]: def super_print(obj): ...: print(f\"type={type(obj)}, value={obj}\") ...: In [4]: super_print(image.id) type = <class 'str'>, value = sha256:54c9d81cbb440897908abdcaa98674db83444636c300170cfd211e40a66f704f In [5]: super_print(image.repo_tags) type = <class 'list'>, value = ['ubuntu:20.04', 'ubuntu:latest'] In [6]: super_print(image.repo_digests) type = <class 'list'>, value = ['ubuntu@sha256:669e010b58baf5beb2836b253c1fd5768333f0d1dbcb834f7c07a4dc93f474be'] In [7]: super_print(image.parent) type = <class 'str'>, value = In [8]: super_print(image.comment) type = <class 'str'>, value = In [9]: super_print(image.created) type = <class 'datetime.datetime'>, value = 2022-02-02 02:14:46.177066+00:00 In [10]: super_print(image.container) type = <class 'str'>, value = 3d4cc5cf7dc1af55a2be4440b5be4f96ea35516b98407a9b9446c218bb43818a In [11]: super_print(image.container_config) type = <class 'python_on_whales.components.container.models.ContainerConfig'>, value = hostname='3d4cc5cf7dc1' domainname='' user='' attach_stdin=False attach_stdout=False attach_stderr=False exposed_ports=None tty=False open_stdin=False stdin_once=False env=['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'] cmd=['/bin/sh', '-c', '#(nop) ', 'CMD [\"bash\"]'] healthcheck=None args_escaped=None image='sha256:b7032458728a84cd355ae42a8f7b323e29af86a22b211f4701363191b25fa805' volumes=None working_dir=PosixPath('.') entrypoint=None network_disabled=None mac_address=None on_build=None labels={} stop_signal=None stop_timeout=None shell=None In [12]: super_print(image.docker_version) type = <class 'str'>, value = 20.10.7 In [13]: super_print(image.author) type = <class 'str'>, value = In [14]: super_print(image.config) type = <class 'python_on_whales.components.container.models.ContainerConfig'>, value = hostname='' domainname='' user='' attach_stdin=False attach_stdout=False attach_stderr=False exposed_ports=None tty=False open_stdin=False stdin_once=False env=['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'] cmd=['bash'] healthcheck=None args_escaped=None image='sha256:b7032458728a84cd355ae42a8f7b323e29af86a22b211f4701363191b25fa805' volumes=None working_dir=PosixPath('.') entrypoint=None network_disabled=None mac_address=None on_build=None labels=None stop_signal=None stop_timeout=None shell=None In [15]: super_print(image.architecture) type = <class 'str'>, value = amd64 In [16]: super_print(image.os) type = <class 'str'>, value = linux In [17]: super_print(image.os_version) type = <class 'NoneType'>, value = None In [18]: super_print(image.size) type = <class 'int'>, value = 72772339 In [19]: super_print(image.virtual_size) type = <class 'int'>, value = 72772339 In [20]: super_print(image.graph_driver.name) type = <class 'str'>, value = overlay2 In [21]: super_print(image.graph_driver.data) type = <class 'dict'>, value = {'MergedDir': '/var/lib/docker/overlay2/87ceeef0a34988e74061cfb2116147bf8f54b1b67e2bdb69b45dc0c5c1aba5a6/merged', 'UpperDir': '/var/lib/docker/overlay2/87ceeef0a34988e74061cfb2116147bf8f54b1b67e2bdb69b45dc0c5c1aba5a6/diff', 'WorkDir': '/var/lib/docker/overlay2/87ceeef0a34988e74061cfb2116147bf8f54b1b67e2bdb69b45dc0c5c1aba5a6/work'} In [22]: super_print(image.root_fs.type) type = <class 'str'>, value = layers In [23]: super_print(image.root_fs.layers) type = <class 'list'>, value = ['sha256:36ffdceb4c77bf34325fb695e64ea447f688797f2f1e3af224c29593310578d2'] In [24]: super_print(image.root_fs.base_layer) type = <class 'NoneType'>, value = None In [25]: super_print(image.metadata) type = <class 'dict'>, value = {'LastTagTime': '0001-01-01T00:00:00Z'}","title":"Attributes"},{"location":"docker_objects/images/#methods","text":"","title":"Methods"},{"location":"docker_objects/images/#copy_from","text":"Image.copy_from(path_in_image, destination) Copy a file from a docker image in the local filesystem. See the docker.image.copy_from command for information about the arguments.","title":"copy_from"},{"location":"docker_objects/images/#copy_to","text":"Image.copy_to(local_path, path_in_image, new_tag=None) Copy a file from the local filesystem in a docker image to create a new docker image. As if you did a dockerfile with a COPY instruction. See the docker.image.copy_to command for information about the arguments.","title":"copy_to"},{"location":"docker_objects/images/#exists","text":"Image.exists() Returns True if the docker image exists and False if it doesn't exists. Note that you might have done docker.image.remove(\"some_tag\") and the image might still exists because python-on-whales references images by id, not by tag. See the docker.image.exists command for information about the arguments.","title":"exists"},{"location":"docker_objects/images/#reload","text":"Image.reload()","title":"reload"},{"location":"docker_objects/images/#remove","text":"Image.remove(force=False, prune=True) Remove this Docker image. See the docker.image.remove command for information about the arguments.","title":"remove"},{"location":"docker_objects/images/#save","text":"Image.save(output=None) Saves this Docker image in a tar. See the docker.image.save command for information about the arguments.","title":"save"},{"location":"docker_objects/images/#tag","text":"Image.tag(new_tag) Add a tag to a Docker image. See the docker.image.tag command for information about the arguments.","title":"tag"},{"location":"docker_objects/networks/","text":"Docker networks Don't use the constructor directly. Instead use from python_on_whales import docker my_network = docker.network.create(\"some-network\") my_network = docker.container.inspect(\"some-network\") For type hints, use this from python_on_whales import Network, docker def ping_hostname_in_network(my_network: Network): docker.run(\"busybox\", [\"ping\", \"-c\", \"10\", \"my_hostname\"], networks=[my_network]) Attributes It attributes are the same that you get with the command line: docker network inspect ... If you want to know the exact structure, you can go to the docker network inspect reference page and click on \"200 no error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: network = docker.network.create(\"my-network\") In [3]: container = docker.run( \"ubuntu\", [\"sleep\", \"infinity\"], name=\"my_ubuntu\", detach=True, networks=[network] ) In [4]: def super_print(obj): ...: print(f\"type={type(obj)}, value={obj}\") ...: In [5]: super_print(network.name) type = <class 'str'>, value = my-network In [6]: super_print(network.id) type = <class 'str'>, value = 4d302a95e05e4b8a8f61054a9d4769948b233464a64f388e6d0b312275d870d9 In [7]: super_print(network.created) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:03.186131+00:00 In [8]: super_print(network.scope) type = <class 'str'>, value = local In [9]: super_print(network.driver) type = <class 'str'>, value = bridge In [10]: super_print(network.enable_ipv6) type = <class 'bool'>, value = False In [11]: super_print(network.ipam.driver) type = <class 'str'>, value = default In [12]: super_print(network.ipam.config) type = <class 'list'>, value = [{'Subnet': '172.19.0.0/16', 'Gateway': '172.19.0.1'}] In [13]: super_print(network.ipam.options) type = <class 'dict'>, value = {} In [14]: super_print(network.internal) type = <class 'bool'>, value = False In [15]: super_print(network.attachable) type = <class 'bool'>, value = False In [16]: super_print(network.ingress) type = <class 'bool'>, value = False In [17]: super_print(network.containers) type = <class 'dict'>, value = {'cb8fbd25d3fc5355e8f556678e1c0a0774ca832e7013f124e0a9508816bf7d8b': NetworkContainer(name='my_ubuntu', endpoint_id='831b2b0580f89139f8122b85712700497ef5d31713f0cb782f836fb745063a4f', mac_address='02:42:ac:13:00:02', ipv4_address='172.19.0.2/16', ipv6_address='')} In [18]: super_print(network.options) type = <class 'dict'>, value = {} In [19]: super_print(network.labels) type = <class 'dict'>, value = {} In [20]: super_print(network.config_from) type = <class 'dict'>, value = {'Network': ''} In [21]: super_print(network.config_only) type = <class 'bool'>, value = False Methods reload Network.reload() remove Network.remove() Removes this Docker network. Rather than removing it manually, you can use a context manager to make sure the network is deleted even if an exception is raised. from python_on_whales import docker with docker.network.create(\"some_name\") as my_net: docker.run( \"busybox\", [\"ping\", \"idonotexistatall.com\"], networks=[my_net], remove=True, ) # an exception will be raised because the container will fail # but the network will be removed anyway.","title":"Networks"},{"location":"docker_objects/networks/#docker-networks","text":"Don't use the constructor directly. Instead use from python_on_whales import docker my_network = docker.network.create(\"some-network\") my_network = docker.container.inspect(\"some-network\") For type hints, use this from python_on_whales import Network, docker def ping_hostname_in_network(my_network: Network): docker.run(\"busybox\", [\"ping\", \"-c\", \"10\", \"my_hostname\"], networks=[my_network])","title":"Docker networks"},{"location":"docker_objects/networks/#attributes","text":"It attributes are the same that you get with the command line: docker network inspect ... If you want to know the exact structure, you can go to the docker network inspect reference page and click on \"200 no error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: network = docker.network.create(\"my-network\") In [3]: container = docker.run( \"ubuntu\", [\"sleep\", \"infinity\"], name=\"my_ubuntu\", detach=True, networks=[network] ) In [4]: def super_print(obj): ...: print(f\"type={type(obj)}, value={obj}\") ...: In [5]: super_print(network.name) type = <class 'str'>, value = my-network In [6]: super_print(network.id) type = <class 'str'>, value = 4d302a95e05e4b8a8f61054a9d4769948b233464a64f388e6d0b312275d870d9 In [7]: super_print(network.created) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:03.186131+00:00 In [8]: super_print(network.scope) type = <class 'str'>, value = local In [9]: super_print(network.driver) type = <class 'str'>, value = bridge In [10]: super_print(network.enable_ipv6) type = <class 'bool'>, value = False In [11]: super_print(network.ipam.driver) type = <class 'str'>, value = default In [12]: super_print(network.ipam.config) type = <class 'list'>, value = [{'Subnet': '172.19.0.0/16', 'Gateway': '172.19.0.1'}] In [13]: super_print(network.ipam.options) type = <class 'dict'>, value = {} In [14]: super_print(network.internal) type = <class 'bool'>, value = False In [15]: super_print(network.attachable) type = <class 'bool'>, value = False In [16]: super_print(network.ingress) type = <class 'bool'>, value = False In [17]: super_print(network.containers) type = <class 'dict'>, value = {'cb8fbd25d3fc5355e8f556678e1c0a0774ca832e7013f124e0a9508816bf7d8b': NetworkContainer(name='my_ubuntu', endpoint_id='831b2b0580f89139f8122b85712700497ef5d31713f0cb782f836fb745063a4f', mac_address='02:42:ac:13:00:02', ipv4_address='172.19.0.2/16', ipv6_address='')} In [18]: super_print(network.options) type = <class 'dict'>, value = {} In [19]: super_print(network.labels) type = <class 'dict'>, value = {} In [20]: super_print(network.config_from) type = <class 'dict'>, value = {'Network': ''} In [21]: super_print(network.config_only) type = <class 'bool'>, value = False","title":"Attributes"},{"location":"docker_objects/networks/#methods","text":"","title":"Methods"},{"location":"docker_objects/networks/#reload","text":"Network.reload()","title":"reload"},{"location":"docker_objects/networks/#remove","text":"Network.remove() Removes this Docker network. Rather than removing it manually, you can use a context manager to make sure the network is deleted even if an exception is raised. from python_on_whales import docker with docker.network.create(\"some_name\") as my_net: docker.run( \"busybox\", [\"ping\", \"idonotexistatall.com\"], networks=[my_net], remove=True, ) # an exception will be raised because the container will fail # but the network will be removed anyway.","title":"remove"},{"location":"docker_objects/nodes/","text":"Docker nodes Nodes in Docker swarm Don't use the constructor directly. Instead use from python_on_whales import docker my_docker_image = docker.node.inspect(\"my-node-name\") list_of_nodes = docker.node.list() For type hints, use this from python_on_whales import Node def print_state(node: Node): print(node.status.state) Attributes It attributes are the same that you get with the command line: docker node inspect ... To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: docker.swarm.init() In [3]: docker.node.list()[0] In [4]: def super_print(obj): ...: print(f\"type = {type(obj)}, value = {obj}\") ...: In [4]: super_print(node.id) type = <class 'str'>, value = syiims74sy2iwe6jnhpphyvbs In [5]: super_print(node.version.index) type = <class 'int'>, value = 9 In [6]: super_print(node.created_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:26.796073+00:00 In [7]: super_print(node.updated_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:27.399908+00:00 In [8]: super_print(node.spec.name) type = <class 'NoneType'>, value = None In [9]: super_print(node.spec.labels) type = <class 'dict'>, value = {} In [10]: super_print(node.spec.role) type = <class 'str'>, value = manager In [11]: super_print(node.spec.availability) type = <class 'str'>, value = active In [12]: super_print(node.description.hostname) type = <class 'str'>, value = fv-az212-119 In [13]: super_print(node.description.platform.architecture) type = <class 'str'>, value = x86_64 In [14]: super_print(node.description.platform.os) type = <class 'str'>, value = linux In [15]: super_print(node.description.resources.nano_cpus) type = <class 'int'>, value = 2000000000 In [16]: super_print(node.description.resources.memory_bytes) type = <class 'int'>, value = 7284850688 In [17]: super_print(node.description.resources.generic_resources) type = <class 'NoneType'>, value = None In [18]: super_print(node.description.engine.engine_version) type = <class 'str'>, value = 20.10.11+azure-3 In [19]: super_print(node.description.engine.labels) type = <class 'NoneType'>, value = None In [20]: super_print(node.description.engine.plugins) type = <class 'list'>, value = [EnginePlugin(type='Log', name='awslogs'), EnginePlugin(type='Log', name='fluentd'), EnginePlugin(type='Log', name='gcplogs'), EnginePlugin(type='Log', name='gelf'), EnginePlugin(type='Log', name='journald'), EnginePlugin(type='Log', name='json-file'), EnginePlugin(type='Log', name='local'), EnginePlugin(type='Log', name='logentries'), EnginePlugin(type='Log', name='splunk'), EnginePlugin(type='Log', name='syslog'), EnginePlugin(type='Network', name='bridge'), EnginePlugin(type='Network', name='host'), EnginePlugin(type='Network', name='ipvlan'), EnginePlugin(type='Network', name='macvlan'), EnginePlugin(type='Network', name='null'), EnginePlugin(type='Network', name='overlay'), EnginePlugin(type='Volume', name='local'), EnginePlugin(type='Volume', name='mochoa/s3fs-volume-plugin:latest')] In [21]: super_print(node.description.tls_info.trust_root) type = <class 'str'>, value = -----BEGIN CERTIFICATE----- MIIBazCCARCgAwIBAgIUM3Wq6gaoKYnr9uv/N/wVlwOGtBUwCgYIKoZIzj0EAwIw EzERMA8GA1UEAxMIc3dhcm0tY2EwHhcNMjIwMjEyMTQ1MjAwWhcNNDIwMjA3MTQ1 MjAwWjATMREwDwYDVQQDEwhzd2FybS1jYTBZMBMGByqGSM49AgEGCCqGSM49AwEH A0IABBiqrUASzROHVMAmC8y/gs/kzFlq23gYCSmFBobplSPVXonb+QJ1oBEnMMeO t+zNai5z6lwVZBrssIADcKK+DaSjQjBAMA4GA1UdDwEB/wQEAwIBBjAPBgNVHRMB Af8EBTADAQH/MB0GA1UdDgQWBBQql6OmA+ANFNLlTdEwsxqSxTua5zAKBggqhkjO PQQDAgNJADBGAiEA0QXJBZo/5Sa6/bmZEhTHPc3VWABHMxH1DF+jiI3Hw7UCIQCw gPnXMPzRLF/Nw96d/623gw8gsoJdtUfIXhBEr2ipWQ== -----END CERTIFICATE----- In [22]: super_print(node.description.tls_info.cert_issuer_subject) type = <class 'str'>, value = MBMxETAPBgNVBAMTCHN3YXJtLWNh In [23]: super_print(node.description.tls_info.cert_issuer_public_key) type = <class 'str'>, value = MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEGKqtQBLNE4dUwCYLzL+Cz+TMWWrbeBgJKYUGhumVI9Veidv5AnWgEScwx4637M1qLnPqXBVkGuywgANwor4NpA== In [24]: super_print(node.status.state) type = <class 'str'>, value = ready In [25]: super_print(node.status.message) type = <class 'NoneType'>, value = None In [26]: super_print(node.status.addr) type = <class 'str'>, value = 10.1.0.131 In [27]: super_print(node.manager_status.leader) type = <class 'bool'>, value = True In [28]: super_print(node.manager_status.reachability) type = <class 'str'>, value = reachable In [29]: super_print(node.manager_status.addr) type = <class 'str'>, value = 10.1.0.131:2377 Methods ps Node.ps() Returns the list of tasks running on this node Returns A List[python_on_whales.Task] object. reload Node.reload() update Node.update(availability=None, labels_add={}, rm_labels=[], role=None) Updates this Swarm node. See docker.node.update for more information about the arguments.","title":"Nodes"},{"location":"docker_objects/nodes/#docker-nodes","text":"Nodes in Docker swarm Don't use the constructor directly. Instead use from python_on_whales import docker my_docker_image = docker.node.inspect(\"my-node-name\") list_of_nodes = docker.node.list() For type hints, use this from python_on_whales import Node def print_state(node: Node): print(node.status.state)","title":"Docker nodes"},{"location":"docker_objects/nodes/#attributes","text":"It attributes are the same that you get with the command line: docker node inspect ... To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: docker.swarm.init() In [3]: docker.node.list()[0] In [4]: def super_print(obj): ...: print(f\"type = {type(obj)}, value = {obj}\") ...: In [4]: super_print(node.id) type = <class 'str'>, value = syiims74sy2iwe6jnhpphyvbs In [5]: super_print(node.version.index) type = <class 'int'>, value = 9 In [6]: super_print(node.created_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:26.796073+00:00 In [7]: super_print(node.updated_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:27.399908+00:00 In [8]: super_print(node.spec.name) type = <class 'NoneType'>, value = None In [9]: super_print(node.spec.labels) type = <class 'dict'>, value = {} In [10]: super_print(node.spec.role) type = <class 'str'>, value = manager In [11]: super_print(node.spec.availability) type = <class 'str'>, value = active In [12]: super_print(node.description.hostname) type = <class 'str'>, value = fv-az212-119 In [13]: super_print(node.description.platform.architecture) type = <class 'str'>, value = x86_64 In [14]: super_print(node.description.platform.os) type = <class 'str'>, value = linux In [15]: super_print(node.description.resources.nano_cpus) type = <class 'int'>, value = 2000000000 In [16]: super_print(node.description.resources.memory_bytes) type = <class 'int'>, value = 7284850688 In [17]: super_print(node.description.resources.generic_resources) type = <class 'NoneType'>, value = None In [18]: super_print(node.description.engine.engine_version) type = <class 'str'>, value = 20.10.11+azure-3 In [19]: super_print(node.description.engine.labels) type = <class 'NoneType'>, value = None In [20]: super_print(node.description.engine.plugins) type = <class 'list'>, value = [EnginePlugin(type='Log', name='awslogs'), EnginePlugin(type='Log', name='fluentd'), EnginePlugin(type='Log', name='gcplogs'), EnginePlugin(type='Log', name='gelf'), EnginePlugin(type='Log', name='journald'), EnginePlugin(type='Log', name='json-file'), EnginePlugin(type='Log', name='local'), EnginePlugin(type='Log', name='logentries'), EnginePlugin(type='Log', name='splunk'), EnginePlugin(type='Log', name='syslog'), EnginePlugin(type='Network', name='bridge'), EnginePlugin(type='Network', name='host'), EnginePlugin(type='Network', name='ipvlan'), EnginePlugin(type='Network', name='macvlan'), EnginePlugin(type='Network', name='null'), EnginePlugin(type='Network', name='overlay'), EnginePlugin(type='Volume', name='local'), EnginePlugin(type='Volume', name='mochoa/s3fs-volume-plugin:latest')] In [21]: super_print(node.description.tls_info.trust_root) type = <class 'str'>, value = -----BEGIN CERTIFICATE----- MIIBazCCARCgAwIBAgIUM3Wq6gaoKYnr9uv/N/wVlwOGtBUwCgYIKoZIzj0EAwIw EzERMA8GA1UEAxMIc3dhcm0tY2EwHhcNMjIwMjEyMTQ1MjAwWhcNNDIwMjA3MTQ1 MjAwWjATMREwDwYDVQQDEwhzd2FybS1jYTBZMBMGByqGSM49AgEGCCqGSM49AwEH A0IABBiqrUASzROHVMAmC8y/gs/kzFlq23gYCSmFBobplSPVXonb+QJ1oBEnMMeO t+zNai5z6lwVZBrssIADcKK+DaSjQjBAMA4GA1UdDwEB/wQEAwIBBjAPBgNVHRMB Af8EBTADAQH/MB0GA1UdDgQWBBQql6OmA+ANFNLlTdEwsxqSxTua5zAKBggqhkjO PQQDAgNJADBGAiEA0QXJBZo/5Sa6/bmZEhTHPc3VWABHMxH1DF+jiI3Hw7UCIQCw gPnXMPzRLF/Nw96d/623gw8gsoJdtUfIXhBEr2ipWQ== -----END CERTIFICATE----- In [22]: super_print(node.description.tls_info.cert_issuer_subject) type = <class 'str'>, value = MBMxETAPBgNVBAMTCHN3YXJtLWNh In [23]: super_print(node.description.tls_info.cert_issuer_public_key) type = <class 'str'>, value = MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEGKqtQBLNE4dUwCYLzL+Cz+TMWWrbeBgJKYUGhumVI9Veidv5AnWgEScwx4637M1qLnPqXBVkGuywgANwor4NpA== In [24]: super_print(node.status.state) type = <class 'str'>, value = ready In [25]: super_print(node.status.message) type = <class 'NoneType'>, value = None In [26]: super_print(node.status.addr) type = <class 'str'>, value = 10.1.0.131 In [27]: super_print(node.manager_status.leader) type = <class 'bool'>, value = True In [28]: super_print(node.manager_status.reachability) type = <class 'str'>, value = reachable In [29]: super_print(node.manager_status.addr) type = <class 'str'>, value = 10.1.0.131:2377","title":"Attributes"},{"location":"docker_objects/nodes/#methods","text":"","title":"Methods"},{"location":"docker_objects/nodes/#ps","text":"Node.ps() Returns the list of tasks running on this node Returns A List[python_on_whales.Task] object.","title":"ps"},{"location":"docker_objects/nodes/#reload","text":"Node.reload()","title":"reload"},{"location":"docker_objects/nodes/#update","text":"Node.update(availability=None, labels_add={}, rm_labels=[], role=None) Updates this Swarm node. See docker.node.update for more information about the arguments.","title":"update"},{"location":"docker_objects/plugins/","text":"Docker plugins Don't use the constructor directly. Instead use from python_on_whales import docker my_docker_plugin = docker.plugin.install(\"vieux/sshfs:latest\") # or my_docker_plugin = docker.plugin.inspect(\"vieux/sshfs:latest\") # or list_of_plugins = docker.plugins.list() For type hints, use this from python_on_whales import Plugin def print_name(plugin: Plugin): print(plugin.name) Attributes It attributes are the same that you get with the command line: docker plugin inspect ... To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: plugin = docker.plugin.install(\"vieux/sshfs:latest\") In [4]: def super_print(obj): ...: print(f\"type = {type(obj)}, value = {obj}\") ...: In [4]: super_print(plugin.id) type = <class 'str'>, value = 260251058eb5d4d73b43ad763c9755cd73e976b4031d791acf02cf51d63be295 In [5]: super_print(plugin.name) type = <class 'str'>, value = mochoa/s3fs-volume-plugin:latest In [6]: super_print(plugin.enabled) type = <class 'bool'>, value = True In [7]: super_print(plugin.settings) type = <class 'python_on_whales.components.plugin.models.PluginSettings'>, value = mounts=[] env=['AWSACCESSKEYID=', 'AWSSECRETACCESSKEY=', 'DEFAULT_S3FSOPTS=nomultipart,use_path_request_style'] args=[] devices=[PluginDevice()] In [8]: super_print(plugin.plugin_reference) type = <class 'str'>, value = docker.io/mochoa/s3fs-volume-plugin:latest In [9]: super_print(plugin.config) type = <class 'python_on_whales.components.plugin.models.PluginConfig'>, value = docker_version='19.03.15' description='S3FS plugin for Docker v2.0.9' documentation='https://github.com/marcelo-ochoa/docker-volume-plugins/' interface=Interface() entrypoint=['/usr/bin/tini', '--', '/s3fs-volume-plugin'] work_dir='' Methods disable Plugin.disable(force=False) Disable this plugin enable Plugin.enable(timeout=None) Enable this plugin push Plugin.push(disable_content_trust=True) Push this plugin reload Plugin.reload() remove Plugin.remove(force=False) Remove this plugin set Plugin.set(configuration) Set the configuration for this plugin upgrade Plugin.upgrade(remote=None, disable_content_trust=True, skip_remote_check=False) Upgrade this plugin","title":"Plugins"},{"location":"docker_objects/plugins/#docker-plugins","text":"Don't use the constructor directly. Instead use from python_on_whales import docker my_docker_plugin = docker.plugin.install(\"vieux/sshfs:latest\") # or my_docker_plugin = docker.plugin.inspect(\"vieux/sshfs:latest\") # or list_of_plugins = docker.plugins.list() For type hints, use this from python_on_whales import Plugin def print_name(plugin: Plugin): print(plugin.name)","title":"Docker plugins"},{"location":"docker_objects/plugins/#attributes","text":"It attributes are the same that you get with the command line: docker plugin inspect ... To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: plugin = docker.plugin.install(\"vieux/sshfs:latest\") In [4]: def super_print(obj): ...: print(f\"type = {type(obj)}, value = {obj}\") ...: In [4]: super_print(plugin.id) type = <class 'str'>, value = 260251058eb5d4d73b43ad763c9755cd73e976b4031d791acf02cf51d63be295 In [5]: super_print(plugin.name) type = <class 'str'>, value = mochoa/s3fs-volume-plugin:latest In [6]: super_print(plugin.enabled) type = <class 'bool'>, value = True In [7]: super_print(plugin.settings) type = <class 'python_on_whales.components.plugin.models.PluginSettings'>, value = mounts=[] env=['AWSACCESSKEYID=', 'AWSSECRETACCESSKEY=', 'DEFAULT_S3FSOPTS=nomultipart,use_path_request_style'] args=[] devices=[PluginDevice()] In [8]: super_print(plugin.plugin_reference) type = <class 'str'>, value = docker.io/mochoa/s3fs-volume-plugin:latest In [9]: super_print(plugin.config) type = <class 'python_on_whales.components.plugin.models.PluginConfig'>, value = docker_version='19.03.15' description='S3FS plugin for Docker v2.0.9' documentation='https://github.com/marcelo-ochoa/docker-volume-plugins/' interface=Interface() entrypoint=['/usr/bin/tini', '--', '/s3fs-volume-plugin'] work_dir=''","title":"Attributes"},{"location":"docker_objects/plugins/#methods","text":"","title":"Methods"},{"location":"docker_objects/plugins/#disable","text":"Plugin.disable(force=False) Disable this plugin","title":"disable"},{"location":"docker_objects/plugins/#enable","text":"Plugin.enable(timeout=None) Enable this plugin","title":"enable"},{"location":"docker_objects/plugins/#push","text":"Plugin.push(disable_content_trust=True) Push this plugin","title":"push"},{"location":"docker_objects/plugins/#reload","text":"Plugin.reload()","title":"reload"},{"location":"docker_objects/plugins/#remove","text":"Plugin.remove(force=False) Remove this plugin","title":"remove"},{"location":"docker_objects/plugins/#set","text":"Plugin.set(configuration) Set the configuration for this plugin","title":"set"},{"location":"docker_objects/plugins/#upgrade","text":"Plugin.upgrade(remote=None, disable_content_trust=True, skip_remote_check=False) Upgrade this plugin","title":"upgrade"},{"location":"docker_objects/secrets/","text":"reload Secret.reload() remove Secret.remove() Remove this Docker secret. See the docker.secret.remove command for information about the arguments.","title":"Secrets"},{"location":"docker_objects/secrets/#reload","text":"Secret.reload()","title":"reload"},{"location":"docker_objects/secrets/#remove","text":"Secret.remove() Remove this Docker secret. See the docker.secret.remove command for information about the arguments.","title":"remove"},{"location":"docker_objects/services/","text":"Docker services Services in Docker swarm Don't use the constructor directly. Instead use from python_on_whales import docker my_docker_service = docker.service.inspect(\"my-service\") my_docker_service = docker.service.create(\"busybox\", [\"ping\", \"www.google.com\"]) For type hints, use this from python_on_whales import Service def print_creation_time(some_service: Service): print(some_service.created_at) Attributes It attributes are the same that you get with the command line: docker service inspect ... To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: docker.swarm.init() In [3]: my_service = docker.service.create(\"busybox\", [\"ping\", \"www.google.com\"]) In [4]: def super_print(obj): ...: print(f\"type = {type(obj)}, value = {obj}\") ...: In [4]: super_print(service.id) type = <class 'str'>, value = fxcbppq7yn34cfji7sam6ia2z In [5]: super_print(service.version) type = <class 'python_on_whales.components.service.models.ServiceVersion'>, value = index=11 In [6]: super_print(service.created_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:29.213886+00:00 In [7]: super_print(service.updated_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:29.213886+00:00 In [8]: super_print(service.spec.name) type = <class 'str'>, value = cranky_moore In [9]: super_print(service.spec.labels) type = <class 'dict'>, value = {} In [10]: super_print(service.spec.mode) type = <class 'dict'>, value = {'Replicated': {'Replicas': 1}} In [11]: super_print(service.spec.update_config) type = <class 'python_on_whales.components.service.models.ChangeConfig'>, value = parallelism=1 failure_action='pause' monitor=5000000000 max_failure_ratio=0 order='stop-first' In [12]: super_print(service.spec.rollback_config) type = <class 'python_on_whales.components.service.models.ChangeConfig'>, value = parallelism=1 failure_action='pause' monitor=5000000000 max_failure_ratio=0 order='stop-first' In [13]: super_print(service.spec.task_template.container_spec.image) type = <class 'str'>, value = busybox:latest@sha256:afcc7f1ac1b49db317a7196c902e61c6c3c4607d63599ee1a82d702d249a0ccb In [14]: super_print(service.spec.task_template.container_spec.labels) type = <class 'NoneType'>, value = None In [15]: super_print(service.spec.task_template.container_spec.privileges) type = <class 'NoneType'>, value = None In [16]: super_print(service.spec.task_template.container_spec.stop_grace_period) type = <class 'int'>, value = 10000000000 In [17]: super_print(service.spec.task_template.container_spec.isolation) type = <class 'str'>, value = default In [18]: super_print(service.spec.task_template.container_spec.env) type = <class 'NoneType'>, value = None In [19]: super_print(service.spec.task_template.resources.limits) type = <class 'python_on_whales.components.service.models.CPUMemoryQuotas'>, value = nano_cpus=None memory_bytes=None In [20]: super_print(service.spec.task_template.resources.reservations) type = <class 'python_on_whales.components.service.models.CPUMemoryQuotas'>, value = nano_cpus=None memory_bytes=None In [21]: super_print(service.previous_spec) type = <class 'NoneType'>, value = None In [22]: super_print(service.endpoint.spec) type = <class 'python_on_whales.components.service.models.ServiceEndpointSpec'>, value = mode=None ports=None In [23]: super_print(service.endpoint.ports) type = <class 'NoneType'>, value = None In [24]: super_print(service.endpoint.virtual_ips) type = <class 'NoneType'>, value = None In [25]: super_print(service.update_status) type = <class 'NoneType'>, value = None Methods exists Service.exists() Returns True if the service is still present in the swarm, False if the service has been removed. ps Service.ps() Returns the list of tasks of this service. reload Service.reload() remove Service.remove() Removes this service It's also possible to use a service as a context manager. By using a context manager, you ensures that the service will be removed even if an exception occurs. from python_on_whales import docker docker.swarm.init() with docker.service.create(\"ubuntu\", [\"sleep\", \"infinity\"]) as my_service: print(\"I'm doing things with the service here\") print(my_service.update_status) print(\"I'm out of the context manager, the service has been removed.\") scale Service.scale(new_scale, detach=False) Change the scale of a service. See the docker.service.scale command for information about the arguments. update Service.update(detach=False, force=False, image=None, with_registry_authentication=False) Updates a service See the docker.service.update command for information about the arguments.","title":"Services"},{"location":"docker_objects/services/#docker-services","text":"Services in Docker swarm Don't use the constructor directly. Instead use from python_on_whales import docker my_docker_service = docker.service.inspect(\"my-service\") my_docker_service = docker.service.create(\"busybox\", [\"ping\", \"www.google.com\"]) For type hints, use this from python_on_whales import Service def print_creation_time(some_service: Service): print(some_service.created_at)","title":"Docker services"},{"location":"docker_objects/services/#attributes","text":"It attributes are the same that you get with the command line: docker service inspect ... To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: docker.swarm.init() In [3]: my_service = docker.service.create(\"busybox\", [\"ping\", \"www.google.com\"]) In [4]: def super_print(obj): ...: print(f\"type = {type(obj)}, value = {obj}\") ...: In [4]: super_print(service.id) type = <class 'str'>, value = fxcbppq7yn34cfji7sam6ia2z In [5]: super_print(service.version) type = <class 'python_on_whales.components.service.models.ServiceVersion'>, value = index=11 In [6]: super_print(service.created_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:29.213886+00:00 In [7]: super_print(service.updated_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:29.213886+00:00 In [8]: super_print(service.spec.name) type = <class 'str'>, value = cranky_moore In [9]: super_print(service.spec.labels) type = <class 'dict'>, value = {} In [10]: super_print(service.spec.mode) type = <class 'dict'>, value = {'Replicated': {'Replicas': 1}} In [11]: super_print(service.spec.update_config) type = <class 'python_on_whales.components.service.models.ChangeConfig'>, value = parallelism=1 failure_action='pause' monitor=5000000000 max_failure_ratio=0 order='stop-first' In [12]: super_print(service.spec.rollback_config) type = <class 'python_on_whales.components.service.models.ChangeConfig'>, value = parallelism=1 failure_action='pause' monitor=5000000000 max_failure_ratio=0 order='stop-first' In [13]: super_print(service.spec.task_template.container_spec.image) type = <class 'str'>, value = busybox:latest@sha256:afcc7f1ac1b49db317a7196c902e61c6c3c4607d63599ee1a82d702d249a0ccb In [14]: super_print(service.spec.task_template.container_spec.labels) type = <class 'NoneType'>, value = None In [15]: super_print(service.spec.task_template.container_spec.privileges) type = <class 'NoneType'>, value = None In [16]: super_print(service.spec.task_template.container_spec.stop_grace_period) type = <class 'int'>, value = 10000000000 In [17]: super_print(service.spec.task_template.container_spec.isolation) type = <class 'str'>, value = default In [18]: super_print(service.spec.task_template.container_spec.env) type = <class 'NoneType'>, value = None In [19]: super_print(service.spec.task_template.resources.limits) type = <class 'python_on_whales.components.service.models.CPUMemoryQuotas'>, value = nano_cpus=None memory_bytes=None In [20]: super_print(service.spec.task_template.resources.reservations) type = <class 'python_on_whales.components.service.models.CPUMemoryQuotas'>, value = nano_cpus=None memory_bytes=None In [21]: super_print(service.previous_spec) type = <class 'NoneType'>, value = None In [22]: super_print(service.endpoint.spec) type = <class 'python_on_whales.components.service.models.ServiceEndpointSpec'>, value = mode=None ports=None In [23]: super_print(service.endpoint.ports) type = <class 'NoneType'>, value = None In [24]: super_print(service.endpoint.virtual_ips) type = <class 'NoneType'>, value = None In [25]: super_print(service.update_status) type = <class 'NoneType'>, value = None","title":"Attributes"},{"location":"docker_objects/services/#methods","text":"","title":"Methods"},{"location":"docker_objects/services/#exists","text":"Service.exists() Returns True if the service is still present in the swarm, False if the service has been removed.","title":"exists"},{"location":"docker_objects/services/#ps","text":"Service.ps() Returns the list of tasks of this service.","title":"ps"},{"location":"docker_objects/services/#reload","text":"Service.reload()","title":"reload"},{"location":"docker_objects/services/#remove","text":"Service.remove() Removes this service It's also possible to use a service as a context manager. By using a context manager, you ensures that the service will be removed even if an exception occurs. from python_on_whales import docker docker.swarm.init() with docker.service.create(\"ubuntu\", [\"sleep\", \"infinity\"]) as my_service: print(\"I'm doing things with the service here\") print(my_service.update_status) print(\"I'm out of the context manager, the service has been removed.\")","title":"remove"},{"location":"docker_objects/services/#scale","text":"Service.scale(new_scale, detach=False) Change the scale of a service. See the docker.service.scale command for information about the arguments.","title":"scale"},{"location":"docker_objects/services/#update","text":"Service.update(detach=False, force=False, image=None, with_registry_authentication=False) Updates a service See the docker.service.update command for information about the arguments.","title":"update"},{"location":"docker_objects/stacks/","text":"ps Stack.ps() remove Stack.remove() services Stack.services()","title":"Stacks"},{"location":"docker_objects/stacks/#ps","text":"Stack.ps()","title":"ps"},{"location":"docker_objects/stacks/#remove","text":"Stack.remove()","title":"remove"},{"location":"docker_objects/stacks/#services","text":"Stack.services()","title":"services"},{"location":"docker_objects/tasks/","text":"Docker tasks Tasks in Docker swarm Don't use the constructor directly. Instead use from python_on_whales import docker my_docker_task = docker.task.inspect(\"some-task-id\") my_tasks_list = docker.service.ps(\"my-service\") For type hints, use this from python_on_whales import Task def print_creation_time(some_task: Task): print(some_task.created_at) Attributes It attributes are the same that you get with the command line: docker inspect <task-id> To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\".","title":"Tasks"},{"location":"docker_objects/tasks/#docker-tasks","text":"Tasks in Docker swarm Don't use the constructor directly. Instead use from python_on_whales import docker my_docker_task = docker.task.inspect(\"some-task-id\") my_tasks_list = docker.service.ps(\"my-service\") For type hints, use this from python_on_whales import Task def print_creation_time(some_task: Task): print(some_task.created_at)","title":"Docker tasks"},{"location":"docker_objects/tasks/#attributes","text":"It attributes are the same that you get with the command line: docker inspect <task-id> To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\".","title":"Attributes"},{"location":"docker_objects/volumes/","text":"Docker volumes Don't use the constructor directly. Instead use from python_on_whales import docker my_docker_volume = docker.volume.inspect(\"my-volume\") # or my_docker_image = docker.volume.create() For type hints, use this from python_on_whales import docker, Volume def print_file(my_volume: Volume): print( docker.run( \"ubuntu\", [\"cat\", \"/some_volume/some_file\"], volumes=[(my_volume, \"/some_volume/some_file\")] ) ) Attributes It attributes are the same that you get with the command line: docker volume inspect ... To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: volume = docker.volume.create() In [3]: def super_print(obj): ...: print(f\"type={type(obj)}, value={obj}\") ...: In [4]: super_print(volume.name) type = <class 'str'>, value = d2a0f7ae3414389d8f328847ae61f4848b241bf9182573c94ef4de3886487ee5 In [5]: super_print(volume.driver) type = <class 'str'>, value = local In [6]: super_print(volume.mountpoint) type = <class 'pathlib.PosixPath'>, value = /var/lib/docker/volumes/d2a0f7ae3414389d8f328847ae61f4848b241bf9182573c94ef4de3886487ee5/_data In [7]: super_print(volume.created_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:15+00:00 In [8]: super_print(volume.status) type = <class 'NoneType'>, value = None In [9]: super_print(volume.labels) type = <class 'dict'>, value = {} In [10]: super_print(volume.scope) type = <class 'str'>, value = local In [11]: super_print(volume.options) type = <class 'dict'>, value = {} Methods clone Volume.clone(new_volume_name=None, driver=None, labels={}, options={}) Creates a new volume and copy all the data inside. See the docker.volume.clone command for information about the arguments. exists Volume.exists() Returns True if the docker volume exists and False if it doesn't exists. If it doesn't exists, it most likely mean that it was removed. See the docker.volume.exists command for information about the arguments. reload Volume.reload() remove Volume.remove() Removes this volume","title":"Volumes"},{"location":"docker_objects/volumes/#docker-volumes","text":"Don't use the constructor directly. Instead use from python_on_whales import docker my_docker_volume = docker.volume.inspect(\"my-volume\") # or my_docker_image = docker.volume.create() For type hints, use this from python_on_whales import docker, Volume def print_file(my_volume: Volume): print( docker.run( \"ubuntu\", [\"cat\", \"/some_volume/some_file\"], volumes=[(my_volume, \"/some_volume/some_file\")] ) )","title":"Docker volumes"},{"location":"docker_objects/volumes/#attributes","text":"It attributes are the same that you get with the command line: docker volume inspect ... To get a complete description of those attributes, you can take a look at the daemon api reference page and click on \"200 No error\". An example is worth many lines of descriptions. In [1]: from python_on_whales import docker In [2]: volume = docker.volume.create() In [3]: def super_print(obj): ...: print(f\"type={type(obj)}, value={obj}\") ...: In [4]: super_print(volume.name) type = <class 'str'>, value = d2a0f7ae3414389d8f328847ae61f4848b241bf9182573c94ef4de3886487ee5 In [5]: super_print(volume.driver) type = <class 'str'>, value = local In [6]: super_print(volume.mountpoint) type = <class 'pathlib.PosixPath'>, value = /var/lib/docker/volumes/d2a0f7ae3414389d8f328847ae61f4848b241bf9182573c94ef4de3886487ee5/_data In [7]: super_print(volume.created_at) type = <class 'datetime.datetime'>, value = 2022-02-12 14:57:15+00:00 In [8]: super_print(volume.status) type = <class 'NoneType'>, value = None In [9]: super_print(volume.labels) type = <class 'dict'>, value = {} In [10]: super_print(volume.scope) type = <class 'str'>, value = local In [11]: super_print(volume.options) type = <class 'dict'>, value = {}","title":"Attributes"},{"location":"docker_objects/volumes/#methods","text":"","title":"Methods"},{"location":"docker_objects/volumes/#clone","text":"Volume.clone(new_volume_name=None, driver=None, labels={}, options={}) Creates a new volume and copy all the data inside. See the docker.volume.clone command for information about the arguments.","title":"clone"},{"location":"docker_objects/volumes/#exists","text":"Volume.exists() Returns True if the docker volume exists and False if it doesn't exists. If it doesn't exists, it most likely mean that it was removed. See the docker.volume.exists command for information about the arguments.","title":"exists"},{"location":"docker_objects/volumes/#reload","text":"Volume.reload()","title":"reload"},{"location":"docker_objects/volumes/#remove","text":"Volume.remove() Removes this volume","title":"remove"},{"location":"sub-commands/buildx/","text":"bake docker.buildx.bake( targets=[], builder=None, files=[], load=False, cache=True, print=False, progress=\"auto\", pull=False, push=False, set={}, variables={}, stream_logs=False, ) Bake is similar to make, it allows you to build things declared in a file. For example it allows you to build multiple docker image in parallel. The CLI docs is here and it contains a lot more information. Arguments targets Union[str, List[str]] : Targets or groups of targets to build. builder Optional[Union[str, python_on_whales.Builder]] : The builder to use. files Union[str, pathlib.Path, List[Union[str, pathlib.Path]]] : Build definition file(s) load bool : Shorthand for set=[\"*.output=type=docker\"] cache bool : Whether to use the cache or not. print bool : Do nothing, just returns the config. progress Union[str, bool] : Set type of progress output ( \"auto\" , \"plain\" , \"tty\" , or False ). Use plain to keep the container output on screen pull bool : Always try to pull the newer version of the image push bool : Shorthand for set=[\"*.output=type=registry\"] set Dict[str, str] : A list of overrides in the form \"targetpattern.key=value\" . variables Dict[str, str] : A dict containing the values of the variables defined in the hcl file. See https://github.com/docker/buildx#hcl-variables-and-functions Returns The configuration used for the bake (files merged + override with the arguments used in the function). It's the loaded json you would obtain by running docker buildx bake --print --load my_target if your command was docker buildx bake --load my_target . Some example here. from python_on_whales import docker # returns the config used and runs the builds config = docker.buildx.bake([\"my_target1\", \"my_target2\"], load=True) assert config == { \"target\": { \"my_target1\": { \"context\": \"./\", \"dockerfile\": \"Dockerfile\", \"tags\": [\"pretty_image1:1.0.0\"], \"target\": \"out1\", \"output\": [\"type=docker\"] }, \"my_target2\": { \"context\": \"./\", \"dockerfile\": \"Dockerfile\", \"tags\": [\"pretty_image2:1.0.0\"], \"target\": \"out2\", \"output\": [\"type=docker\"] } } } # returns the config only, doesn't run the builds config = docker.buildx.bake([\"my_target1\", \"my_target2\"], load=True, print=True) build docker.buildx.build( context_path, add_hosts={}, allow=[], build_args={}, builder=None, cache=True, cache_from=None, cache_to=None, file=None, labels={}, load=False, network=None, output={}, platforms=None, progress=\"auto\", pull=False, push=False, secrets=[], ssh=None, tags=[], target=None, stream_logs=False, ) Build a Docker image with builkit as backend. Alias: docker.build(...) A python_on_whales.Image is returned, even when using multiple tags. That is because it will produce a single image with multiple tags. If no image is loaded into the Docker daemon (if push=True for ex), then None is returned. Arguments context_path Union[str, pathlib.Path] : The path of the build context. add_hosts Dict[str, str] : Hosts to add. add_hosts={\"my_host1\": \"192.168.32.35\"} allow List[str] : List of extra privileges. Eg allow=[\"network.host\", \"security.insecure\"] build_args Dict[str, str] : The build arguments. ex build_args={\"PY_VERSION\": \"3.7.8\", \"UBUNTU_VERSION\": \"20.04\"} . builder Optional[Union[str, python_on_whales.Builder]] : Specify which builder to use. cache bool : Whether or not to use the cache cache_from Optional[Union[str, Dict[str, str], List[Dict[str, str]]]] : Works only with the container driver. Loads the cache (if needed) from a registry cache_from=\"user/app:cache\" or a directory on the client cache_from=\"type=local,src=path/to/dir\" . It's also possible to use a dict or list of dict form for this argument. e.g. cache_from=dict(type=\"local\", src=\"path/to/dir\") cache_to Optional[Union[str, Dict[str, str]]] : Works only with the container driver. Sends the resulting docker cache either to a registry cache_to=\"user/app:cache\" , or to a local directory cache_to=\"type=local,dest=path/to/dir\" . It's also possible to use a dict form for this argument. e.g. cache_to=dict(type=\"local\", dest=\"path/to/dir\", mode=\"max\") file Optional[Union[str, pathlib.Path]] : The path of the Dockerfile labels Dict[str, str] : Dict of labels to add to the image. labels={\"very-secure\": \"1\", \"needs-gpu\": \"0\"} for example. load bool : Shortcut for output=dict(type=\"docker\") If True , docker.buildx.build will return a python_on_whales.Image . network Optional[str] : which network to use when building the Docker image output Dict[str, str] : Output destination (format: output={\"type\": \"local\", \"dest\": \"path\"} Possible output types are [\"local\", \"tar\", \"oci\", \"docker\", \"image\", \"registry\"] . See this link for more details about each exporter. platforms Optional[List[str]] : List of target platforms when building the image. Ex: platforms=[\"linux/amd64\", \"linux/arm64\"] progress Union[str, bool] : Set type of progress output (auto, plain, tty, or False). Use plain to keep the container output on screen pull bool : Always attempt to pull a newer version of the image push bool : Shorthand for output=dict(type=\"registry\") . secrets Union[str, List[str]] : One or more secrets passed as string(s). For example secrets=\"id=aws,src=/home/my_user/.aws/credentials\" ssh Optional[str] : SSH agent socket or keys to expose to the build (format is default|<id>[=<socket>|<key>[,<key>]] as a string) tags Union[str, List[str]] : Tag or tags to put on the resulting image. target Optional[str] : Set the target build stage to build. stream_logs bool : If True this function will return an iterator of strings. You can then read the logs as they arrive. Returns A python_on_whales.Image if a Docker image is loaded in the daemon after the build (the default behavior when calling docker.build(...) ). Otherwise, None . create docker.buildx.create( context_or_endpoint=None, buildkitd_flags=None, config=None, driver=None, driver_options={}, name=None, use=False, ) Create a new builder instance Arguments context_or_endpoint Optional[str] : buildkitd_flags Optional[str] : Flags for buildkitd daemon config Optional[Union[str, pathlib.Path]] : BuildKit config file driver Optional[str] : Driver to use (available: [kubernetes docker docker-container]) driver_options Dict[str, str] : Options for the driver. e.g driver_options=dict(network=\"host\") name Optional[str] : Builder instance name use bool : Set the current builder instance to this builder Returns A python_on_whales.Builder object. disk_usage docker.buildx.disk_usage() Not yet implemented inspect docker.buildx.inspect(x=None) Returns a builder instance from the name. Arguments x Optional[str] : If None (the default), returns the current builder. If a string is provided, the builder that has this name is returned. Returns A python_on_whales.Builder object. is_installed docker.buildx.is_installed() Returns True if docker buildx is installed and working. If it's not installed, head to the installation page and follow the instructions. list docker.buildx.list() Returns the list of python_on_whales.Builder available. prune docker.buildx.prune(all=False, filters={}) Remove build cache on the current builder. Arguments all bool : Remove all cache, not just dangling layers filters Dict[str, str] : Filters to use, for example filters=dict(until=\"24h\") remove docker.buildx.remove(builder) Remove a builder Arguments builder Union[python_on_whales.Builder, str] : The builder to remove stop docker.buildx.stop(builder) Stop the builder instance Arguments: builder: The builder to stop. If None (the default value), the current builder is stopped. use docker.buildx.use(builder, default=False, global_=False) Set the current builder instance Arguments builder Union[python_on_whales.Builder, str] : The builder to use default bool : Set builder as default for the current context __global___ bool : Builder will be used even when changing contexts version docker.buildx.version() Returns the docker buildx version as a string. from python_on_whales import docker version = docker.buildx.version() print(version) # \"github.com/docker/buildx v0.4.2 fb7b670b764764dc4716df3eba07ffdae4cc47b2\" inspect docker.buildx.imagetools.inspect(name) Returns the manifest of a Docker image in a registry without pulling it","title":"docker buildx"},{"location":"sub-commands/buildx/#bake","text":"docker.buildx.bake( targets=[], builder=None, files=[], load=False, cache=True, print=False, progress=\"auto\", pull=False, push=False, set={}, variables={}, stream_logs=False, ) Bake is similar to make, it allows you to build things declared in a file. For example it allows you to build multiple docker image in parallel. The CLI docs is here and it contains a lot more information. Arguments targets Union[str, List[str]] : Targets or groups of targets to build. builder Optional[Union[str, python_on_whales.Builder]] : The builder to use. files Union[str, pathlib.Path, List[Union[str, pathlib.Path]]] : Build definition file(s) load bool : Shorthand for set=[\"*.output=type=docker\"] cache bool : Whether to use the cache or not. print bool : Do nothing, just returns the config. progress Union[str, bool] : Set type of progress output ( \"auto\" , \"plain\" , \"tty\" , or False ). Use plain to keep the container output on screen pull bool : Always try to pull the newer version of the image push bool : Shorthand for set=[\"*.output=type=registry\"] set Dict[str, str] : A list of overrides in the form \"targetpattern.key=value\" . variables Dict[str, str] : A dict containing the values of the variables defined in the hcl file. See https://github.com/docker/buildx#hcl-variables-and-functions Returns The configuration used for the bake (files merged + override with the arguments used in the function). It's the loaded json you would obtain by running docker buildx bake --print --load my_target if your command was docker buildx bake --load my_target . Some example here. from python_on_whales import docker # returns the config used and runs the builds config = docker.buildx.bake([\"my_target1\", \"my_target2\"], load=True) assert config == { \"target\": { \"my_target1\": { \"context\": \"./\", \"dockerfile\": \"Dockerfile\", \"tags\": [\"pretty_image1:1.0.0\"], \"target\": \"out1\", \"output\": [\"type=docker\"] }, \"my_target2\": { \"context\": \"./\", \"dockerfile\": \"Dockerfile\", \"tags\": [\"pretty_image2:1.0.0\"], \"target\": \"out2\", \"output\": [\"type=docker\"] } } } # returns the config only, doesn't run the builds config = docker.buildx.bake([\"my_target1\", \"my_target2\"], load=True, print=True)","title":"bake"},{"location":"sub-commands/buildx/#build","text":"docker.buildx.build( context_path, add_hosts={}, allow=[], build_args={}, builder=None, cache=True, cache_from=None, cache_to=None, file=None, labels={}, load=False, network=None, output={}, platforms=None, progress=\"auto\", pull=False, push=False, secrets=[], ssh=None, tags=[], target=None, stream_logs=False, ) Build a Docker image with builkit as backend. Alias: docker.build(...) A python_on_whales.Image is returned, even when using multiple tags. That is because it will produce a single image with multiple tags. If no image is loaded into the Docker daemon (if push=True for ex), then None is returned. Arguments context_path Union[str, pathlib.Path] : The path of the build context. add_hosts Dict[str, str] : Hosts to add. add_hosts={\"my_host1\": \"192.168.32.35\"} allow List[str] : List of extra privileges. Eg allow=[\"network.host\", \"security.insecure\"] build_args Dict[str, str] : The build arguments. ex build_args={\"PY_VERSION\": \"3.7.8\", \"UBUNTU_VERSION\": \"20.04\"} . builder Optional[Union[str, python_on_whales.Builder]] : Specify which builder to use. cache bool : Whether or not to use the cache cache_from Optional[Union[str, Dict[str, str], List[Dict[str, str]]]] : Works only with the container driver. Loads the cache (if needed) from a registry cache_from=\"user/app:cache\" or a directory on the client cache_from=\"type=local,src=path/to/dir\" . It's also possible to use a dict or list of dict form for this argument. e.g. cache_from=dict(type=\"local\", src=\"path/to/dir\") cache_to Optional[Union[str, Dict[str, str]]] : Works only with the container driver. Sends the resulting docker cache either to a registry cache_to=\"user/app:cache\" , or to a local directory cache_to=\"type=local,dest=path/to/dir\" . It's also possible to use a dict form for this argument. e.g. cache_to=dict(type=\"local\", dest=\"path/to/dir\", mode=\"max\") file Optional[Union[str, pathlib.Path]] : The path of the Dockerfile labels Dict[str, str] : Dict of labels to add to the image. labels={\"very-secure\": \"1\", \"needs-gpu\": \"0\"} for example. load bool : Shortcut for output=dict(type=\"docker\") If True , docker.buildx.build will return a python_on_whales.Image . network Optional[str] : which network to use when building the Docker image output Dict[str, str] : Output destination (format: output={\"type\": \"local\", \"dest\": \"path\"} Possible output types are [\"local\", \"tar\", \"oci\", \"docker\", \"image\", \"registry\"] . See this link for more details about each exporter. platforms Optional[List[str]] : List of target platforms when building the image. Ex: platforms=[\"linux/amd64\", \"linux/arm64\"] progress Union[str, bool] : Set type of progress output (auto, plain, tty, or False). Use plain to keep the container output on screen pull bool : Always attempt to pull a newer version of the image push bool : Shorthand for output=dict(type=\"registry\") . secrets Union[str, List[str]] : One or more secrets passed as string(s). For example secrets=\"id=aws,src=/home/my_user/.aws/credentials\" ssh Optional[str] : SSH agent socket or keys to expose to the build (format is default|<id>[=<socket>|<key>[,<key>]] as a string) tags Union[str, List[str]] : Tag or tags to put on the resulting image. target Optional[str] : Set the target build stage to build. stream_logs bool : If True this function will return an iterator of strings. You can then read the logs as they arrive. Returns A python_on_whales.Image if a Docker image is loaded in the daemon after the build (the default behavior when calling docker.build(...) ). Otherwise, None .","title":"build"},{"location":"sub-commands/buildx/#create","text":"docker.buildx.create( context_or_endpoint=None, buildkitd_flags=None, config=None, driver=None, driver_options={}, name=None, use=False, ) Create a new builder instance Arguments context_or_endpoint Optional[str] : buildkitd_flags Optional[str] : Flags for buildkitd daemon config Optional[Union[str, pathlib.Path]] : BuildKit config file driver Optional[str] : Driver to use (available: [kubernetes docker docker-container]) driver_options Dict[str, str] : Options for the driver. e.g driver_options=dict(network=\"host\") name Optional[str] : Builder instance name use bool : Set the current builder instance to this builder Returns A python_on_whales.Builder object.","title":"create"},{"location":"sub-commands/buildx/#disk_usage","text":"docker.buildx.disk_usage() Not yet implemented","title":"disk_usage"},{"location":"sub-commands/buildx/#inspect","text":"docker.buildx.inspect(x=None) Returns a builder instance from the name. Arguments x Optional[str] : If None (the default), returns the current builder. If a string is provided, the builder that has this name is returned. Returns A python_on_whales.Builder object.","title":"inspect"},{"location":"sub-commands/buildx/#is_installed","text":"docker.buildx.is_installed() Returns True if docker buildx is installed and working. If it's not installed, head to the installation page and follow the instructions.","title":"is_installed"},{"location":"sub-commands/buildx/#list","text":"docker.buildx.list() Returns the list of python_on_whales.Builder available.","title":"list"},{"location":"sub-commands/buildx/#prune","text":"docker.buildx.prune(all=False, filters={}) Remove build cache on the current builder. Arguments all bool : Remove all cache, not just dangling layers filters Dict[str, str] : Filters to use, for example filters=dict(until=\"24h\")","title":"prune"},{"location":"sub-commands/buildx/#remove","text":"docker.buildx.remove(builder) Remove a builder Arguments builder Union[python_on_whales.Builder, str] : The builder to remove","title":"remove"},{"location":"sub-commands/buildx/#stop","text":"docker.buildx.stop(builder) Stop the builder instance Arguments: builder: The builder to stop. If None (the default value), the current builder is stopped.","title":"stop"},{"location":"sub-commands/buildx/#use","text":"docker.buildx.use(builder, default=False, global_=False) Set the current builder instance Arguments builder Union[python_on_whales.Builder, str] : The builder to use default bool : Set builder as default for the current context __global___ bool : Builder will be used even when changing contexts","title":"use"},{"location":"sub-commands/buildx/#version","text":"docker.buildx.version() Returns the docker buildx version as a string. from python_on_whales import docker version = docker.buildx.version() print(version) # \"github.com/docker/buildx v0.4.2 fb7b670b764764dc4716df3eba07ffdae4cc47b2\"","title":"version"},{"location":"sub-commands/buildx/#inspect_1","text":"docker.buildx.imagetools.inspect(name) Returns the manifest of a Docker image in a registry without pulling it","title":"inspect"},{"location":"sub-commands/compose/","text":"Some notes about the compose functions Behind the scenes, the Go implementation of Docker compose is called a.k.a. Compose v2, not the Python implementation . You can verify that docker compose is installed by running docker compose --help Be careful! it's different from docker-compose --help ! Notice the - between 'docker' and 'compose'. Compose v2 has no - in the command. If that doesn't work, then install the cli plugin . it's just a single binary to download. The Go implementation of compose is still experimental, so take the appropriate precautions. If you don't need to set any project-wide options, like the project name or the compose file path, you can just import docker and start working. from python_on_whales import docker docker.compose.build() docker.compose.up() ... docker.compose.down() Otherwise, you have to define your project-wide options only once, when creating the Docker client. from python_on_whales import DockerClient docker = DockerClient(compose_files=[\"./my-compose-file.yml\"]) docker.compose.build() docker.compose.up() ... docker.compose.down() You have multiple compose options available (like profiles, env_files, project name) when creating the Docker client. You can check them out in the DockerClient documentation . About docker.compose.images() . The Docker command line has a docker compose images command. Python-on-whales doesn't have an equivalent because it's trivial to do so with existing functions. images = [docker.image.inspect(container.image) for container in docker.container.ps()] docker.container.ps() returns the list of all containers in the compose stack. container.image gives you the id of the Docker image of the container as a str . docker.image.inspect() gives you a python_on_whales.Image from a str . build docker.compose.build(services=[]) Build services declared in a yaml compose file. Arguments services List[str] : The services to build (as strings). If empty (default), all services are built. config docker.compose.config(return_json=False) Returns the configuration of the compose stack for further inspection. For example from python_on_whales import docker project_config = docker.compose.config() print(project_config.services[\"my_first_service\"].image) \"redis\" Arguments return_json bool : If False , a ComposeConfig object will be returned, and you 'll be able to take advantage of your IDE autocompletion. If you want the full json output, you may use return_json . In this case, you'll get lists and dicts corresponding to the json response, unmodified. It may be useful if you just want to print the config or want to access a field that was not in the ComposeConfig class. Returns A ComposeConfig object if return_json is False , and a dict otherwise. create docker.compose.create(services=[], build=False, force_recreate=False, no_build=False, no_recreate=False) Creates containers for a service. Arguments build bool : Build images before starting containers. force_recreate bool : Recreate containers even if their configuration and image haven't changed. no_build bool : Don't build an image, even if it's missing. no_recreate : If containers already exist, don't recreate them. Incompatible with force_recreate=True . down docker.compose.down(remove_orphans=False, remove_images=None, timeout=None, volumes=False) Stops and removes the containers Arguments remove_orphans bool : Remove containers for services not defined in the Compose file. remove_images Optional[str] : Remove images used by services. \"local\" remove only images that don't have a custom tag. Possible values are \"local\" and \"all\" . timeout Optional[int] : Specify a shutdown timeout in seconds (default 10). volumes bool : Remove named volumes declared in the volumes section of the Compose file and anonymous volumes attached to containers. events docker.compose.events() Not yet implemented exec docker.compose.exec() Not yet implemented is_installed docker.compose.is_installed() Returns True if docker compose (the one written in Go) is installed and working. kill docker.compose.kill(services=[], signal=None) Kills the container(s) of a service Arguments services Union[str, List[str]] : One or more service(s) to kill signal Optional[str] : the signal to send to the container. Default is \"SIGKILL\" logs docker.compose.logs( services=[], tail=None, follow=False, no_log_prefix=False, timestamps=False, since=None, until=None, stream=False, ) View output from containers Arguments services Union[str, List[str]] : One or more service(s) to view tail Optional[str] : Number of lines to show from the end of the logs for each container. (default \"all\") follow bool : Follow log output WARNING : With this option, docker.compose.logs() will not return at all. Use it exclusively with stream=True . You can loop on the logs but the loop will never end. no_log_prefix : Don't print prefix in logs timestamps bool : Show timestamps since Optional[str] : Show logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes) until Optional[str] : Show logs before a timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes) stream bool : Similar to the stream argument of docker.run() . This function will then returns and iterator that will yield a tuple (source, content) with source being \"stderr\" or \"stdout\" . content is the content of the line as bytes. Take a look at the user guide to have an example of the output. Returns str if stream=False (the default), Iterable[Tuple[str, bytes]] if stream=True . pause docker.compose.pause(services=[]) Pause one or more services port docker.compose.port() Not yet implemented ps docker.compose.ps() Returns the containers that were created by the current project. Returns A List[python_on_whales.Container] pull docker.compose.pull(services=[]) Pull service images Arguments services List[str] : The list of services to select. Only the images of those services will be pulled. If no services are specified (the default behavior) all images of all services are pulled. push docker.compose.push(services=[]) Push service images Arguments services List[str] : The list of services to select. Only the images of those services will be pushed. If no services are specified (the default behavior) all images of all services are pushed. restart docker.compose.restart(services=[], timeout=None) Restart containers Arguments services Union[str, List[str]] : The names of one or more services to restart (str or list of str) timeout Optional[Union[int, datetime.timedelta]] : The shutdown timeout ( int are interpreted as seconds). None means the CLI default value (10s). See the docker stop docs for more details about this argument. rm docker.compose.rm(services=[], stop=False, volumes=False) Removes stopped service containers By default, anonymous volumes attached to containers will not be removed. You can override this with volumes=True . Any data which is not in a volume will be lost. Arguments services Union[str, List[str]] : The names of one or more services to remove (str or list of str) stop bool : Stop the containers, if required, before removing volumes bool : Remove any anonymous volumes attached to containers run docker.compose.run( service, command=[], detach=False, name=None, tty=True, stream=False, dependencies=True, publish=[], remove=False, service_ports=False, use_aliases=False, user=None, workdir=None, ) Run a one-off command on a service. Arguments service str : The name of the service. command List[str] : The command to execute. detach bool : if True , returns immediately with the Container. If False , returns the command stdout as string. name Optional[str] : Assign a name to the container. dependencies bool : Also start linked services. publish List[Union[Tuple[Union[str, int], Union[str, int]], Tuple[Union[str, int], Union[str, int], str]]] : Publish a container's port(s) to the host. service_ports bool : Enable service's ports and map them to the host. remove bool : Automatically remove the container when it exits. use_aliases bool : Use the service's network aliases in the connected network(s). tty bool : Allocate a pseudo-TTY. Allow the process to access your terminal to write on it. stream bool : Similar to docker.run(..., stream=True) . user Optional[str] : Username or UID, format: \"<name|uid>[:<group|gid>]\" workdir Optional[Union[str, pathlib.Path]] : Working directory inside the container Returns: Optional[str] start docker.compose.start(services=[]) Start the specified services. Arguments services Union[str, List[str]] : The names of one or more services to start stop docker.compose.stop(services=[], timeout=None) Stop services Arguments services Union[str, List[str]] : The names of one or more services to stop (str or list of str) timeout Optional[Union[int, datetime.timedelta]] : Number of seconds or timedelta (will be converted to seconds). Specify a shutdown timeout. Default is 10s. top docker.compose.top() Not yet implemented unpause docker.compose.unpause(services=[]) Unpause one or more services up docker.compose.up( services=[], build=False, detach=False, abort_on_container_exit=False, scales={}, attach_dependencies=False, force_recreate=False, no_build=False, color=True, log_prefix=True, start=True, ) Start the containers. Reading the logs of the containers is not yet implemented. Arguments services List[str] : The services to start. If empty (default), all services are started. build bool : If True , build the docker images before starting the containers even if a docker image with this name already exists. If False (the default), build only the docker images that do not already exist. detach bool : If True , run the containers in the background. If False this function returns only when all containers have stopped. Incompatible with abort_on_container_exit=True . abort_on_container_exit bool : If True stops all containers if any container was stopped. Incompatible with detach=True . scales Dict[str, int] : Scale SERVICE to NUM instances. Overrides the scale setting in the Compose file if present. For example: scales={\"my_service\": 2, \"my_other_service\": 5} . attach_dependencies bool : Attach to dependent containers. force_recreate bool : Recreate containers even if their configuration and image haven't changed. no_build bool : Don't build an image, even if it's missing. color bool : If False , it will produce monochrome output. log_prefix bool : If False , will not display the prefix in the logs. start bool : Start the service after creating them. Returns None at the moment. The plan is to be able to capture and stream the logs later. It's not yet implemented. version docker.compose.version() Returns the version of docker compose as a str .","title":"docker compose"},{"location":"sub-commands/compose/#some-notes-about-the-compose-functions","text":"Behind the scenes, the Go implementation of Docker compose is called a.k.a. Compose v2, not the Python implementation . You can verify that docker compose is installed by running docker compose --help Be careful! it's different from docker-compose --help ! Notice the - between 'docker' and 'compose'. Compose v2 has no - in the command. If that doesn't work, then install the cli plugin . it's just a single binary to download. The Go implementation of compose is still experimental, so take the appropriate precautions. If you don't need to set any project-wide options, like the project name or the compose file path, you can just import docker and start working. from python_on_whales import docker docker.compose.build() docker.compose.up() ... docker.compose.down() Otherwise, you have to define your project-wide options only once, when creating the Docker client. from python_on_whales import DockerClient docker = DockerClient(compose_files=[\"./my-compose-file.yml\"]) docker.compose.build() docker.compose.up() ... docker.compose.down() You have multiple compose options available (like profiles, env_files, project name) when creating the Docker client. You can check them out in the DockerClient documentation .","title":"Some notes about the compose functions"},{"location":"sub-commands/compose/#about-dockercomposeimages","text":"The Docker command line has a docker compose images command. Python-on-whales doesn't have an equivalent because it's trivial to do so with existing functions. images = [docker.image.inspect(container.image) for container in docker.container.ps()] docker.container.ps() returns the list of all containers in the compose stack. container.image gives you the id of the Docker image of the container as a str . docker.image.inspect() gives you a python_on_whales.Image from a str .","title":"About docker.compose.images()."},{"location":"sub-commands/compose/#build","text":"docker.compose.build(services=[]) Build services declared in a yaml compose file. Arguments services List[str] : The services to build (as strings). If empty (default), all services are built.","title":"build"},{"location":"sub-commands/compose/#config","text":"docker.compose.config(return_json=False) Returns the configuration of the compose stack for further inspection. For example from python_on_whales import docker project_config = docker.compose.config() print(project_config.services[\"my_first_service\"].image) \"redis\" Arguments return_json bool : If False , a ComposeConfig object will be returned, and you 'll be able to take advantage of your IDE autocompletion. If you want the full json output, you may use return_json . In this case, you'll get lists and dicts corresponding to the json response, unmodified. It may be useful if you just want to print the config or want to access a field that was not in the ComposeConfig class. Returns A ComposeConfig object if return_json is False , and a dict otherwise.","title":"config"},{"location":"sub-commands/compose/#create","text":"docker.compose.create(services=[], build=False, force_recreate=False, no_build=False, no_recreate=False) Creates containers for a service. Arguments build bool : Build images before starting containers. force_recreate bool : Recreate containers even if their configuration and image haven't changed. no_build bool : Don't build an image, even if it's missing. no_recreate : If containers already exist, don't recreate them. Incompatible with force_recreate=True .","title":"create"},{"location":"sub-commands/compose/#down","text":"docker.compose.down(remove_orphans=False, remove_images=None, timeout=None, volumes=False) Stops and removes the containers Arguments remove_orphans bool : Remove containers for services not defined in the Compose file. remove_images Optional[str] : Remove images used by services. \"local\" remove only images that don't have a custom tag. Possible values are \"local\" and \"all\" . timeout Optional[int] : Specify a shutdown timeout in seconds (default 10). volumes bool : Remove named volumes declared in the volumes section of the Compose file and anonymous volumes attached to containers.","title":"down"},{"location":"sub-commands/compose/#events","text":"docker.compose.events() Not yet implemented","title":"events"},{"location":"sub-commands/compose/#exec","text":"docker.compose.exec() Not yet implemented","title":"exec"},{"location":"sub-commands/compose/#is_installed","text":"docker.compose.is_installed() Returns True if docker compose (the one written in Go) is installed and working.","title":"is_installed"},{"location":"sub-commands/compose/#kill","text":"docker.compose.kill(services=[], signal=None) Kills the container(s) of a service Arguments services Union[str, List[str]] : One or more service(s) to kill signal Optional[str] : the signal to send to the container. Default is \"SIGKILL\"","title":"kill"},{"location":"sub-commands/compose/#logs","text":"docker.compose.logs( services=[], tail=None, follow=False, no_log_prefix=False, timestamps=False, since=None, until=None, stream=False, ) View output from containers Arguments services Union[str, List[str]] : One or more service(s) to view tail Optional[str] : Number of lines to show from the end of the logs for each container. (default \"all\") follow bool : Follow log output WARNING : With this option, docker.compose.logs() will not return at all. Use it exclusively with stream=True . You can loop on the logs but the loop will never end. no_log_prefix : Don't print prefix in logs timestamps bool : Show timestamps since Optional[str] : Show logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes) until Optional[str] : Show logs before a timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes) stream bool : Similar to the stream argument of docker.run() . This function will then returns and iterator that will yield a tuple (source, content) with source being \"stderr\" or \"stdout\" . content is the content of the line as bytes. Take a look at the user guide to have an example of the output. Returns str if stream=False (the default), Iterable[Tuple[str, bytes]] if stream=True .","title":"logs"},{"location":"sub-commands/compose/#pause","text":"docker.compose.pause(services=[]) Pause one or more services","title":"pause"},{"location":"sub-commands/compose/#port","text":"docker.compose.port() Not yet implemented","title":"port"},{"location":"sub-commands/compose/#ps","text":"docker.compose.ps() Returns the containers that were created by the current project. Returns A List[python_on_whales.Container]","title":"ps"},{"location":"sub-commands/compose/#pull","text":"docker.compose.pull(services=[]) Pull service images Arguments services List[str] : The list of services to select. Only the images of those services will be pulled. If no services are specified (the default behavior) all images of all services are pulled.","title":"pull"},{"location":"sub-commands/compose/#push","text":"docker.compose.push(services=[]) Push service images Arguments services List[str] : The list of services to select. Only the images of those services will be pushed. If no services are specified (the default behavior) all images of all services are pushed.","title":"push"},{"location":"sub-commands/compose/#restart","text":"docker.compose.restart(services=[], timeout=None) Restart containers Arguments services Union[str, List[str]] : The names of one or more services to restart (str or list of str) timeout Optional[Union[int, datetime.timedelta]] : The shutdown timeout ( int are interpreted as seconds). None means the CLI default value (10s). See the docker stop docs for more details about this argument.","title":"restart"},{"location":"sub-commands/compose/#rm","text":"docker.compose.rm(services=[], stop=False, volumes=False) Removes stopped service containers By default, anonymous volumes attached to containers will not be removed. You can override this with volumes=True . Any data which is not in a volume will be lost. Arguments services Union[str, List[str]] : The names of one or more services to remove (str or list of str) stop bool : Stop the containers, if required, before removing volumes bool : Remove any anonymous volumes attached to containers","title":"rm"},{"location":"sub-commands/compose/#run","text":"docker.compose.run( service, command=[], detach=False, name=None, tty=True, stream=False, dependencies=True, publish=[], remove=False, service_ports=False, use_aliases=False, user=None, workdir=None, ) Run a one-off command on a service. Arguments service str : The name of the service. command List[str] : The command to execute. detach bool : if True , returns immediately with the Container. If False , returns the command stdout as string. name Optional[str] : Assign a name to the container. dependencies bool : Also start linked services. publish List[Union[Tuple[Union[str, int], Union[str, int]], Tuple[Union[str, int], Union[str, int], str]]] : Publish a container's port(s) to the host. service_ports bool : Enable service's ports and map them to the host. remove bool : Automatically remove the container when it exits. use_aliases bool : Use the service's network aliases in the connected network(s). tty bool : Allocate a pseudo-TTY. Allow the process to access your terminal to write on it. stream bool : Similar to docker.run(..., stream=True) . user Optional[str] : Username or UID, format: \"<name|uid>[:<group|gid>]\" workdir Optional[Union[str, pathlib.Path]] : Working directory inside the container Returns: Optional[str]","title":"run"},{"location":"sub-commands/compose/#start","text":"docker.compose.start(services=[]) Start the specified services. Arguments services Union[str, List[str]] : The names of one or more services to start","title":"start"},{"location":"sub-commands/compose/#stop","text":"docker.compose.stop(services=[], timeout=None) Stop services Arguments services Union[str, List[str]] : The names of one or more services to stop (str or list of str) timeout Optional[Union[int, datetime.timedelta]] : Number of seconds or timedelta (will be converted to seconds). Specify a shutdown timeout. Default is 10s.","title":"stop"},{"location":"sub-commands/compose/#top","text":"docker.compose.top() Not yet implemented","title":"top"},{"location":"sub-commands/compose/#unpause","text":"docker.compose.unpause(services=[]) Unpause one or more services","title":"unpause"},{"location":"sub-commands/compose/#up","text":"docker.compose.up( services=[], build=False, detach=False, abort_on_container_exit=False, scales={}, attach_dependencies=False, force_recreate=False, no_build=False, color=True, log_prefix=True, start=True, ) Start the containers. Reading the logs of the containers is not yet implemented. Arguments services List[str] : The services to start. If empty (default), all services are started. build bool : If True , build the docker images before starting the containers even if a docker image with this name already exists. If False (the default), build only the docker images that do not already exist. detach bool : If True , run the containers in the background. If False this function returns only when all containers have stopped. Incompatible with abort_on_container_exit=True . abort_on_container_exit bool : If True stops all containers if any container was stopped. Incompatible with detach=True . scales Dict[str, int] : Scale SERVICE to NUM instances. Overrides the scale setting in the Compose file if present. For example: scales={\"my_service\": 2, \"my_other_service\": 5} . attach_dependencies bool : Attach to dependent containers. force_recreate bool : Recreate containers even if their configuration and image haven't changed. no_build bool : Don't build an image, even if it's missing. color bool : If False , it will produce monochrome output. log_prefix bool : If False , will not display the prefix in the logs. start bool : Start the service after creating them. Returns None at the moment. The plan is to be able to capture and stream the logs later. It's not yet implemented.","title":"up"},{"location":"sub-commands/compose/#version","text":"docker.compose.version() Returns the version of docker compose as a str .","title":"version"},{"location":"sub-commands/config/","text":"create docker.config.create(name, file, labels={}, template_driver=None) Create a config from a file See the docker docs for more information about swarm configs. Arguments name str : The config name. file Union[str, pathlib.Path] : Tbe file to be used as config. labels Dict[str, str] : The labels to add to the config template_driver Optional[str] : The template driver Returns A python_on_whales.Config object. inspect docker.config.inspect(x) Returns a python_on_whales.Config object based on its name or id. Argument x: An id or name or a list of ids/names. Returns A python_on_whales.Config if a string was passed as argument. A List[python_on_whales.Config] if a list of strings was passed as argument. list docker.config.list(filters={}) List all config available in the swarm. Arguments filters Dict[str, str] : If you want to filter the results based on a given condition. For example, docker.config.list(filters=dict(label=\"my_label=hello\")) . Returns A List[python_on_whales.Config] . remove docker.config.remove(x) Remove one or more configs. Arguments x Union[python_on_whales.Config, str, List[Union[python_on_whales.Config, str]]] : One or a list of configs. Valid values are the id of the config or a python_on_whales.Config object.","title":"docker config"},{"location":"sub-commands/config/#create","text":"docker.config.create(name, file, labels={}, template_driver=None) Create a config from a file See the docker docs for more information about swarm configs. Arguments name str : The config name. file Union[str, pathlib.Path] : Tbe file to be used as config. labels Dict[str, str] : The labels to add to the config template_driver Optional[str] : The template driver Returns A python_on_whales.Config object.","title":"create"},{"location":"sub-commands/config/#inspect","text":"docker.config.inspect(x) Returns a python_on_whales.Config object based on its name or id. Argument x: An id or name or a list of ids/names. Returns A python_on_whales.Config if a string was passed as argument. A List[python_on_whales.Config] if a list of strings was passed as argument.","title":"inspect"},{"location":"sub-commands/config/#list","text":"docker.config.list(filters={}) List all config available in the swarm. Arguments filters Dict[str, str] : If you want to filter the results based on a given condition. For example, docker.config.list(filters=dict(label=\"my_label=hello\")) . Returns A List[python_on_whales.Config] .","title":"list"},{"location":"sub-commands/config/#remove","text":"docker.config.remove(x) Remove one or more configs. Arguments x Union[python_on_whales.Config, str, List[Union[python_on_whales.Config, str]]] : One or a list of configs. Valid values are the id of the config or a python_on_whales.Config object.","title":"remove"},{"location":"sub-commands/container/","text":"attach docker.container.attach() Not yet implemented commit docker.container.commit(container, tag=None, author=None, message=None, pause=True) Create a new image from a container's changes Arguments container Union[python_on_whales.Container, str] : The container to create the image from tag Optional[str] : tag to apply on the image produced author Optional[str] : Author (e.g., \"John Hannibal Smith hannibal@a-team.com \") message Optional[str] : Commit message pause bool : Pause container during commit copy docker.container.copy(source, destination) Copy files/folders between a container and the local filesystem Alias: docker.copy(...) from python_on_whales import docker docker.run(\"ubuntu\", [\"sleep\", \"infinity\"], name=\"dodo\", remove=True, detach=True) docker.copy(\"/tmp/my_local_file.txt\", (\"dodo\", \"/path/in/container.txt\")) docker.copy((\"dodo\", \"/path/in/container.txt\"), \"/tmp/my_local_file2.txt\") Doesn't yet support sending or receiving iterators of Python bytes. Arguments source Union[str, pathlib.Path, Tuple[Union[python_on_whales.Container, str], Union[str, pathlib.Path]]] : Local path or tuple. When using a tuple, the first element of the tuple is the container, the second element is the path in the container. ex: source=(\"my-container\", \"/usr/bin/something\") . destination Union[str, pathlib.Path, Tuple[Union[python_on_whales.Container, str], Union[str, pathlib.Path]]] : Local path or tuple. When using a tuple, the first element of the tuple is the container, the second element is the path in the container. ex: source=(\"my-container\", \"/usr/bin/something\") . create docker.container.create( image, command=[], *, add_hosts=[], blkio_weight=None, blkio_weight_device=[], cap_add=[], cap_drop=[], cgroup_parent=None, cidfile=None, cpu_period=None, cpu_quota=None, cpu_rt_period=None, cpu_rt_runtime=None, cpu_shares=None, cpus=None, cpuset_cpus=None, cpuset_mems=None, detach=False, devices=[], device_cgroup_rules=[], device_read_bps=[], device_read_iops=[], device_write_bps=[], device_write_iops=[], content_trust=False, dns=[], dns_options=[], dns_search=[], domainname=None, entrypoint=None, envs={}, env_files=[], expose=[], gpus=None, groups_add=[], healthcheck=True, health_cmd=None, health_interval=None, health_retries=None, health_start_period=None, health_timeout=None, hostname=None, init=False, ip=None, ip6=None, ipc=None, isolation=None, kernel_memory=None, labels={}, label_files=[], link=[], link_local_ip=[], log_driver=None, log_options=[], mac_address=None, memory=None, memory_reservation=None, memory_swap=None, memory_swappiness=None, mounts=[], name=None, networks=[], network_aliases=[], oom_kill=True, oom_score_adj=None, pid=None, pids_limit=None, platform=None, privileged=False, publish=[], publish_all=False, read_only=False, restart=None, remove=False, runtime=None, security_options=[], shm_size=None, sig_proxy=True, stop_signal=None, stop_timeout=None, storage_options=[], sysctl={}, tmpfs=[], ulimit=[], user=None, userns=None, uts=None, volumes=[], volume_driver=None, volumes_from=[], workdir=None ) Creates a container, but does not start it. Alias: docker.create(...) Start it then with the .start() method. It might be useful if you want to delay the start of a container, to do some preparations beforehand. For example, it's common to do this workflow: docker create -> docker cp -> docker start to put files in the container before starting. There is no detach argument since it's a runtime option. The arguments are the same as docker.run . diff docker.container.diff(container) List all the files modified, added or deleted since the container started. Alias: docker.diff(...) Arguments container Union[python_on_whales.Container, str] : The container to inspect Returns Dict[str, str] Something like {\"/some_path\": \"A\", \"/some_file\": \"M\", \"/tmp\": \"D\"} for example. execute docker.container.execute( container, command, detach=False, envs={}, env_files=[], interactive=False, privileged=False, tty=False, user=None, workdir=None, stream=False, ) Execute a command inside a container Alias: docker.execute(...) Arguments container Union[python_on_whales.Container, str] : The container to execute the command in. command Union[str, List[str]] : The command to execute. detach bool : if True , returns immediately with None . If False , returns the command stdout as string. envs Dict[str, str] : Set environment variables env_files Union[str, pathlib.Path, List[Union[str, pathlib.Path]]] : Read one or more files of environment variables interactive bool : Leave stdin open during the duration of the process to allow communication with the parent process. Currently only works with tty=True for interactive use on the terminal. privileged bool : Give extended privileges to the container. tty bool : Allocate a pseudo-TTY. Allow the process to access your terminal to write on it. user Optional[str] : Username or UID, format: \"<name|uid>[:<group|gid>]\" workdir Optional[Union[str, pathlib.Path]] : Working directory inside the container stream bool : Similar to docker.run(..., stream=True) . Returns: Optional[str] Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. exists docker.container.exists(x) Returns True if the container exists. False otherwise. It's just calling docker.container.inspect(...) and verifies that it doesn't throw a python_on_whales.exceptions.NoSuchContainer . Returns A bool export docker.container.export(container, output) Export a container's filesystem as a tar archive Alias: docker.export(...) Arguments container Union[python_on_whales.Container, str] : The container to export. output Union[str, pathlib.Path] : The path of the output tar archive. Returning a generator of bytes is not yet implemented. Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. inspect docker.container.inspect(x) Returns a container object from a name or ID. Arguments reference : A container name or ID, or a list of container names and/or IDs Returns: A python_on_whales.Container object or a list of those if a list of IDs was passed as input. Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. kill docker.container.kill(containers, signal=None) Kill a container. Alias: docker.kill(...) Arguments containers Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or more containers to kill signal Optional[str] : The signal to send the container Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. list docker.container.list(all=False, filters={}) List the containers on the host. Alias: docker.ps(...) Arguments all bool : If True , also returns containers that are not running. Returns A List[python_on_whales.Container] logs docker.container.logs( container, details=False, since=None, tail=None, timestamps=False, until=None, follow=False, stream=False ) Returns the logs of a container as a string or an iterator. Alias: docker.logs(...) Arguments container Union[python_on_whales.Container, str] : The container to get the logs of details bool : Show extra details provided to logs since Union[None, datetime.datetime, datetime.timedelta] : Use a datetime or timedelta to specify the lower date limit for the logs. tail Optional[int] : Number of lines to show from the end of the logs (default all) timestamps bool : Put timestamps next to lines. until Union[None, datetime.datetime, datetime.timedelta] : Use a datetime or a timedelta to specify the upper date limit for the logs. follow bool : If False (the default), the logs returned are the logs up to the time of the function call. If True , the logs of the container up to the time the container stopped are displayed. Which means that if the container isn't stopped yet, the function will continue until the container is stopped. Which is why it is advised to use the stream option if you use the follow option. Without stream , only a str will be returned, possibly much later in the future. With stream , you'll be able to read the logs in real time. stream bool : Similar to the stream argument of docker.run . This function will then returns and iterator that will yield a tuple (source, content) with source being \"stderr\" or \"stdout\" . content is the content of the line as bytes. Take a look at the user guide to have an example of the output. Returns str if stream=False (the default), Iterable[Tuple[str, bytes]] if stream=True . Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. If you are a bit confused about follow and stream , here are some use cases. If you want to have the logs up to this point as a str , don't use those args. If you want to stream the output in real time, use follow=True, stream=True If you want the logs up to this point but you don't want to fit all the logs in memory because they are too big, use stream=True . pause docker.container.pause(containers) Pauses one or more containers Alias: docker.pause(...) Arguments containers Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or more containers to pause Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. prune docker.container.prune(filters=[]) Remove containers that are not running. Arguments filters Union[str, List[str]] : Filters as strings or list of strings remove docker.container.remove(containers, force=False, volumes=False) Removes a container Alias: docker.remove(...) Arguments containers Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or more containers. force bool : Force the removal of a running container (uses SIGKILL) volumes bool : Remove anonymous volumes associated with the container Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. rename docker.container.rename(container, new_name) Changes the name of a container. Alias: docker.rename(...) Arguments container Union[python_on_whales.Container, str] : The container to rename new_name str : The new name of the container. Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. restart docker.container.restart(containers, time=None) Restarts one or more container. Alias: docker.restart(...) Arguments containers Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or more containers to restart time Optional[Union[int, datetime.timedelta]] : Amount of to wait for stop before killing the container (default 10s). If int , the unit is seconds. Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. run docker.container.run( image, command=[], *, add_hosts=[], blkio_weight=None, blkio_weight_device=[], cap_add=[], cap_drop=[], cgroup_parent=None, cidfile=None, cpu_period=None, cpu_quota=None, cpu_rt_period=None, cpu_rt_runtime=None, cpu_shares=None, cpus=None, cpuset_cpus=None, cpuset_mems=None, detach=False, devices=[], device_cgroup_rules=[], device_read_bps=[], device_read_iops=[], device_write_bps=[], device_write_iops=[], content_trust=False, dns=[], dns_options=[], dns_search=[], domainname=None, entrypoint=None, envs={}, env_files=[], expose=[], gpus=None, groups_add=[], healthcheck=True, health_cmd=None, health_interval=None, health_retries=None, health_start_period=None, health_timeout=None, hostname=None, init=False, interactive=False, ip=None, ip6=None, ipc=None, isolation=None, kernel_memory=None, labels={}, label_files=[], link=[], link_local_ip=[], log_driver=None, log_options=[], mac_address=None, memory=None, memory_reservation=None, memory_swap=None, memory_swappiness=None, mounts=[], name=None, networks=[], network_aliases=[], oom_kill=True, oom_score_adj=None, pid=None, pids_limit=None, platform=None, privileged=False, publish=[], publish_all=False, read_only=False, restart=None, remove=False, runtime=None, security_options=[], shm_size=None, sig_proxy=True, stop_signal=None, stop_timeout=None, storage_options=[], stream=False, sysctl={}, tmpfs=[], tty=False, ulimit=[], user=None, userns=None, uts=None, volumes=[], volume_driver=None, volumes_from=[], workdir=None ) Runs a container You can use docker.run or docker.container.run to call this function. For a deeper dive into the arguments and what they do, visit https://docs.docker.com/engine/reference/run/ If you want to know exactly how to call docker.run() depending on your use case (detach, stream...), take a look at the docker.run() guide . >>> from python_on_whales import docker >>> returned_string = docker.run(\"hello-world\") >>> print(returned_string) Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ >>> from python_on_whales import docker >>> result_string = docker.run(\"ubuntu\", [\"ls\", \"/host\"], volumes=[(\"/\", \"/host\", \"ro\")]) >>> print(result_string) bin boot dev etc home init lib lib64 lost+found media mnt opt proc projects root run sbin snap srv sys tmp usr var Arguments image Union[str, python_on_whales.Image] : The docker image to use for the container command List[str] : List of arguments to provide to the container. add_hosts List[Tuple[str, str]] : hosts to add in the format of a tuple. For example, add_hosts=[(\"my_host_1\", \"192.168.30.31\"), (\"host2\", \"192.168.80.81\")] blkio_weight Optional[int] : Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0) cpu_period Optional[int] : Limit CPU CFS (Completely Fair Scheduler) period cpu_quota Optional[int] : Limit CPU CFS (Completely Fair Scheduler) quota cpu_rt_period Optional[int] : Limit CPU real-time period in microseconds cpu_rt_runtime Optional[int] : Limit CPU real-time runtime in microseconds cpu_shares Optional[int] : CPU shares (relative weight) cpus Optional[float] : The maximal amount of cpu the container can use. 1 means one cpu core. cpuset_cpus Optional[List[int]] : CPUs in which to allow execution. Must be given as a list. cpuset_mems Optional[List[int]] : MEMs in which to allow execution. Must be given as a list. detach bool : If False , returns the ouput of the container as a string. If True , returns a python_on_whales.Container object. dns_search List[str] : Set custom DNS search domains domainname Optional[str] : Container NIS domain name entrypoint Optional[str] : Overwrite the default ENTRYPOINT of the image envs Dict[str, str] : Environment variables as a dict . For example: {\"OMP_NUM_THREADS\": 3} env_files Union[str, pathlib.Path, List[Union[str, pathlib.Path]]] : One or a list of env files. gpus Optional[Union[int, str]] : For this to work, you need the Nvidia container runtime The value needed is a str or int . Some examples of valid argument are \"all\" or \"device=GPU-3a23c669-1f69-c64e-cf85-44e9b07e7a2a\" or \"device=0,2\" . If you want 3 gpus, just write gpus=3 . hostname Optional[str] : Container host name interactive bool : Leave stdin open during the duration of the process to allow communication with the parent process. Currently only works with tty=True for interactive use on the terminal. ip Optional[str] : IPv4 address (e.g., 172.30.100.104) ip6 Optional[str] : IPv6 address (e.g., 2001:db8::33) ipc Optional[str] : IPC mode to use isolation Optional[str] : Container isolation technology kernel_memory Optional[Union[int, str]] : Kernel memory limit. int represents the number of bytes, but you can use \"4k\" or 2g for example. labels Dict[str, str] : Set meta data on a container. The labels can be used later when filtering containers with docker.ps(filters='...') . The labels can also be found on each container with the attribute my_container.config.labels . log_driver Optional[str] : Logging driver for the container mac_address Optional[str] : Container MAC address (e.g., \"92:d0:c6:0a:29:33\" ) memory Optional[Union[int, str]] : Memory limit, valid values are 1024 (ints are bytes) or \"43m\" or \"6g\" . memory_reservation Optional[Union[int, str]] : Memory soft limit memory_swap Optional[Union[int, str]] : Swap limit equal to memory plus swap: '-1' to enable unlimited swap. memory_swappiness Optional[int] : Tune container memory swappiness (0 to 100) (default -1) name Optional[str] : The container name. If not provided, one is automatically genrated for you. healthcheck bool : Set to False to disable container periodic healthcheck. oom_kill bool : Set to False to disable the OOM killer for this container. pid Optional[str] : PID namespace to use pids_limit Optional[int] : Tune container pids limit (set -1 for unlimited) platform Optional[str] : Set platform if server is multi-platform capable. privileged bool : Give extended privileges to this container. publish List[Union[Tuple[Union[str, int], Union[str, int]], Tuple[Union[str, int], Union[str, int], str]]] : Ports to publish, same as the -p argument in the Docker CLI. example are [(8000, 7000) , (\"127.0.0.1:3000\", 2000)] or [(\"127.0.0.1:3000\", 2000, \"udp\")] . You can also use a single entry in the tuple to signify that you want a random free port on the host. For example: publish=[(80,)] . publish_all bool : Publish all exposed ports to random ports. read_only bool : Mount the container's root filesystem as read only. restart Optional[str] : Restart policy to apply when a container exits (default \"no\") remove bool : Automatically remove the container when it exits. runtime Optional[str] : Runtime to use for this container. security_options List[str] : Security options shm_size Optional[Union[int, str]] : Size of /dev/shm. int is for bytes. But you can use \"512m\" or \"4g\" for example. stop_timeout Optional[int] : Signal to stop a container (default \"SIGTERM\") storage_options List[str] : Storage driver options for the container tty bool : Allocate a pseudo-TTY. Allow the process to access your terminal to write on it. user Optional[str] : Username or UID (format: <name|uid>[:<group|gid>] ) userns Optional[str] : User namespace to use uts Optional[str] : UTS namespace to use volumes Optional[List[Union[Tuple[Union[python_on_whales.Volume, str, pathlib.Path], Union[str, pathlib.Path]], Tuple[Union[python_on_whales.Volume, str, pathlib.Path], Union[str, pathlib.Path], str]]]] : Bind mount a volume. Some examples: [(\"/\", \"/host\"), (\"/etc/hosts\", \"/etc/hosts\", \"rw\")] . volume_driver Optional[str] : Optional volume driver for the container workdir Optional[Union[str, pathlib.Path]] : The directory in the container where the process will be executed. Returns The container output as a string if detach is False (the default), and a python_on_whales.Container if detach is True . start docker.container.start(containers, attach=False, stream=False) Starts one or more stopped containers. Aliases: docker.start , docker.container.start , python_on_whales.Container.start . Arguments containers Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or a list of containers. stats docker.container.stats(all=False) Get containers resource usage statistics Alias: docker.stats(...) Usage: from python_on_whales import docker docker.run(\"redis\", detach=True) print(docker.stats()) # [<<class 'python_on_whales.components.container.ContainerStats'> object, # attributes are block_read=0, block_write=0, cpu_percentage=0.08, # container=e90ae41a5b17, # container_id=e90ae41a5b17df998584141692f1e361c485e8d00c37ee21fdc360d3523dd1c1, # memory_percentage=0.18, memory_used=11198791, memory_limit=6233071288, # container_name=crazy_northcutt, net_upload=696, net_download=0>] The data unit is the byte. Arguments all bool : Get the stats of all containers, not just running ones. Returns A List[python_on_whales.ContainerStats] . stop docker.container.stop(containers, time=None) Stops one or more running containers Alias: docker.stop(...) Aliases: docker.stop , docker.container.stop , python_on_whales.Container.stop . Arguments containers Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or a list of containers. time Optional[Union[int, datetime.timedelta]] : Seconds to wait for stop before killing a container (default 10) Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. top docker.container.top() Get the running processes of a container Alias: docker.top(...) Not yet implemented unpause docker.container.unpause(x) Unpause all processes within one or more containers Alias: docker.unpause(...) Arguments x Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or more containers (name, id or python_on_whales.Container object). Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. update docker.container.update( x, blkio_weight=None, cpu_period=None, cpu_quota=None, cpu_rt_period=None, cpu_rt_runtime=None, cpu_shares=None, cpus=None, cpuset_cpus=None, cpuset_mems=None, kernel_memory=None, memory=None, memory_reservation=None, memory_swap=None, pids_limit=None, restart=None, ) Update configuration of one or more containers Alias: docker.update(...) Arguments x Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or a list of containers to update. blkio_weight Optional[int] : Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0) cpu_period Optional[int] : Limit CPU CFS (Completely Fair Scheduler) period cpu_quota Optional[int] : Limit CPU CFS (Completely Fair Scheduler) quota cpu_rt_period Optional[int] : Limit CPU real-time period in microseconds cpu_rt_runtime Optional[int] : Limit CPU real-time runtime in microseconds cpu_shares Optional[int] : CPU shares (relative weight) cpus Optional[float] : The maximal amount of cpu the container can use. 1 means one cpu core. cpuset_cpus Optional[List[int]] : CPUs in which to allow execution. Must be given as a list. cpuset_mems Optional[List[int]] : MEMs in which to allow execution. Must be given as a list. memory Optional[Union[int, str]] : Memory limit, valid values are 1024 (ints are bytes) or \"43m\" or \"6g\" . memory_reservation Optional[Union[int, str]] : Memory soft limit memory_swap Optional[Union[int, str]] : Swap limit equal to memory plus swap: '-1' to enable unlimited swap. pids_limit Optional[int] : Tune container pids limit (set -1 for unlimited) restart Optional[str] : Restart policy to apply when a container exits (default \"no\") Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. wait docker.container.wait(x) Block until one or more containers stop, then returns their exit codes Alias: docker.wait(...) Arguments x Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or a list of containers to wait for. Returns An int if a single container was passed as argument or a list of ints if multiple containers were passed as arguments. Some Examples: cont = docker.run(\"ubuntu\", [\"bash\", \"-c\", \"sleep 2 && exit 8\"], detach=True) exit_code = docker.wait(cont) print(exit_code) # 8 docker.container.remove(cont) cont_1 = docker.run(\"ubuntu\", [\"bash\", \"-c\", \"sleep 4 && exit 8\"], detach=True) cont_2 = docker.run(\"ubuntu\", [\"bash\", \"-c\", \"sleep 2 && exit 10\"], detach=True) exit_codes = docker.wait([cont_1, cont_2]) print(exit_codes) # [8, 10] docker.container.remove([cont_1, cont_2]) Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"docker container"},{"location":"sub-commands/container/#attach","text":"docker.container.attach() Not yet implemented","title":"attach"},{"location":"sub-commands/container/#commit","text":"docker.container.commit(container, tag=None, author=None, message=None, pause=True) Create a new image from a container's changes Arguments container Union[python_on_whales.Container, str] : The container to create the image from tag Optional[str] : tag to apply on the image produced author Optional[str] : Author (e.g., \"John Hannibal Smith hannibal@a-team.com \") message Optional[str] : Commit message pause bool : Pause container during commit","title":"commit"},{"location":"sub-commands/container/#copy","text":"docker.container.copy(source, destination) Copy files/folders between a container and the local filesystem Alias: docker.copy(...) from python_on_whales import docker docker.run(\"ubuntu\", [\"sleep\", \"infinity\"], name=\"dodo\", remove=True, detach=True) docker.copy(\"/tmp/my_local_file.txt\", (\"dodo\", \"/path/in/container.txt\")) docker.copy((\"dodo\", \"/path/in/container.txt\"), \"/tmp/my_local_file2.txt\") Doesn't yet support sending or receiving iterators of Python bytes. Arguments source Union[str, pathlib.Path, Tuple[Union[python_on_whales.Container, str], Union[str, pathlib.Path]]] : Local path or tuple. When using a tuple, the first element of the tuple is the container, the second element is the path in the container. ex: source=(\"my-container\", \"/usr/bin/something\") . destination Union[str, pathlib.Path, Tuple[Union[python_on_whales.Container, str], Union[str, pathlib.Path]]] : Local path or tuple. When using a tuple, the first element of the tuple is the container, the second element is the path in the container. ex: source=(\"my-container\", \"/usr/bin/something\") .","title":"copy"},{"location":"sub-commands/container/#create","text":"docker.container.create( image, command=[], *, add_hosts=[], blkio_weight=None, blkio_weight_device=[], cap_add=[], cap_drop=[], cgroup_parent=None, cidfile=None, cpu_period=None, cpu_quota=None, cpu_rt_period=None, cpu_rt_runtime=None, cpu_shares=None, cpus=None, cpuset_cpus=None, cpuset_mems=None, detach=False, devices=[], device_cgroup_rules=[], device_read_bps=[], device_read_iops=[], device_write_bps=[], device_write_iops=[], content_trust=False, dns=[], dns_options=[], dns_search=[], domainname=None, entrypoint=None, envs={}, env_files=[], expose=[], gpus=None, groups_add=[], healthcheck=True, health_cmd=None, health_interval=None, health_retries=None, health_start_period=None, health_timeout=None, hostname=None, init=False, ip=None, ip6=None, ipc=None, isolation=None, kernel_memory=None, labels={}, label_files=[], link=[], link_local_ip=[], log_driver=None, log_options=[], mac_address=None, memory=None, memory_reservation=None, memory_swap=None, memory_swappiness=None, mounts=[], name=None, networks=[], network_aliases=[], oom_kill=True, oom_score_adj=None, pid=None, pids_limit=None, platform=None, privileged=False, publish=[], publish_all=False, read_only=False, restart=None, remove=False, runtime=None, security_options=[], shm_size=None, sig_proxy=True, stop_signal=None, stop_timeout=None, storage_options=[], sysctl={}, tmpfs=[], ulimit=[], user=None, userns=None, uts=None, volumes=[], volume_driver=None, volumes_from=[], workdir=None ) Creates a container, but does not start it. Alias: docker.create(...) Start it then with the .start() method. It might be useful if you want to delay the start of a container, to do some preparations beforehand. For example, it's common to do this workflow: docker create -> docker cp -> docker start to put files in the container before starting. There is no detach argument since it's a runtime option. The arguments are the same as docker.run .","title":"create"},{"location":"sub-commands/container/#diff","text":"docker.container.diff(container) List all the files modified, added or deleted since the container started. Alias: docker.diff(...) Arguments container Union[python_on_whales.Container, str] : The container to inspect Returns Dict[str, str] Something like {\"/some_path\": \"A\", \"/some_file\": \"M\", \"/tmp\": \"D\"} for example.","title":"diff"},{"location":"sub-commands/container/#execute","text":"docker.container.execute( container, command, detach=False, envs={}, env_files=[], interactive=False, privileged=False, tty=False, user=None, workdir=None, stream=False, ) Execute a command inside a container Alias: docker.execute(...) Arguments container Union[python_on_whales.Container, str] : The container to execute the command in. command Union[str, List[str]] : The command to execute. detach bool : if True , returns immediately with None . If False , returns the command stdout as string. envs Dict[str, str] : Set environment variables env_files Union[str, pathlib.Path, List[Union[str, pathlib.Path]]] : Read one or more files of environment variables interactive bool : Leave stdin open during the duration of the process to allow communication with the parent process. Currently only works with tty=True for interactive use on the terminal. privileged bool : Give extended privileges to the container. tty bool : Allocate a pseudo-TTY. Allow the process to access your terminal to write on it. user Optional[str] : Username or UID, format: \"<name|uid>[:<group|gid>]\" workdir Optional[Union[str, pathlib.Path]] : Working directory inside the container stream bool : Similar to docker.run(..., stream=True) . Returns: Optional[str] Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"execute"},{"location":"sub-commands/container/#exists","text":"docker.container.exists(x) Returns True if the container exists. False otherwise. It's just calling docker.container.inspect(...) and verifies that it doesn't throw a python_on_whales.exceptions.NoSuchContainer . Returns A bool","title":"exists"},{"location":"sub-commands/container/#export","text":"docker.container.export(container, output) Export a container's filesystem as a tar archive Alias: docker.export(...) Arguments container Union[python_on_whales.Container, str] : The container to export. output Union[str, pathlib.Path] : The path of the output tar archive. Returning a generator of bytes is not yet implemented. Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"export"},{"location":"sub-commands/container/#inspect","text":"docker.container.inspect(x) Returns a container object from a name or ID. Arguments reference : A container name or ID, or a list of container names and/or IDs Returns: A python_on_whales.Container object or a list of those if a list of IDs was passed as input. Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"inspect"},{"location":"sub-commands/container/#kill","text":"docker.container.kill(containers, signal=None) Kill a container. Alias: docker.kill(...) Arguments containers Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or more containers to kill signal Optional[str] : The signal to send the container Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"kill"},{"location":"sub-commands/container/#list","text":"docker.container.list(all=False, filters={}) List the containers on the host. Alias: docker.ps(...) Arguments all bool : If True , also returns containers that are not running. Returns A List[python_on_whales.Container]","title":"list"},{"location":"sub-commands/container/#logs","text":"docker.container.logs( container, details=False, since=None, tail=None, timestamps=False, until=None, follow=False, stream=False ) Returns the logs of a container as a string or an iterator. Alias: docker.logs(...) Arguments container Union[python_on_whales.Container, str] : The container to get the logs of details bool : Show extra details provided to logs since Union[None, datetime.datetime, datetime.timedelta] : Use a datetime or timedelta to specify the lower date limit for the logs. tail Optional[int] : Number of lines to show from the end of the logs (default all) timestamps bool : Put timestamps next to lines. until Union[None, datetime.datetime, datetime.timedelta] : Use a datetime or a timedelta to specify the upper date limit for the logs. follow bool : If False (the default), the logs returned are the logs up to the time of the function call. If True , the logs of the container up to the time the container stopped are displayed. Which means that if the container isn't stopped yet, the function will continue until the container is stopped. Which is why it is advised to use the stream option if you use the follow option. Without stream , only a str will be returned, possibly much later in the future. With stream , you'll be able to read the logs in real time. stream bool : Similar to the stream argument of docker.run . This function will then returns and iterator that will yield a tuple (source, content) with source being \"stderr\" or \"stdout\" . content is the content of the line as bytes. Take a look at the user guide to have an example of the output. Returns str if stream=False (the default), Iterable[Tuple[str, bytes]] if stream=True . Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists. If you are a bit confused about follow and stream , here are some use cases. If you want to have the logs up to this point as a str , don't use those args. If you want to stream the output in real time, use follow=True, stream=True If you want the logs up to this point but you don't want to fit all the logs in memory because they are too big, use stream=True .","title":"logs"},{"location":"sub-commands/container/#pause","text":"docker.container.pause(containers) Pauses one or more containers Alias: docker.pause(...) Arguments containers Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or more containers to pause Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"pause"},{"location":"sub-commands/container/#prune","text":"docker.container.prune(filters=[]) Remove containers that are not running. Arguments filters Union[str, List[str]] : Filters as strings or list of strings","title":"prune"},{"location":"sub-commands/container/#remove","text":"docker.container.remove(containers, force=False, volumes=False) Removes a container Alias: docker.remove(...) Arguments containers Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or more containers. force bool : Force the removal of a running container (uses SIGKILL) volumes bool : Remove anonymous volumes associated with the container Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"remove"},{"location":"sub-commands/container/#rename","text":"docker.container.rename(container, new_name) Changes the name of a container. Alias: docker.rename(...) Arguments container Union[python_on_whales.Container, str] : The container to rename new_name str : The new name of the container. Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"rename"},{"location":"sub-commands/container/#restart","text":"docker.container.restart(containers, time=None) Restarts one or more container. Alias: docker.restart(...) Arguments containers Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or more containers to restart time Optional[Union[int, datetime.timedelta]] : Amount of to wait for stop before killing the container (default 10s). If int , the unit is seconds. Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"restart"},{"location":"sub-commands/container/#run","text":"docker.container.run( image, command=[], *, add_hosts=[], blkio_weight=None, blkio_weight_device=[], cap_add=[], cap_drop=[], cgroup_parent=None, cidfile=None, cpu_period=None, cpu_quota=None, cpu_rt_period=None, cpu_rt_runtime=None, cpu_shares=None, cpus=None, cpuset_cpus=None, cpuset_mems=None, detach=False, devices=[], device_cgroup_rules=[], device_read_bps=[], device_read_iops=[], device_write_bps=[], device_write_iops=[], content_trust=False, dns=[], dns_options=[], dns_search=[], domainname=None, entrypoint=None, envs={}, env_files=[], expose=[], gpus=None, groups_add=[], healthcheck=True, health_cmd=None, health_interval=None, health_retries=None, health_start_period=None, health_timeout=None, hostname=None, init=False, interactive=False, ip=None, ip6=None, ipc=None, isolation=None, kernel_memory=None, labels={}, label_files=[], link=[], link_local_ip=[], log_driver=None, log_options=[], mac_address=None, memory=None, memory_reservation=None, memory_swap=None, memory_swappiness=None, mounts=[], name=None, networks=[], network_aliases=[], oom_kill=True, oom_score_adj=None, pid=None, pids_limit=None, platform=None, privileged=False, publish=[], publish_all=False, read_only=False, restart=None, remove=False, runtime=None, security_options=[], shm_size=None, sig_proxy=True, stop_signal=None, stop_timeout=None, storage_options=[], stream=False, sysctl={}, tmpfs=[], tty=False, ulimit=[], user=None, userns=None, uts=None, volumes=[], volume_driver=None, volumes_from=[], workdir=None ) Runs a container You can use docker.run or docker.container.run to call this function. For a deeper dive into the arguments and what they do, visit https://docs.docker.com/engine/reference/run/ If you want to know exactly how to call docker.run() depending on your use case (detach, stream...), take a look at the docker.run() guide . >>> from python_on_whales import docker >>> returned_string = docker.run(\"hello-world\") >>> print(returned_string) Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ >>> from python_on_whales import docker >>> result_string = docker.run(\"ubuntu\", [\"ls\", \"/host\"], volumes=[(\"/\", \"/host\", \"ro\")]) >>> print(result_string) bin boot dev etc home init lib lib64 lost+found media mnt opt proc projects root run sbin snap srv sys tmp usr var Arguments image Union[str, python_on_whales.Image] : The docker image to use for the container command List[str] : List of arguments to provide to the container. add_hosts List[Tuple[str, str]] : hosts to add in the format of a tuple. For example, add_hosts=[(\"my_host_1\", \"192.168.30.31\"), (\"host2\", \"192.168.80.81\")] blkio_weight Optional[int] : Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0) cpu_period Optional[int] : Limit CPU CFS (Completely Fair Scheduler) period cpu_quota Optional[int] : Limit CPU CFS (Completely Fair Scheduler) quota cpu_rt_period Optional[int] : Limit CPU real-time period in microseconds cpu_rt_runtime Optional[int] : Limit CPU real-time runtime in microseconds cpu_shares Optional[int] : CPU shares (relative weight) cpus Optional[float] : The maximal amount of cpu the container can use. 1 means one cpu core. cpuset_cpus Optional[List[int]] : CPUs in which to allow execution. Must be given as a list. cpuset_mems Optional[List[int]] : MEMs in which to allow execution. Must be given as a list. detach bool : If False , returns the ouput of the container as a string. If True , returns a python_on_whales.Container object. dns_search List[str] : Set custom DNS search domains domainname Optional[str] : Container NIS domain name entrypoint Optional[str] : Overwrite the default ENTRYPOINT of the image envs Dict[str, str] : Environment variables as a dict . For example: {\"OMP_NUM_THREADS\": 3} env_files Union[str, pathlib.Path, List[Union[str, pathlib.Path]]] : One or a list of env files. gpus Optional[Union[int, str]] : For this to work, you need the Nvidia container runtime The value needed is a str or int . Some examples of valid argument are \"all\" or \"device=GPU-3a23c669-1f69-c64e-cf85-44e9b07e7a2a\" or \"device=0,2\" . If you want 3 gpus, just write gpus=3 . hostname Optional[str] : Container host name interactive bool : Leave stdin open during the duration of the process to allow communication with the parent process. Currently only works with tty=True for interactive use on the terminal. ip Optional[str] : IPv4 address (e.g., 172.30.100.104) ip6 Optional[str] : IPv6 address (e.g., 2001:db8::33) ipc Optional[str] : IPC mode to use isolation Optional[str] : Container isolation technology kernel_memory Optional[Union[int, str]] : Kernel memory limit. int represents the number of bytes, but you can use \"4k\" or 2g for example. labels Dict[str, str] : Set meta data on a container. The labels can be used later when filtering containers with docker.ps(filters='...') . The labels can also be found on each container with the attribute my_container.config.labels . log_driver Optional[str] : Logging driver for the container mac_address Optional[str] : Container MAC address (e.g., \"92:d0:c6:0a:29:33\" ) memory Optional[Union[int, str]] : Memory limit, valid values are 1024 (ints are bytes) or \"43m\" or \"6g\" . memory_reservation Optional[Union[int, str]] : Memory soft limit memory_swap Optional[Union[int, str]] : Swap limit equal to memory plus swap: '-1' to enable unlimited swap. memory_swappiness Optional[int] : Tune container memory swappiness (0 to 100) (default -1) name Optional[str] : The container name. If not provided, one is automatically genrated for you. healthcheck bool : Set to False to disable container periodic healthcheck. oom_kill bool : Set to False to disable the OOM killer for this container. pid Optional[str] : PID namespace to use pids_limit Optional[int] : Tune container pids limit (set -1 for unlimited) platform Optional[str] : Set platform if server is multi-platform capable. privileged bool : Give extended privileges to this container. publish List[Union[Tuple[Union[str, int], Union[str, int]], Tuple[Union[str, int], Union[str, int], str]]] : Ports to publish, same as the -p argument in the Docker CLI. example are [(8000, 7000) , (\"127.0.0.1:3000\", 2000)] or [(\"127.0.0.1:3000\", 2000, \"udp\")] . You can also use a single entry in the tuple to signify that you want a random free port on the host. For example: publish=[(80,)] . publish_all bool : Publish all exposed ports to random ports. read_only bool : Mount the container's root filesystem as read only. restart Optional[str] : Restart policy to apply when a container exits (default \"no\") remove bool : Automatically remove the container when it exits. runtime Optional[str] : Runtime to use for this container. security_options List[str] : Security options shm_size Optional[Union[int, str]] : Size of /dev/shm. int is for bytes. But you can use \"512m\" or \"4g\" for example. stop_timeout Optional[int] : Signal to stop a container (default \"SIGTERM\") storage_options List[str] : Storage driver options for the container tty bool : Allocate a pseudo-TTY. Allow the process to access your terminal to write on it. user Optional[str] : Username or UID (format: <name|uid>[:<group|gid>] ) userns Optional[str] : User namespace to use uts Optional[str] : UTS namespace to use volumes Optional[List[Union[Tuple[Union[python_on_whales.Volume, str, pathlib.Path], Union[str, pathlib.Path]], Tuple[Union[python_on_whales.Volume, str, pathlib.Path], Union[str, pathlib.Path], str]]]] : Bind mount a volume. Some examples: [(\"/\", \"/host\"), (\"/etc/hosts\", \"/etc/hosts\", \"rw\")] . volume_driver Optional[str] : Optional volume driver for the container workdir Optional[Union[str, pathlib.Path]] : The directory in the container where the process will be executed. Returns The container output as a string if detach is False (the default), and a python_on_whales.Container if detach is True .","title":"run"},{"location":"sub-commands/container/#start","text":"docker.container.start(containers, attach=False, stream=False) Starts one or more stopped containers. Aliases: docker.start , docker.container.start , python_on_whales.Container.start . Arguments containers Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or a list of containers.","title":"start"},{"location":"sub-commands/container/#stats","text":"docker.container.stats(all=False) Get containers resource usage statistics Alias: docker.stats(...) Usage: from python_on_whales import docker docker.run(\"redis\", detach=True) print(docker.stats()) # [<<class 'python_on_whales.components.container.ContainerStats'> object, # attributes are block_read=0, block_write=0, cpu_percentage=0.08, # container=e90ae41a5b17, # container_id=e90ae41a5b17df998584141692f1e361c485e8d00c37ee21fdc360d3523dd1c1, # memory_percentage=0.18, memory_used=11198791, memory_limit=6233071288, # container_name=crazy_northcutt, net_upload=696, net_download=0>] The data unit is the byte. Arguments all bool : Get the stats of all containers, not just running ones. Returns A List[python_on_whales.ContainerStats] .","title":"stats"},{"location":"sub-commands/container/#stop","text":"docker.container.stop(containers, time=None) Stops one or more running containers Alias: docker.stop(...) Aliases: docker.stop , docker.container.stop , python_on_whales.Container.stop . Arguments containers Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or a list of containers. time Optional[Union[int, datetime.timedelta]] : Seconds to wait for stop before killing a container (default 10) Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"stop"},{"location":"sub-commands/container/#top","text":"docker.container.top() Get the running processes of a container Alias: docker.top(...) Not yet implemented","title":"top"},{"location":"sub-commands/container/#unpause","text":"docker.container.unpause(x) Unpause all processes within one or more containers Alias: docker.unpause(...) Arguments x Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or more containers (name, id or python_on_whales.Container object). Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"unpause"},{"location":"sub-commands/container/#update","text":"docker.container.update( x, blkio_weight=None, cpu_period=None, cpu_quota=None, cpu_rt_period=None, cpu_rt_runtime=None, cpu_shares=None, cpus=None, cpuset_cpus=None, cpuset_mems=None, kernel_memory=None, memory=None, memory_reservation=None, memory_swap=None, pids_limit=None, restart=None, ) Update configuration of one or more containers Alias: docker.update(...) Arguments x Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or a list of containers to update. blkio_weight Optional[int] : Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0) cpu_period Optional[int] : Limit CPU CFS (Completely Fair Scheduler) period cpu_quota Optional[int] : Limit CPU CFS (Completely Fair Scheduler) quota cpu_rt_period Optional[int] : Limit CPU real-time period in microseconds cpu_rt_runtime Optional[int] : Limit CPU real-time runtime in microseconds cpu_shares Optional[int] : CPU shares (relative weight) cpus Optional[float] : The maximal amount of cpu the container can use. 1 means one cpu core. cpuset_cpus Optional[List[int]] : CPUs in which to allow execution. Must be given as a list. cpuset_mems Optional[List[int]] : MEMs in which to allow execution. Must be given as a list. memory Optional[Union[int, str]] : Memory limit, valid values are 1024 (ints are bytes) or \"43m\" or \"6g\" . memory_reservation Optional[Union[int, str]] : Memory soft limit memory_swap Optional[Union[int, str]] : Swap limit equal to memory plus swap: '-1' to enable unlimited swap. pids_limit Optional[int] : Tune container pids limit (set -1 for unlimited) restart Optional[str] : Restart policy to apply when a container exits (default \"no\") Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"update"},{"location":"sub-commands/container/#wait","text":"docker.container.wait(x) Block until one or more containers stop, then returns their exit codes Alias: docker.wait(...) Arguments x Union[python_on_whales.Container, str, List[Union[python_on_whales.Container, str]]] : One or a list of containers to wait for. Returns An int if a single container was passed as argument or a list of ints if multiple containers were passed as arguments. Some Examples: cont = docker.run(\"ubuntu\", [\"bash\", \"-c\", \"sleep 2 && exit 8\"], detach=True) exit_code = docker.wait(cont) print(exit_code) # 8 docker.container.remove(cont) cont_1 = docker.run(\"ubuntu\", [\"bash\", \"-c\", \"sleep 4 && exit 8\"], detach=True) cont_2 = docker.run(\"ubuntu\", [\"bash\", \"-c\", \"sleep 2 && exit 10\"], detach=True) exit_codes = docker.wait([cont_1, cont_2]) print(exit_codes) # [8, 10] docker.container.remove([cont_1, cont_2]) Raises python_on_whales.exceptions.NoSuchContainer if the container does not exists.","title":"wait"},{"location":"sub-commands/context/","text":"create docker.context.create() Not yet implemented inspect docker.context.inspect(x=None) Returns the context object. If no argument is provided, returns the current context. list docker.context.list() List all Docker contexts available Returns List[python_on_whales.Context] remove docker.context.remove(x, force=False) Removes one or more contexts Arguments x Union[python_on_whales.components.context.cli_wrapper.Context, str, List[Union[python_on_whales.components.context.cli_wrapper.Context, str]]] : One or more contexts force bool : Force the removal of this context update docker.context.update() Not yet implemented use docker.context.use(context) Set the default context Arguments context Union[python_on_whales.components.context.cli_wrapper.Context, str] : The context to set as default","title":"docker context"},{"location":"sub-commands/context/#create","text":"docker.context.create() Not yet implemented","title":"create"},{"location":"sub-commands/context/#inspect","text":"docker.context.inspect(x=None) Returns the context object. If no argument is provided, returns the current context.","title":"inspect"},{"location":"sub-commands/context/#list","text":"docker.context.list() List all Docker contexts available Returns List[python_on_whales.Context]","title":"list"},{"location":"sub-commands/context/#remove","text":"docker.context.remove(x, force=False) Removes one or more contexts Arguments x Union[python_on_whales.components.context.cli_wrapper.Context, str, List[Union[python_on_whales.components.context.cli_wrapper.Context, str]]] : One or more contexts force bool : Force the removal of this context","title":"remove"},{"location":"sub-commands/context/#update","text":"docker.context.update() Not yet implemented","title":"update"},{"location":"sub-commands/context/#use","text":"docker.context.use(context) Set the default context Arguments context Union[python_on_whales.components.context.cli_wrapper.Context, str] : The context to set as default","title":"use"},{"location":"sub-commands/image/","text":"copy_from docker.image.copy_from(image, path_in_image, destination) copy_to docker.image.copy_to(base_image, local_path, path_in_image, new_tag=None) exists docker.image.exists(x) Returns True if the image exists. False otherwise. It's just calling docker.image.inspect(...) and verifies that it doesn't throw a python_on_whales.exceptions.NoSuchImage . Returns A bool history docker.image.history() Not yet implemented import_ docker.image.import_(source, tag=None, changes=[], message=None, platform=None) Import the contents from a tarball to create a filesystem image Alias: docker.import_(...) Arguments changes List[str] : Apply Dockerfile instruction to the created image message Optional[str] : Set commit message for imported image platform Optional[str] : Set platform if server is multi-platform capable inspect docker.image.inspect(x) Creates a python_on_whales.Image object. Returns python_on_whales.Image , or List[python_on_whales.Image] if the input was a list of strings. Raises python_on_whales.exceptions.NoSuchImage if one of the images does not exists. list docker.image.list(filters={}) Returns the list of Docker images present on the machine. Alias: docker.images() Note that each image may have multiple tags. Returns A List[python_on_whales.Image] object. load docker.image.load(input, quiet=False) Loads one or multiple Docker image(s) from a tar or an iterator of bytes . Alias: docker.load(...) Arguments input Union[str, pathlib.Path, bytes, Iterator[bytes]] : Path or input stream to load the images from. quiet bool : If you don't want to display the progress bars. Returns None when using bytes as input. A List[str] (list of tags) when a path is provided. prune docker.image.prune(all=False, filter={}) Remove unused images Arguments all bool : Remove all unused images, not just dangling ones filter Dict[str, str] : Provide filter values (e.g. {\"until\": \"<timestamp>\"} ) pull docker.image.pull(x, quiet=False) Pull one or more docker image(s) Alias: docker.pull(...) Arguments x Union[str, List[str]] : The image name(s) . Can be a string or a list of strings. In case of list, multithreading is used to pull the images. The progress bars might look strange as multiple processes are drawing on the terminal at the same time. quiet bool : If you don't want to see the progress bars. Returns: The Docker image loaded ( python_on_whales.Image object). If a list was passed as input, then a List[python_on_whales.Image] will be returned. push docker.image.push(x, quiet=False) Push a tag or a repository to a registry Alias: docker.push(...) Arguments x Union[str, List[str]] : Tag(s) or repo(s) to push. Can be a string or a list of strings. If it's a list of string, python-on-whales will push all the images with multiple threads. The progress bars might look strange as multiple processes are drawing on the terminal at the same time. quiet bool : If you don't want to see the progress bars. Raises python_on_whales.exceptions.NoSuchImage if one of the images does not exists. remove docker.image.remove(x, force=False, prune=True) Remove one or more docker images. Arguments x Union[str, python_on_whales.Image, List[Union[str, python_on_whales.Image]]] : Single image or list of Docker images to remove. You can use tags or python_on_whales.Image objects. force bool : Force removal of the image prune bool : Delete untagged parents Raises python_on_whales.exceptions.NoSuchImage if one of the images does not exists. save docker.image.save(images, output=None) Save one or more images to a tar archive. Returns a stream if output is None Alias: docker.save(...) Arguments images Union[str, python_on_whales.Image, List[Union[str, python_on_whales.Image]]] : Single docker image or list of docker images to save output Optional[Union[str, pathlib.Path]] : Path of the tar archive to produce. If output is None, a generator of bytes is produced. It can be used to stream those bytes elsewhere, to another Docker daemon for example. Returns Optional[Iterator[bytes]] . If output is a path, nothing is returned. Raises python_on_whales.exceptions.NoSuchImage if one of the images does not exists. Example An example of transfer of an image from a local Docker daemon to a remote Docker daemon. We assume that the remote machine has an ssh access: from python_on_whales import DockerClient local_docker = DockerClient() remote_docker = DockerClient(host=\"ssh://my_user@186.167.32.84\") image_name = \"busybox:1\" local_docker.pull(image_name) bytes_iterator = local_docker.image.save(image_name) remote_docker.image.load(bytes_iterator) Of course the best solution is to use a registry to transfer image but it's a cool example nonetheless. tag docker.image.tag(source_image, new_tag) Adds a tag to a Docker image. Alias: docker.tag(...) Arguments source_image Union[python_on_whales.Image, str] : The Docker image to tag. You can use a tag to reference it. new_tag str : The tag to add to the Docker image. Raises python_on_whales.exceptions.NoSuchImage if the image does not exists.","title":"docker image"},{"location":"sub-commands/image/#copy_from","text":"docker.image.copy_from(image, path_in_image, destination)","title":"copy_from"},{"location":"sub-commands/image/#copy_to","text":"docker.image.copy_to(base_image, local_path, path_in_image, new_tag=None)","title":"copy_to"},{"location":"sub-commands/image/#exists","text":"docker.image.exists(x) Returns True if the image exists. False otherwise. It's just calling docker.image.inspect(...) and verifies that it doesn't throw a python_on_whales.exceptions.NoSuchImage . Returns A bool","title":"exists"},{"location":"sub-commands/image/#history","text":"docker.image.history() Not yet implemented","title":"history"},{"location":"sub-commands/image/#import_","text":"docker.image.import_(source, tag=None, changes=[], message=None, platform=None) Import the contents from a tarball to create a filesystem image Alias: docker.import_(...) Arguments changes List[str] : Apply Dockerfile instruction to the created image message Optional[str] : Set commit message for imported image platform Optional[str] : Set platform if server is multi-platform capable","title":"import_"},{"location":"sub-commands/image/#inspect","text":"docker.image.inspect(x) Creates a python_on_whales.Image object. Returns python_on_whales.Image , or List[python_on_whales.Image] if the input was a list of strings. Raises python_on_whales.exceptions.NoSuchImage if one of the images does not exists.","title":"inspect"},{"location":"sub-commands/image/#list","text":"docker.image.list(filters={}) Returns the list of Docker images present on the machine. Alias: docker.images() Note that each image may have multiple tags. Returns A List[python_on_whales.Image] object.","title":"list"},{"location":"sub-commands/image/#load","text":"docker.image.load(input, quiet=False) Loads one or multiple Docker image(s) from a tar or an iterator of bytes . Alias: docker.load(...) Arguments input Union[str, pathlib.Path, bytes, Iterator[bytes]] : Path or input stream to load the images from. quiet bool : If you don't want to display the progress bars. Returns None when using bytes as input. A List[str] (list of tags) when a path is provided.","title":"load"},{"location":"sub-commands/image/#prune","text":"docker.image.prune(all=False, filter={}) Remove unused images Arguments all bool : Remove all unused images, not just dangling ones filter Dict[str, str] : Provide filter values (e.g. {\"until\": \"<timestamp>\"} )","title":"prune"},{"location":"sub-commands/image/#pull","text":"docker.image.pull(x, quiet=False) Pull one or more docker image(s) Alias: docker.pull(...) Arguments x Union[str, List[str]] : The image name(s) . Can be a string or a list of strings. In case of list, multithreading is used to pull the images. The progress bars might look strange as multiple processes are drawing on the terminal at the same time. quiet bool : If you don't want to see the progress bars. Returns: The Docker image loaded ( python_on_whales.Image object). If a list was passed as input, then a List[python_on_whales.Image] will be returned.","title":"pull"},{"location":"sub-commands/image/#push","text":"docker.image.push(x, quiet=False) Push a tag or a repository to a registry Alias: docker.push(...) Arguments x Union[str, List[str]] : Tag(s) or repo(s) to push. Can be a string or a list of strings. If it's a list of string, python-on-whales will push all the images with multiple threads. The progress bars might look strange as multiple processes are drawing on the terminal at the same time. quiet bool : If you don't want to see the progress bars. Raises python_on_whales.exceptions.NoSuchImage if one of the images does not exists.","title":"push"},{"location":"sub-commands/image/#remove","text":"docker.image.remove(x, force=False, prune=True) Remove one or more docker images. Arguments x Union[str, python_on_whales.Image, List[Union[str, python_on_whales.Image]]] : Single image or list of Docker images to remove. You can use tags or python_on_whales.Image objects. force bool : Force removal of the image prune bool : Delete untagged parents Raises python_on_whales.exceptions.NoSuchImage if one of the images does not exists.","title":"remove"},{"location":"sub-commands/image/#save","text":"docker.image.save(images, output=None) Save one or more images to a tar archive. Returns a stream if output is None Alias: docker.save(...) Arguments images Union[str, python_on_whales.Image, List[Union[str, python_on_whales.Image]]] : Single docker image or list of docker images to save output Optional[Union[str, pathlib.Path]] : Path of the tar archive to produce. If output is None, a generator of bytes is produced. It can be used to stream those bytes elsewhere, to another Docker daemon for example. Returns Optional[Iterator[bytes]] . If output is a path, nothing is returned. Raises python_on_whales.exceptions.NoSuchImage if one of the images does not exists. Example An example of transfer of an image from a local Docker daemon to a remote Docker daemon. We assume that the remote machine has an ssh access: from python_on_whales import DockerClient local_docker = DockerClient() remote_docker = DockerClient(host=\"ssh://my_user@186.167.32.84\") image_name = \"busybox:1\" local_docker.pull(image_name) bytes_iterator = local_docker.image.save(image_name) remote_docker.image.load(bytes_iterator) Of course the best solution is to use a registry to transfer image but it's a cool example nonetheless.","title":"save"},{"location":"sub-commands/image/#tag","text":"docker.image.tag(source_image, new_tag) Adds a tag to a Docker image. Alias: docker.tag(...) Arguments source_image Union[python_on_whales.Image, str] : The Docker image to tag. You can use a tag to reference it. new_tag str : The tag to add to the Docker image. Raises python_on_whales.exceptions.NoSuchImage if the image does not exists.","title":"tag"},{"location":"sub-commands/manifest/","text":"annotate docker.manifest.annotate() Not yet implemented create docker.manifest.create() Not yet implemented inspect docker.manifest.inspect() Not yet implemented push docker.manifest.push() Not yet implemented","title":"docker manifest"},{"location":"sub-commands/manifest/#annotate","text":"docker.manifest.annotate() Not yet implemented","title":"annotate"},{"location":"sub-commands/manifest/#create","text":"docker.manifest.create() Not yet implemented","title":"create"},{"location":"sub-commands/manifest/#inspect","text":"docker.manifest.inspect() Not yet implemented","title":"inspect"},{"location":"sub-commands/manifest/#push","text":"docker.manifest.push() Not yet implemented","title":"push"},{"location":"sub-commands/network/","text":"connect docker.network.connect(network, container, alias=None, driver_options=[], ip=None, ip6=None, links=[]) create docker.network.create(name, attachable=False, driver=None, gateway=None, subnet=None, labels={}, options=[]) Creates a Docker network. Arguments name str : The name of the network Returns A python_on_whales.Network . disconnect docker.network.disconnect(network, container, force=False) inspect docker.network.inspect(x) list docker.network.list(filters={}) prune docker.network.prune(filters={}) remove docker.network.remove(networks) Removes a Docker network Arguments networks Union[python_on_whales.Network, str, List[Union[python_on_whales.Network, str]]] : One or more networks.","title":"docker network"},{"location":"sub-commands/network/#connect","text":"docker.network.connect(network, container, alias=None, driver_options=[], ip=None, ip6=None, links=[])","title":"connect"},{"location":"sub-commands/network/#create","text":"docker.network.create(name, attachable=False, driver=None, gateway=None, subnet=None, labels={}, options=[]) Creates a Docker network. Arguments name str : The name of the network Returns A python_on_whales.Network .","title":"create"},{"location":"sub-commands/network/#disconnect","text":"docker.network.disconnect(network, container, force=False)","title":"disconnect"},{"location":"sub-commands/network/#inspect","text":"docker.network.inspect(x)","title":"inspect"},{"location":"sub-commands/network/#list","text":"docker.network.list(filters={})","title":"list"},{"location":"sub-commands/network/#prune","text":"docker.network.prune(filters={})","title":"prune"},{"location":"sub-commands/network/#remove","text":"docker.network.remove(networks) Removes a Docker network Arguments networks Union[python_on_whales.Network, str, List[Union[python_on_whales.Network, str]]] : One or more networks.","title":"remove"},{"location":"sub-commands/node/","text":"demote docker.node.demote(x) Demote one or more nodes from manager in the swarm Arguments x Union[python_on_whales.Node, str, List[Union[python_on_whales.Node, str]]] : One or a list of nodes. inspect docker.node.inspect(x) Returns a python_on_whales.Node object from a string (id or hostname of the node) Arguments x Union[str, List[str]] : One id or hostname or a list of ids or hostnames Returns One or a list of python_on_whales.Node list docker.node.list() Returns the list of nodes in this swarm. Returns A List[python_on_whales.Node] promote docker.node.promote(x) Promote one or more nodes to manager in the swarm Arguments x Union[python_on_whales.Node, str, List[Union[python_on_whales.Node, str]]] : One or a list of nodes. ps docker.node.ps(x=[]) Returns the list of swarm tasks running on one or more nodes. from python_on_whales import docker tasks = docker.node.ps(\"my-node-name\") print(tasks[0].desired_state) # running Arguments x Union[python_on_whales.Node, str, List[Union[python_on_whales.Node, str]]] : One or more nodes (can be id, name or python_on_whales.Node object.). If the argument is not provided, it defaults to the current node. Returns List[python_on_whales.Task] remove docker.node.remove(x, force=False) Remove one or more nodes from the swarm Arguments x Union[python_on_whales.Node, str, List[Union[python_on_whales.Node, str]]] : One node or a list of nodes. You can use the id or the hostname of a node. You can also use a python_on_whales.Node . force bool : Force remove a node from the swarm update docker.node.update(node, availability=None, labels_add={}, rm_labels=[], role=None) Updates a Swarm node. Arguments node Union[python_on_whales.Node, str] : The node to update, you can use a string or a python_on_whales.Node object. availability Optional[str] : Availability of the node (\"active\"|\"pause\"|\"drain\") labels_add Dict[str, str] : Remove a node label if exists rm_labels List[str] : Labels to remove from the node. role Optional[str] : Role of the node (\"worker\"|\"manager\")","title":"docker node"},{"location":"sub-commands/node/#demote","text":"docker.node.demote(x) Demote one or more nodes from manager in the swarm Arguments x Union[python_on_whales.Node, str, List[Union[python_on_whales.Node, str]]] : One or a list of nodes.","title":"demote"},{"location":"sub-commands/node/#inspect","text":"docker.node.inspect(x) Returns a python_on_whales.Node object from a string (id or hostname of the node) Arguments x Union[str, List[str]] : One id or hostname or a list of ids or hostnames Returns One or a list of python_on_whales.Node","title":"inspect"},{"location":"sub-commands/node/#list","text":"docker.node.list() Returns the list of nodes in this swarm. Returns A List[python_on_whales.Node]","title":"list"},{"location":"sub-commands/node/#promote","text":"docker.node.promote(x) Promote one or more nodes to manager in the swarm Arguments x Union[python_on_whales.Node, str, List[Union[python_on_whales.Node, str]]] : One or a list of nodes.","title":"promote"},{"location":"sub-commands/node/#ps","text":"docker.node.ps(x=[]) Returns the list of swarm tasks running on one or more nodes. from python_on_whales import docker tasks = docker.node.ps(\"my-node-name\") print(tasks[0].desired_state) # running Arguments x Union[python_on_whales.Node, str, List[Union[python_on_whales.Node, str]]] : One or more nodes (can be id, name or python_on_whales.Node object.). If the argument is not provided, it defaults to the current node. Returns List[python_on_whales.Task]","title":"ps"},{"location":"sub-commands/node/#remove","text":"docker.node.remove(x, force=False) Remove one or more nodes from the swarm Arguments x Union[python_on_whales.Node, str, List[Union[python_on_whales.Node, str]]] : One node or a list of nodes. You can use the id or the hostname of a node. You can also use a python_on_whales.Node . force bool : Force remove a node from the swarm","title":"remove"},{"location":"sub-commands/node/#update","text":"docker.node.update(node, availability=None, labels_add={}, rm_labels=[], role=None) Updates a Swarm node. Arguments node Union[python_on_whales.Node, str] : The node to update, you can use a string or a python_on_whales.Node object. availability Optional[str] : Availability of the node (\"active\"|\"pause\"|\"drain\") labels_add Dict[str, str] : Remove a node label if exists rm_labels List[str] : Labels to remove from the node. role Optional[str] : Role of the node (\"worker\"|\"manager\")","title":"update"},{"location":"sub-commands/plugin/","text":"create docker.plugin.create(plugin_name, plugin_data_directory, compress=False) Create a plugin from a rootfs and configuration. Arguments plugin_name str : The name you want to give to your plugin plugin_data_directory Union[str, pathlib.Path] : Must contain config.json and rootfs directory. compress bool : Compress the context using gzip disable docker.plugin.disable(plugin, force=False) Disable a plugin Arguments plugin Union[python_on_whales.Plugin, str] : The plugin to disable force bool : Force the disable of an active plugin enable docker.plugin.enable(plugin, timeout=None) Enable a plugin Arguments plugin Union[python_on_whales.Plugin, str] : The plugin to enable timeout Optional[int] : HTTP client timeout (in seconds) (default 30) inspect docker.plugin.inspect(x) Returns a python_on_whales.Plugin object from a string (name or id of the plugin) Arguments x Union[str, List[str]] : One id or hostname or a list of name or ids Returns One or a list of python_on_whales.Plugin install docker.plugin.install(plugin_name, configuration={}, alias=None, disable=False, disable_content_trust=True) Installs a Docker plugin Warning: --grant-all-permissions is enabled, which means the program won't stop to ask you to grant the permissions. Arguments plugin_name str : The name of the plugin you want to install configuration Dict[str, str] : A dict adding configuration options to the plugin alias Optional[str] : Local name for plugin disable bool : Do not enable the plugin on install disable_content_trust bool : Skip image verification (default True ) Returns A python_on_whales.Plugin . list docker.plugin.list() Returns a List[python_on_whales.Plugin that are installed on the daemon. push docker.plugin.push(plugin, disable_content_trust=True) Push a plugin to a registry. Arguments plugin Union[python_on_whales.Plugin, str] : The plugin to push disable_content_trust bool : Skip image signing (default True ) remove docker.plugin.remove(x, force=False) Removes one or more plugins Arguments plugin : One or more plugins to remove. force bool : Force the removal of this plugin. set docker.plugin.set(plugin, configuration) Change the settings for a plugin Arguments plugin Union[python_on_whales.Plugin, str] : The plugin that needs its settings changed configuration Dict[str, str] : The new configuration options. upgrade docker.plugin.upgrade(plugin, remote=None, disable_content_trust=True, skip_remote_check=False) Upgrade a plugin Warning: --grant-all-permissions is enabled, which means the program won't stop to ask you to grant the permissions. Arguments plugin Union[python_on_whales.Plugin, str] : The plugin to upgrade remote Optional[str] : The remote to fetch the upgrade from disable_content_trust bool : Skip image verification (default True ) skip_remote_check bool : Do not check if specified remote plugin matches existing plugin image","title":"docker plugin"},{"location":"sub-commands/plugin/#create","text":"docker.plugin.create(plugin_name, plugin_data_directory, compress=False) Create a plugin from a rootfs and configuration. Arguments plugin_name str : The name you want to give to your plugin plugin_data_directory Union[str, pathlib.Path] : Must contain config.json and rootfs directory. compress bool : Compress the context using gzip","title":"create"},{"location":"sub-commands/plugin/#disable","text":"docker.plugin.disable(plugin, force=False) Disable a plugin Arguments plugin Union[python_on_whales.Plugin, str] : The plugin to disable force bool : Force the disable of an active plugin","title":"disable"},{"location":"sub-commands/plugin/#enable","text":"docker.plugin.enable(plugin, timeout=None) Enable a plugin Arguments plugin Union[python_on_whales.Plugin, str] : The plugin to enable timeout Optional[int] : HTTP client timeout (in seconds) (default 30)","title":"enable"},{"location":"sub-commands/plugin/#inspect","text":"docker.plugin.inspect(x) Returns a python_on_whales.Plugin object from a string (name or id of the plugin) Arguments x Union[str, List[str]] : One id or hostname or a list of name or ids Returns One or a list of python_on_whales.Plugin","title":"inspect"},{"location":"sub-commands/plugin/#install","text":"docker.plugin.install(plugin_name, configuration={}, alias=None, disable=False, disable_content_trust=True) Installs a Docker plugin Warning: --grant-all-permissions is enabled, which means the program won't stop to ask you to grant the permissions. Arguments plugin_name str : The name of the plugin you want to install configuration Dict[str, str] : A dict adding configuration options to the plugin alias Optional[str] : Local name for plugin disable bool : Do not enable the plugin on install disable_content_trust bool : Skip image verification (default True ) Returns A python_on_whales.Plugin .","title":"install"},{"location":"sub-commands/plugin/#list","text":"docker.plugin.list() Returns a List[python_on_whales.Plugin that are installed on the daemon.","title":"list"},{"location":"sub-commands/plugin/#push","text":"docker.plugin.push(plugin, disable_content_trust=True) Push a plugin to a registry. Arguments plugin Union[python_on_whales.Plugin, str] : The plugin to push disable_content_trust bool : Skip image signing (default True )","title":"push"},{"location":"sub-commands/plugin/#remove","text":"docker.plugin.remove(x, force=False) Removes one or more plugins Arguments plugin : One or more plugins to remove. force bool : Force the removal of this plugin.","title":"remove"},{"location":"sub-commands/plugin/#set","text":"docker.plugin.set(plugin, configuration) Change the settings for a plugin Arguments plugin Union[python_on_whales.Plugin, str] : The plugin that needs its settings changed configuration Dict[str, str] : The new configuration options.","title":"set"},{"location":"sub-commands/plugin/#upgrade","text":"docker.plugin.upgrade(plugin, remote=None, disable_content_trust=True, skip_remote_check=False) Upgrade a plugin Warning: --grant-all-permissions is enabled, which means the program won't stop to ask you to grant the permissions. Arguments plugin Union[python_on_whales.Plugin, str] : The plugin to upgrade remote Optional[str] : The remote to fetch the upgrade from disable_content_trust bool : Skip image verification (default True ) skip_remote_check bool : Do not check if specified remote plugin matches existing plugin image","title":"upgrade"},{"location":"sub-commands/secret/","text":"create docker.secret.create(name, file, driver=None, labels={}, template_driver=None) Creates a python_on_whales.Secret . Returns A python_on_whales.Secret object. inspect docker.secret.inspect(x) Returns one or more python_on_whales.Secret based on an ID or name. Arguments x Union[str, List[str]] : One or more IDs/names. list docker.secret.list(filters={}) Returns all secrets as a List[python_on_whales.Secret] . remove docker.secret.remove(x) Removes one or more secrets Arguments x Union[python_on_whales.Secret, str, List[Union[python_on_whales.Secret, str]]] : One or more secrets. Name, ids or python_on_whales.Secret objects are valid inputs.","title":"docker secret"},{"location":"sub-commands/secret/#create","text":"docker.secret.create(name, file, driver=None, labels={}, template_driver=None) Creates a python_on_whales.Secret . Returns A python_on_whales.Secret object.","title":"create"},{"location":"sub-commands/secret/#inspect","text":"docker.secret.inspect(x) Returns one or more python_on_whales.Secret based on an ID or name. Arguments x Union[str, List[str]] : One or more IDs/names.","title":"inspect"},{"location":"sub-commands/secret/#list","text":"docker.secret.list(filters={}) Returns all secrets as a List[python_on_whales.Secret] .","title":"list"},{"location":"sub-commands/secret/#remove","text":"docker.secret.remove(x) Removes one or more secrets Arguments x Union[python_on_whales.Secret, str, List[Union[python_on_whales.Secret, str]]] : One or more secrets. Name, ids or python_on_whales.Secret objects are valid inputs.","title":"remove"},{"location":"sub-commands/service/","text":"create docker.service.create( image, command, cap_add=[], cap_drop=[], constraints=[], detach=False, dns=[], dns_options=[], dns_search=[], endpoint_mode=None, entrypoint=None, envs={}, env_files=[], generic_resources=[], groups=[], healthcheck=True, health_cmd=None, health_interval=None, health_retries=None, health_start_period=None, health_timeout=None, hosts={}, hostname=None, init=False, isolation=None, labels={}, limit_cpu=None, limit_memory=None, limit_pids=None, log_driver=None, ) Creates a Docker swarm service. Consider using 'docker stack deploy' instead as it's idempotent and easier to read for complex applications. docker stack deploy is basically docker compose for swarm clusters. Arguments: image: The image to use as the base for the service. command: The command to execute in the container(s). exists docker.service.exists(x) Verify that a service exists. It's just calling docker.service.inspect(...) and verifies that it doesn't throw a python_on_whales.exceptions.NoSuchService . Returns A bool inspect docker.service.inspect(x) Returns one or a list of python_on_whales.Service object(s). Raises python_on_whales.exceptions.NoSuchService if one of the services doesn't exists. list docker.service.list() Returns the list of services Returns A List[python_on_whales.Services] logs docker.service.logs( service, details=False, since=None, tail=None, timestamps=False, follow=False, raw=False, task_ids=True, resolve=True, truncate=True, stream=False, ) Returns the logs of a service as a string or an iterator. Arguments service Union[str, python_on_whales.Service] : The service to get the logs of details bool : Show extra details provided to logs since Union[None, datetime.datetime, datetime.timedelta] : Use a datetime or timedelta to specify the lower date limit for the logs. tail Optional[int] : Number of lines to show from the end of the logs (default all) timestamps bool : Put timestamps next to lines. follow bool : If False (the default), the logs returned are the logs up to the time of the function call. If True , the logs of the container up to the time the service is stopped (removed) are displayed. Which is why you must use the stream option if you use the follow option. Without stream , only a str will be returned, possibly much later in the future (maybe never if the service is never removed). So this option is not possible (You'll get an error if you use follow and not stream). With stream , you'll be able to read the logs in real time and stop whenever you need. stream bool : Similar to the stream argument of docker.run() . This function will then returns and iterator that will yield a tuple (source, content) with source being \"stderr\" or \"stdout\" . content is the content of the line as bytes. Take a look at the user guide to have an example of the output. Returns str if stream=False (the default), Iterable[Tuple[str, bytes]] if stream=True . Raises python_on_whales.exceptions.NoSuchService if the service does not exists. ps docker.service.ps(x) Returns the list of swarm tasks associated with this service. You can pass multiple services at once at this function. from python_on_whales import docker tasks = docker.service.ps(\"my-service-name\") print(tasks[0].desired_state) # running Arguments x Union[str, python_on_whales.Service, List[Union[str, python_on_whales.Service]]] : One or more services (can be id, name or python_on_whales.Service object.) Returns List[python_on_whales.Task] Raises python_on_whales.exceptions.NoSuchService if one of the services doesn't exists. remove docker.service.remove(services) Removes a service Arguments services Union[str, python_on_whales.Service, List[Union[str, python_on_whales.Service]]] : One or a list of services to remove. Raises python_on_whales.exceptions.NoSuchService if one of the services doesn't exists. rollback docker.service.rollback() Not yet implemented scale docker.service.scale(new_scales, detach=False) Scale one or more services. Arguments new_scales Dict[Union[str, python_on_whales.Service], int] : Mapping between services and the desired scales. For example you can provide new_scale={\"service1\": 4, \"service2\": 8} detach bool : If True, does not wait for the services to converge and return immediately. Raises python_on_whales.exceptions.NoSuchService if one of the services doesn't exists. update docker.service.update(service, detach=False, force=False, image=None, with_registry_authentication=False) Update a service More options coming soon Arguments service Union[str, python_on_whales.Service] : The service to update detach bool : Exit immediately instead of waiting for the service to converge force bool : Force update even if no changes require it image Optional[str] : Service image tag with_registry_authentication bool : Send registry authentication details to swarm agents Raises python_on_whales.exceptions.NoSuchService if the service doesn't exists.","title":"docker service"},{"location":"sub-commands/service/#create","text":"docker.service.create( image, command, cap_add=[], cap_drop=[], constraints=[], detach=False, dns=[], dns_options=[], dns_search=[], endpoint_mode=None, entrypoint=None, envs={}, env_files=[], generic_resources=[], groups=[], healthcheck=True, health_cmd=None, health_interval=None, health_retries=None, health_start_period=None, health_timeout=None, hosts={}, hostname=None, init=False, isolation=None, labels={}, limit_cpu=None, limit_memory=None, limit_pids=None, log_driver=None, ) Creates a Docker swarm service. Consider using 'docker stack deploy' instead as it's idempotent and easier to read for complex applications. docker stack deploy is basically docker compose for swarm clusters. Arguments: image: The image to use as the base for the service. command: The command to execute in the container(s).","title":"create"},{"location":"sub-commands/service/#exists","text":"docker.service.exists(x) Verify that a service exists. It's just calling docker.service.inspect(...) and verifies that it doesn't throw a python_on_whales.exceptions.NoSuchService . Returns A bool","title":"exists"},{"location":"sub-commands/service/#inspect","text":"docker.service.inspect(x) Returns one or a list of python_on_whales.Service object(s). Raises python_on_whales.exceptions.NoSuchService if one of the services doesn't exists.","title":"inspect"},{"location":"sub-commands/service/#list","text":"docker.service.list() Returns the list of services Returns A List[python_on_whales.Services]","title":"list"},{"location":"sub-commands/service/#logs","text":"docker.service.logs( service, details=False, since=None, tail=None, timestamps=False, follow=False, raw=False, task_ids=True, resolve=True, truncate=True, stream=False, ) Returns the logs of a service as a string or an iterator. Arguments service Union[str, python_on_whales.Service] : The service to get the logs of details bool : Show extra details provided to logs since Union[None, datetime.datetime, datetime.timedelta] : Use a datetime or timedelta to specify the lower date limit for the logs. tail Optional[int] : Number of lines to show from the end of the logs (default all) timestamps bool : Put timestamps next to lines. follow bool : If False (the default), the logs returned are the logs up to the time of the function call. If True , the logs of the container up to the time the service is stopped (removed) are displayed. Which is why you must use the stream option if you use the follow option. Without stream , only a str will be returned, possibly much later in the future (maybe never if the service is never removed). So this option is not possible (You'll get an error if you use follow and not stream). With stream , you'll be able to read the logs in real time and stop whenever you need. stream bool : Similar to the stream argument of docker.run() . This function will then returns and iterator that will yield a tuple (source, content) with source being \"stderr\" or \"stdout\" . content is the content of the line as bytes. Take a look at the user guide to have an example of the output. Returns str if stream=False (the default), Iterable[Tuple[str, bytes]] if stream=True . Raises python_on_whales.exceptions.NoSuchService if the service does not exists.","title":"logs"},{"location":"sub-commands/service/#ps","text":"docker.service.ps(x) Returns the list of swarm tasks associated with this service. You can pass multiple services at once at this function. from python_on_whales import docker tasks = docker.service.ps(\"my-service-name\") print(tasks[0].desired_state) # running Arguments x Union[str, python_on_whales.Service, List[Union[str, python_on_whales.Service]]] : One or more services (can be id, name or python_on_whales.Service object.) Returns List[python_on_whales.Task] Raises python_on_whales.exceptions.NoSuchService if one of the services doesn't exists.","title":"ps"},{"location":"sub-commands/service/#remove","text":"docker.service.remove(services) Removes a service Arguments services Union[str, python_on_whales.Service, List[Union[str, python_on_whales.Service]]] : One or a list of services to remove. Raises python_on_whales.exceptions.NoSuchService if one of the services doesn't exists.","title":"remove"},{"location":"sub-commands/service/#rollback","text":"docker.service.rollback() Not yet implemented","title":"rollback"},{"location":"sub-commands/service/#scale","text":"docker.service.scale(new_scales, detach=False) Scale one or more services. Arguments new_scales Dict[Union[str, python_on_whales.Service], int] : Mapping between services and the desired scales. For example you can provide new_scale={\"service1\": 4, \"service2\": 8} detach bool : If True, does not wait for the services to converge and return immediately. Raises python_on_whales.exceptions.NoSuchService if one of the services doesn't exists.","title":"scale"},{"location":"sub-commands/service/#update","text":"docker.service.update(service, detach=False, force=False, image=None, with_registry_authentication=False) Update a service More options coming soon Arguments service Union[str, python_on_whales.Service] : The service to update detach bool : Exit immediately instead of waiting for the service to converge force bool : Force update even if no changes require it image Optional[str] : Service image tag with_registry_authentication bool : Send registry authentication details to swarm agents Raises python_on_whales.exceptions.NoSuchService if the service doesn't exists.","title":"update"},{"location":"sub-commands/stack/","text":"deploy docker.stack.deploy( name, compose_files=[], orchestrator=None, prune=False, resolve_image=\"always\", with_registry_auth=False, env_files=[], variables={}, ) Deploys a stack. Arguments name str : The name of the stack to deploy. Mandatory. compose_files Union[str, pathlib.Path, List[Union[str, pathlib.Path]]] : One or more docker-compose files. If there are more than one, they will be fused together. orchestrator Optional[str] : The orchestrator to use, `\"swarm\" or \"kubernetes\" or \"all\". prune bool : Prune services that are no longer referenced resolve_image str : Query the registry to resolve image digest and supported platforms \"always\"|\"changed\"|\"never\" (default \"always\" ). Note that if the registry cannot be queried when using \"always\" , it's going to try to use images present locally on the nodes. with_registry_auth bool : Send registry authentication details to Swarm agents. Required if you need to run docker login to pull the docker images in your stack. env_files List[Union[str, pathlib.Path]] : Similar to .env files in docker-compose. Loads variables from .env files. If both env_files and variables are used, variables have priority. This behavior is similar to the one you would experience with compose. variables Dict[str, str] : A dict dictating by what to replace the variables declared in the docker-compose files. In the docker CLI, you would use environment variables for this. Returns A python_on_whales.Stack object. list docker.stack.list() Returns a list of python_on_whales.Stack Returns A List[python_on_whales.Stack] . ps docker.stack.ps(x) Returns the list of swarm tasks in this stack. from python_on_whales import docker tasks = docker.stack.ps(\"my-stack\") print(tasks[0].desired_state) # running Arguments x Union[str, python_on_whales.Stack] : A stack . It can be name or a python_on_whales.Stack object. Returns List[python_on_whales.Task] remove docker.stack.remove(x) Removes one or more stacks. Arguments x Union[str, python_on_whales.Stack, List[Union[str, python_on_whales.Stack]]] : One or more stacks services docker.stack.services(stack) List the services present in the stack. Arguments stack Union[str, python_on_whales.Stack] : A docker stack or the name of a stack. Returns A List[python_on_whales.Stack]","title":"docker stack"},{"location":"sub-commands/stack/#deploy","text":"docker.stack.deploy( name, compose_files=[], orchestrator=None, prune=False, resolve_image=\"always\", with_registry_auth=False, env_files=[], variables={}, ) Deploys a stack. Arguments name str : The name of the stack to deploy. Mandatory. compose_files Union[str, pathlib.Path, List[Union[str, pathlib.Path]]] : One or more docker-compose files. If there are more than one, they will be fused together. orchestrator Optional[str] : The orchestrator to use, `\"swarm\" or \"kubernetes\" or \"all\". prune bool : Prune services that are no longer referenced resolve_image str : Query the registry to resolve image digest and supported platforms \"always\"|\"changed\"|\"never\" (default \"always\" ). Note that if the registry cannot be queried when using \"always\" , it's going to try to use images present locally on the nodes. with_registry_auth bool : Send registry authentication details to Swarm agents. Required if you need to run docker login to pull the docker images in your stack. env_files List[Union[str, pathlib.Path]] : Similar to .env files in docker-compose. Loads variables from .env files. If both env_files and variables are used, variables have priority. This behavior is similar to the one you would experience with compose. variables Dict[str, str] : A dict dictating by what to replace the variables declared in the docker-compose files. In the docker CLI, you would use environment variables for this. Returns A python_on_whales.Stack object.","title":"deploy"},{"location":"sub-commands/stack/#list","text":"docker.stack.list() Returns a list of python_on_whales.Stack Returns A List[python_on_whales.Stack] .","title":"list"},{"location":"sub-commands/stack/#ps","text":"docker.stack.ps(x) Returns the list of swarm tasks in this stack. from python_on_whales import docker tasks = docker.stack.ps(\"my-stack\") print(tasks[0].desired_state) # running Arguments x Union[str, python_on_whales.Stack] : A stack . It can be name or a python_on_whales.Stack object. Returns List[python_on_whales.Task]","title":"ps"},{"location":"sub-commands/stack/#remove","text":"docker.stack.remove(x) Removes one or more stacks. Arguments x Union[str, python_on_whales.Stack, List[Union[str, python_on_whales.Stack]]] : One or more stacks","title":"remove"},{"location":"sub-commands/stack/#services","text":"docker.stack.services(stack) List the services present in the stack. Arguments stack Union[str, python_on_whales.Stack] : A docker stack or the name of a stack. Returns A List[python_on_whales.Stack]","title":"services"},{"location":"sub-commands/swarm/","text":"ca docker.swarm.ca( ca_certificate=None, ca_key=None, certificate_expiry=None, detach=False, external_ca=None, rotate=False ) Get and rotate the root CA Arguments ca_certificate Optional[Union[str, pathlib.Path]] : Path to the PEM-formatted root CA certificate to use for the new cluster ca_key Optional[Union[str, pathlib.Path]] : Path to the PEM-formatted root CA key to use for the new cluster certificate_expiry Optional[Union[int, datetime.timedelta]] : Validity period for node certificates detach bool : Exit immediately instead of waiting for the root rotation to converge. The function will return None . external_ca Optional[str] : Specifications of one or more certificate signing endpoints rotate bool : Rotate the swarm CA - if no certificate or key are provided, new ones will be generated. init docker.swarm.init( advertise_address=None, autolock=False, availability=\"active\", data_path_address=None, data_path_port=None, listen_address=None, ) Initialize a Swarm. If you need the token to join the new swarm from another node, use the docker.swarm.join_token function. A example of how to initialize the whole swarm without leaving the manager if the manager has ssh access to the workers: from python_on_whales import docker, DockerClient worker_docker = DockerClient(host=\"ssh://worker_linux_user@worker_hostname\") # Here the docker variable is connected to the local daemon # worker_docker is a connected to the Docker daemon of the # worker through ssh, useful to control it without login to the machine # manually. docker.swarm.init() my_token = docker.swarm.join_token(\"worker\") # you can set manager too worker_docker.swarm.join(\"manager_hostname:2377\", token=my_token) Arguments advertise_address Optional[str] : Advertised address (format: <ip|interface>[:port] ) autolock bool : Enable manager autolocking (requiring an unlock key to start a stopped manager) availability str : Availability of the node (\"active\"|\"pause\"|\"drain\") data_path_address Optional[str] : Address or interface to use for data path traffic (format is <ip|interface> ) join docker.swarm.join( manager_address, advertise_address=None, availability=\"active\", data_path_address=None, listen_address=None, token=None, ) Joins a swarm Arguments manager_address str : The address of the swarm manager in the format \"{ip}:{port}\" advertise_address Optional[str] : Advertised address (format: [:port]) availability str : Availability of the node ( \"active\" | \"pause\" | \"drain\" ) data_path_address Optional[str] : Address or interface to use for data path traffic (format: ) listen-address : Listen address (format: [:port]) (default 0.0.0.0:2377) token Optional[str] : Token for entry into the swarm, will determine if the node enters the swarm as a manager or a worker. join_token docker.swarm.join_token(node_type, rotate=False) Obtains a token to join the swarm This token can then be used with docker.swarm.join(\"manager:2377\", token=my_token) . Arguments node_type str : \"manager\" or \"worker\" rotate bool : Rotate join token leave docker.swarm.leave(force=False) Leave the swarm Arguments force bool : Force this node to leave the swarm, ignoring warnings unlock docker.swarm.unlock(key) Unlock a swarm after the --autolock parameter was used and the daemon restarted. Arguments: key: The key to unlock the swarm. The key can be obtained on any manager with docker.swarm.unlock_key() . unlock_key docker.swarm.unlock_key(rotate=False) Gives you the key needed to unlock the swarm after a manager daemon reboot. Arguments rotate bool : Rotate the unlock key. update docker.swarm.update( autolock=None, cert_expiry=None, dispatcher_heartbeat=None, external_ca=None, max_snapshots=None, snapshot_interval=None, task_history_limit=None, ) Update the swarm configuration Arguments autolock Optional[bool] : Change manager autolocking setting cert_expiry Optional[datetime.timedelta] : Validity period for node certificates, default is datetime.timedelta(days=90) . If int , it's a number of seconds. dispatcher_heartbeat Optional[datetime.timedelta] : Dispatcher heartbeat period. external_ca Optional[str] : Specifications of one or more certificate signing endpoints max_snapshots Optional[int] : Number of additional Raft snapshots to retain snapshot_interval Optional[int] : Number of log entries between Raft snapshots (default 10000) task_history_limit Optional[int] : Task history retention limit (default 5)","title":"docker swarm"},{"location":"sub-commands/swarm/#ca","text":"docker.swarm.ca( ca_certificate=None, ca_key=None, certificate_expiry=None, detach=False, external_ca=None, rotate=False ) Get and rotate the root CA Arguments ca_certificate Optional[Union[str, pathlib.Path]] : Path to the PEM-formatted root CA certificate to use for the new cluster ca_key Optional[Union[str, pathlib.Path]] : Path to the PEM-formatted root CA key to use for the new cluster certificate_expiry Optional[Union[int, datetime.timedelta]] : Validity period for node certificates detach bool : Exit immediately instead of waiting for the root rotation to converge. The function will return None . external_ca Optional[str] : Specifications of one or more certificate signing endpoints rotate bool : Rotate the swarm CA - if no certificate or key are provided, new ones will be generated.","title":"ca"},{"location":"sub-commands/swarm/#init","text":"docker.swarm.init( advertise_address=None, autolock=False, availability=\"active\", data_path_address=None, data_path_port=None, listen_address=None, ) Initialize a Swarm. If you need the token to join the new swarm from another node, use the docker.swarm.join_token function. A example of how to initialize the whole swarm without leaving the manager if the manager has ssh access to the workers: from python_on_whales import docker, DockerClient worker_docker = DockerClient(host=\"ssh://worker_linux_user@worker_hostname\") # Here the docker variable is connected to the local daemon # worker_docker is a connected to the Docker daemon of the # worker through ssh, useful to control it without login to the machine # manually. docker.swarm.init() my_token = docker.swarm.join_token(\"worker\") # you can set manager too worker_docker.swarm.join(\"manager_hostname:2377\", token=my_token) Arguments advertise_address Optional[str] : Advertised address (format: <ip|interface>[:port] ) autolock bool : Enable manager autolocking (requiring an unlock key to start a stopped manager) availability str : Availability of the node (\"active\"|\"pause\"|\"drain\") data_path_address Optional[str] : Address or interface to use for data path traffic (format is <ip|interface> )","title":"init"},{"location":"sub-commands/swarm/#join","text":"docker.swarm.join( manager_address, advertise_address=None, availability=\"active\", data_path_address=None, listen_address=None, token=None, ) Joins a swarm Arguments manager_address str : The address of the swarm manager in the format \"{ip}:{port}\" advertise_address Optional[str] : Advertised address (format: [:port]) availability str : Availability of the node ( \"active\" | \"pause\" | \"drain\" ) data_path_address Optional[str] : Address or interface to use for data path traffic (format: ) listen-address : Listen address (format: [:port]) (default 0.0.0.0:2377) token Optional[str] : Token for entry into the swarm, will determine if the node enters the swarm as a manager or a worker.","title":"join"},{"location":"sub-commands/swarm/#join_token","text":"docker.swarm.join_token(node_type, rotate=False) Obtains a token to join the swarm This token can then be used with docker.swarm.join(\"manager:2377\", token=my_token) . Arguments node_type str : \"manager\" or \"worker\" rotate bool : Rotate join token","title":"join_token"},{"location":"sub-commands/swarm/#leave","text":"docker.swarm.leave(force=False) Leave the swarm Arguments force bool : Force this node to leave the swarm, ignoring warnings","title":"leave"},{"location":"sub-commands/swarm/#unlock","text":"docker.swarm.unlock(key) Unlock a swarm after the --autolock parameter was used and the daemon restarted. Arguments: key: The key to unlock the swarm. The key can be obtained on any manager with docker.swarm.unlock_key() .","title":"unlock"},{"location":"sub-commands/swarm/#unlock_key","text":"docker.swarm.unlock_key(rotate=False) Gives you the key needed to unlock the swarm after a manager daemon reboot. Arguments rotate bool : Rotate the unlock key.","title":"unlock_key"},{"location":"sub-commands/swarm/#update","text":"docker.swarm.update( autolock=None, cert_expiry=None, dispatcher_heartbeat=None, external_ca=None, max_snapshots=None, snapshot_interval=None, task_history_limit=None, ) Update the swarm configuration Arguments autolock Optional[bool] : Change manager autolocking setting cert_expiry Optional[datetime.timedelta] : Validity period for node certificates, default is datetime.timedelta(days=90) . If int , it's a number of seconds. dispatcher_heartbeat Optional[datetime.timedelta] : Dispatcher heartbeat period. external_ca Optional[str] : Specifications of one or more certificate signing endpoints max_snapshots Optional[int] : Number of additional Raft snapshots to retain snapshot_interval Optional[int] : Number of log entries between Raft snapshots (default 10000) task_history_limit Optional[int] : Task history retention limit (default 5)","title":"update"},{"location":"sub-commands/system/","text":"disk_free docker.system.disk_free() Give information about the disk usage of the Docker daemon. Returns a python_on_whales.DiskFreeResult object. from python_on_whales import docker disk_free_result = docker.system.disk_free() print(disk_free_result.images.active) #int print(disk_free_result.containers.reclaimable) # int, number of bytes print(disk_free_result.volumes.reclaimable_percent) # float print(disk_free_result.build_cache.total_count) # int print(disk_free_result.build_cache.size) # int, number of bytes ... Note that the number are not 100% accurate because the docker CLI doesn't provide the exact numbers. Maybe in a future implementation, we can provide exact numbers. Verbose mode is not yet implemented. events docker.system.events() Not yet implemented info docker.system.info() Returns diverse information about the Docker client and daemon. Returns A python_on_whales.SystemInfo object As an example from python_on_whales import docker info = docker.system.info() print(info.images) # 40 print(info.plugins.volume) # [\"local\"} ... You can find all attributes available by looking up the reference page for system info . prune docker.system.prune(all=False, volumes=False, filters={}) Remove unused docker data Arguments all bool : Remove all unused images not just dangling ones volumes bool : Prune volumes filters Dict[str, str] : See the Docker documentation page about filtering . For example, filters=dict(until=\"24h\") .","title":"docker system"},{"location":"sub-commands/system/#disk_free","text":"docker.system.disk_free() Give information about the disk usage of the Docker daemon. Returns a python_on_whales.DiskFreeResult object. from python_on_whales import docker disk_free_result = docker.system.disk_free() print(disk_free_result.images.active) #int print(disk_free_result.containers.reclaimable) # int, number of bytes print(disk_free_result.volumes.reclaimable_percent) # float print(disk_free_result.build_cache.total_count) # int print(disk_free_result.build_cache.size) # int, number of bytes ... Note that the number are not 100% accurate because the docker CLI doesn't provide the exact numbers. Maybe in a future implementation, we can provide exact numbers. Verbose mode is not yet implemented.","title":"disk_free"},{"location":"sub-commands/system/#events","text":"docker.system.events() Not yet implemented","title":"events"},{"location":"sub-commands/system/#info","text":"docker.system.info() Returns diverse information about the Docker client and daemon. Returns A python_on_whales.SystemInfo object As an example from python_on_whales import docker info = docker.system.info() print(info.images) # 40 print(info.plugins.volume) # [\"local\"} ... You can find all attributes available by looking up the reference page for system info .","title":"info"},{"location":"sub-commands/system/#prune","text":"docker.system.prune(all=False, volumes=False, filters={}) Remove unused docker data Arguments all bool : Remove all unused images not just dangling ones volumes bool : Prune volumes filters Dict[str, str] : See the Docker documentation page about filtering . For example, filters=dict(until=\"24h\") .","title":"prune"},{"location":"sub-commands/task/","text":"inspect docker.task.inspect(x) Returns a python_on_whales.Task object from its ID. list docker.task.list() Returns all tasks in the swarm Returns List[python_on_whales.Task] logs docker.task.logs() Not Yet implemented","title":"docker task"},{"location":"sub-commands/task/#inspect","text":"docker.task.inspect(x) Returns a python_on_whales.Task object from its ID.","title":"inspect"},{"location":"sub-commands/task/#list","text":"docker.task.list() Returns all tasks in the swarm Returns List[python_on_whales.Task]","title":"list"},{"location":"sub-commands/task/#logs","text":"docker.task.logs() Not Yet implemented","title":"logs"},{"location":"sub-commands/trust/","text":"inspect docker.trust.inspect() Not yet implemented revoke docker.trust.revoke() Not yet implemented sign docker.trust.sign() Not yet implemented","title":"docker trust"},{"location":"sub-commands/trust/#inspect","text":"docker.trust.inspect() Not yet implemented","title":"inspect"},{"location":"sub-commands/trust/#revoke","text":"docker.trust.revoke() Not yet implemented","title":"revoke"},{"location":"sub-commands/trust/#sign","text":"docker.trust.sign() Not yet implemented","title":"sign"},{"location":"sub-commands/volume/","text":"clone docker.volume.clone(source, new_volume_name=None, driver=None, labels={}, options={}) Clone a volume. Arguments source Union[python_on_whales.Volume, str] : The volume to clone new_volume_name Optional[str] : The new volume name. If not given, a random name is chosen. driver Optional[str] : Specify volume driver name (default \"local\") labels Dict[str, str] : Set metadata for a volume options Dict[str, str] : Set driver specific options Returns A python_on_whales.Volume , the new volume. copy docker.volume.copy(source, destination) Copy files/folders between a volume and the local filesystem. Arguments source Union[str, pathlib.Path, Tuple[Union[python_on_whales.Volume, str], Union[str, pathlib.Path]]] : If source is a directory/file inside a Docker volume, a tuple (my_volume, path_in_volume) must be provided. The volume can be a python_on_whales.Volume or a volume name as str . The path can be a pathlib.Path or a str . If source is a local directory, a pathlib.Path or str should be provided. End the source path with /. if you want to copy the directory content in another directory. destination Union[str, pathlib.Path, Tuple[Union[python_on_whales.Volume, str], Union[str, pathlib.Path]]] : Same as source . create docker.volume.create(volume_name=None, driver=None, labels={}, options={}) Creates a volume Arguments volume_name Optional[str] : The volume name, if not provided, a long random string will be used instead. driver Optional[str] : Specify volume driver name (default \"local\") labels Dict[str, str] : Set metadata for a volume options Dict[str, str] : Set driver specific options exists docker.volume.exists(x) Returns True if the volume exists. False otherwise. It's just calling docker.volume.inspect(...) and verifies that it doesn't throw a python_on_whales.exceptions.NoSuchVolume . Returns A bool inspect docker.volume.inspect(x) list docker.volume.list(filters={}) List volumes Arguments filters Dict[str, Union[str, int]] : See the Docker documentation page about filtering . An example filters=dict(dangling=1, driver=\"local\") . Returns List[python_on_whales.Volume] prune docker.volume.prune(filters={}) Remove volumes Arguments filters Dict[str, Union[str, int]] : See the Docker documentation page about filtering . An example filters=dict(dangling=1, driver=\"local\") . remove docker.volume.remove(x) Removes one or more volumes Arguments x Union[python_on_whales.Volume, str, List[Union[python_on_whales.Volume, str]]] : A volume or a list of volumes.","title":"docker volume"},{"location":"sub-commands/volume/#clone","text":"docker.volume.clone(source, new_volume_name=None, driver=None, labels={}, options={}) Clone a volume. Arguments source Union[python_on_whales.Volume, str] : The volume to clone new_volume_name Optional[str] : The new volume name. If not given, a random name is chosen. driver Optional[str] : Specify volume driver name (default \"local\") labels Dict[str, str] : Set metadata for a volume options Dict[str, str] : Set driver specific options Returns A python_on_whales.Volume , the new volume.","title":"clone"},{"location":"sub-commands/volume/#copy","text":"docker.volume.copy(source, destination) Copy files/folders between a volume and the local filesystem. Arguments source Union[str, pathlib.Path, Tuple[Union[python_on_whales.Volume, str], Union[str, pathlib.Path]]] : If source is a directory/file inside a Docker volume, a tuple (my_volume, path_in_volume) must be provided. The volume can be a python_on_whales.Volume or a volume name as str . The path can be a pathlib.Path or a str . If source is a local directory, a pathlib.Path or str should be provided. End the source path with /. if you want to copy the directory content in another directory. destination Union[str, pathlib.Path, Tuple[Union[python_on_whales.Volume, str], Union[str, pathlib.Path]]] : Same as source .","title":"copy"},{"location":"sub-commands/volume/#create","text":"docker.volume.create(volume_name=None, driver=None, labels={}, options={}) Creates a volume Arguments volume_name Optional[str] : The volume name, if not provided, a long random string will be used instead. driver Optional[str] : Specify volume driver name (default \"local\") labels Dict[str, str] : Set metadata for a volume options Dict[str, str] : Set driver specific options","title":"create"},{"location":"sub-commands/volume/#exists","text":"docker.volume.exists(x) Returns True if the volume exists. False otherwise. It's just calling docker.volume.inspect(...) and verifies that it doesn't throw a python_on_whales.exceptions.NoSuchVolume . Returns A bool","title":"exists"},{"location":"sub-commands/volume/#inspect","text":"docker.volume.inspect(x)","title":"inspect"},{"location":"sub-commands/volume/#list","text":"docker.volume.list(filters={}) List volumes Arguments filters Dict[str, Union[str, int]] : See the Docker documentation page about filtering . An example filters=dict(dangling=1, driver=\"local\") . Returns List[python_on_whales.Volume]","title":"list"},{"location":"sub-commands/volume/#prune","text":"docker.volume.prune(filters={}) Remove volumes Arguments filters Dict[str, Union[str, int]] : See the Docker documentation page about filtering . An example filters=dict(dangling=1, driver=\"local\") .","title":"prune"},{"location":"sub-commands/volume/#remove","text":"docker.volume.remove(x) Removes one or more volumes Arguments x Union[python_on_whales.Volume, str, List[Union[python_on_whales.Volume, str]]] : A volume or a list of volumes.","title":"remove"},{"location":"user_guide/docker_run/","text":"The different ways of using docker.run() Simple call from python_on_whales import docker stdout_as_str = docker.run(\"hello-world\") print(stdout_as_str) # Hello from Docker! # This message shows that your installation appears to be working correctly. # ... This is the simplest way. The function docker.run(...) returns only when the container is done and the output (stdout) is returned all at once in a single string. This is very practical for simple use cases, but not so much when you have a container that needs to run for a very long time for example, as you don't get the output in real time. Detach the container from python_on_whales import docker from redis import Redis redis_container = docker.run(\"redis\", detach=True, publish=[(6379, 6379)]) # the container is up and listening on port 6379 redis_client = Redis() redis_client.set(\"hello\", \"world\") print(redis_client.get(\"hello\")) # b'world' This is a very simple way to start a container in the background. It will continue running until the process inside exits. It's useful when running servers for example, because they should never stop. Detach with the context manager from python_on_whales import docker from redis import Redis with docker.run(\"redis\", detach=True, publish=[(6379, 6379)]) as redis_container: # the container is up and listening on port 6379 redis_client = Redis() redis_client.set(\"hello\", \"world\") print(redis_client.get(\"hello\")) # b'world' print(\"The container is now stopped and removed because we're outside the context manager\") print(redis_container.state.running) # will raise an error with the message \"no such container\" Using the context manager is quite useful when you need the container running in the background but you need to know exactly for how long it will live. For example in unit tests, you might need a redis server to execute a function. You can then have the redis container running only during this specific unit test. This is also better than calling manually redis_container.remove() . Why? For the same reason it's better to do with open(...) as f: than f = open(...) . If an exception occurs in the context manager block, the container is still removed. Stream the output from python_on_whales import docker output_generator = docker.run(\"busybox\", [\"ping\", \"-c\", \"50\", \"www.google.com\"], stream=True, name=\"box\") for stream_type, stream_content in output_generator: print(f\"Stream type: {stream_type}, stream content: {stream_content}\") # Stream type: stdout, stream content: b'PING www.google.com (142.250.74.228): 56 data bytes\\n' # Stream type: stdout, stream content: b'64 bytes from 142.250.74.228: seq=0 ttl=119 time=18.350 ms\\n' # Stream type: stdout, stream content: b'64 bytes from 142.250.74.228: seq=1 ttl=119 time=18.386 ms\\n' # ... # Stream type: stdout, stream content: b'64 bytes from 142.250.74.228: seq=48 ttl=119 time=18.494 ms\\n' # Stream type: stdout, stream content: b'64 bytes from 142.250.74.228: seq=49 ttl=119 time=18.260 ms\\n' # Stream type: stdout, stream content: b'\\n' # Stream type: stdout, stream content: b'--- www.google.com ping statistics ---\\n' # Stream type: stdout, stream content: b'50 packets transmitted, 50 packets received, 0% packet loss\\n' # Stream type: stdout, stream content: b'round-trip min/avg/max = 17.547/18.075/18.508 ms\\n' # when the generator is done and we're out of the loop # it means the container has finished running. print(docker.container.inspect(\"box\").state.running) # False This is very useful for long running processes. For example if you need the output of a container that will stay up for a very long time.","title":"docker.run() guide"},{"location":"user_guide/docker_run/#the-different-ways-of-using-dockerrun","text":"","title":"The different ways of using docker.run()"},{"location":"user_guide/docker_run/#simple-call","text":"from python_on_whales import docker stdout_as_str = docker.run(\"hello-world\") print(stdout_as_str) # Hello from Docker! # This message shows that your installation appears to be working correctly. # ... This is the simplest way. The function docker.run(...) returns only when the container is done and the output (stdout) is returned all at once in a single string. This is very practical for simple use cases, but not so much when you have a container that needs to run for a very long time for example, as you don't get the output in real time.","title":"Simple call"},{"location":"user_guide/docker_run/#detach-the-container","text":"from python_on_whales import docker from redis import Redis redis_container = docker.run(\"redis\", detach=True, publish=[(6379, 6379)]) # the container is up and listening on port 6379 redis_client = Redis() redis_client.set(\"hello\", \"world\") print(redis_client.get(\"hello\")) # b'world' This is a very simple way to start a container in the background. It will continue running until the process inside exits. It's useful when running servers for example, because they should never stop.","title":"Detach the container"},{"location":"user_guide/docker_run/#detach-with-the-context-manager","text":"from python_on_whales import docker from redis import Redis with docker.run(\"redis\", detach=True, publish=[(6379, 6379)]) as redis_container: # the container is up and listening on port 6379 redis_client = Redis() redis_client.set(\"hello\", \"world\") print(redis_client.get(\"hello\")) # b'world' print(\"The container is now stopped and removed because we're outside the context manager\") print(redis_container.state.running) # will raise an error with the message \"no such container\" Using the context manager is quite useful when you need the container running in the background but you need to know exactly for how long it will live. For example in unit tests, you might need a redis server to execute a function. You can then have the redis container running only during this specific unit test. This is also better than calling manually redis_container.remove() . Why? For the same reason it's better to do with open(...) as f: than f = open(...) . If an exception occurs in the context manager block, the container is still removed.","title":"Detach with the context manager"},{"location":"user_guide/docker_run/#stream-the-output","text":"from python_on_whales import docker output_generator = docker.run(\"busybox\", [\"ping\", \"-c\", \"50\", \"www.google.com\"], stream=True, name=\"box\") for stream_type, stream_content in output_generator: print(f\"Stream type: {stream_type}, stream content: {stream_content}\") # Stream type: stdout, stream content: b'PING www.google.com (142.250.74.228): 56 data bytes\\n' # Stream type: stdout, stream content: b'64 bytes from 142.250.74.228: seq=0 ttl=119 time=18.350 ms\\n' # Stream type: stdout, stream content: b'64 bytes from 142.250.74.228: seq=1 ttl=119 time=18.386 ms\\n' # ... # Stream type: stdout, stream content: b'64 bytes from 142.250.74.228: seq=48 ttl=119 time=18.494 ms\\n' # Stream type: stdout, stream content: b'64 bytes from 142.250.74.228: seq=49 ttl=119 time=18.260 ms\\n' # Stream type: stdout, stream content: b'\\n' # Stream type: stdout, stream content: b'--- www.google.com ping statistics ---\\n' # Stream type: stdout, stream content: b'50 packets transmitted, 50 packets received, 0% packet loss\\n' # Stream type: stdout, stream content: b'round-trip min/avg/max = 17.547/18.075/18.508 ms\\n' # when the generator is done and we're out of the loop # it means the container has finished running. print(docker.container.inspect(\"box\").state.running) # False This is very useful for long running processes. For example if you need the output of a container that will stay up for a very long time.","title":"Stream the output"},{"location":"user_guide/generic_resources/","text":"Docker Swarm generic resources There are two kind of generic resources, discreet and named. Both are declared in /etc/docker/daemon.json and both are accessible in your containers as environment variables. Named resources Named resources should be used when you have a small number of things you want accessed. The best example is gpu devices. Each gpu has a UUID, which can be the name of this resources. Actually you could also use an index, and this index would have to be the \"name\" of the gpu. Since we want to show they're generic, let's take something else than GPUs for this example. Let's say you have 5 hamsters connected to your node, making an app run: They are named Robert, Lucie, Annie, James and Stacy. You'll define one service that needs one hamster and one that needs three. We'll call them my_light_service and my_heavy_service . Let's declare the hamsters in the /etc/docker/daemon.json . If this file doesn't exist on your system, you can create it. Mine looks like this, note that you don't need the insecure registries part: { \"insecure-registries\": [\"127.0.0.1:5000\"], \"node-generic-resources\": [ \"hamster=Robert\", \"hamster=Lucie\", \"hamster=Annie\", \"hamster=James\", \"hamster=Stacy\" ] } Restart your Docker daemon with sudo service docker restart . Then create a Docker swarm: docker swarm init The hamster are declared, up and ready to go! You can check they're here with docker node ls and docker node inspect . Creating services with the CLI It's time to create services and hit those hamsters! First we'll create the services with the CLI and then with the command line. $ docker service create --generic-resource \"hamster=1\" --name my_light_service ubuntu bash -c \"env && sleep infinity\" $ docker service create --generic-resource \"hamster=3\" --name my_heavy_service ubuntu bash -c \"env && sleep infinity\" We have one replica for the light and heavy service. They use 4 hamster. Let's try to use moooooooore! $ docker service scale -d my_light_service=10 my_heavy_service=10 $ docker service ls ID NAME MODE REPLICAS IMAGE PORTS tt436bxjtdn7 my_heavy_service replicated 1/10 ubuntu:latest ksiq5x0bxch1 my_light_service replicated 2/10 ubuntu:latest Remember, we only have 5 hamsters, and 3 are needed for the heavy service and one for the light service. Hence here 2 * 1 + 1 * 3 = 5 ! This is what we wanted. So how does each container knows which hamster to use? We asked each container to print the environment variables and sleep for infinity env && sleep infinity . Let's take a look with docker logs : $ docker ps CONTAINER ID IMAGE COMMAND NAMES 1e8932f5a985 ubuntu:latest \"bash -c 'env && sle\u2026\" my_light_service.4.shys2wwxz7jjfjg2g2e0xl1sw 0a5c4ddd303a ubuntu:latest \"bash -c 'env && sle\u2026\" my_heavy_service.1.p39satddgf6j1uhspdiohcyzh e2872006cc97 ubuntu:latest \"bash -c 'env && sle\u2026\" my_light_service.1.bbo0fbi5d5e2zdwozgbse8x57 $ docker logs my_light_service.4.shys2wwxz7jjfjg2g2e0xl1sw DOCKER_RESOURCE_HAMSTER=Stacy HOSTNAME=1e8932f5a985 $ docker logs my_heavy_service.1.p39satddgf6j1uhspdiohcyzh DOCKER_RESOURCE_HAMSTER=Lucie,Annie,James HOSTNAME=0a5c4ddd303a $ docker logs my_light_service.1.bbo0fbi5d5e2zdwozgbse8x57 DOCKER_RESOURCE_HAMSTER=Robert HOSTNAME=e2872006cc97 So we can see that each container is aware of it's hamster with an environment variable. The process running in the container can grab it and then use the correct hamster without making two containers use the same hamster. Using hamsters with Docker stack Here is a docker-compose.yml that will declare the services exactly like we did in the CLI: version: \"3.8\" services: my_light_service: command: - bash - -c - env && sleep infinity image: ubuntu deploy: replicas: 10 resources: reservations: generic_resources: - discrete_resource_spec: kind: 'hamster' value: 1 my_heavy_service: command: - bash - -c - env && sleep infinity image: ubuntu deploy: replicas: 10 resources: reservations: generic_resources: - discrete_resource_spec: kind: 'hamster' value: 3 $ docker stack deploy -c docker-compose.yml my_stack_using_hamsters Creating network my_stack_using_hamsters_default Creating service my_stack_using_hamsters_my_heavy_service Creating service my_stack_using_hamsters_my_light_service $ docker service ls ID NAME MODE REPLICAS IMAGE nlhwfnz0d1cx my_stack_using_hamsters_my_heavy_service replicated 1/10 ubuntu:latest c77tv3czzfw2 my_stack_using_hamsters_my_light_service replicated 2/10 ubuntu:latest How does that fit with Nvidia GPUs? Well, if you remember, the Nvidia runtime uses environment variables in the container to know which gpu to use. By modifying the /etc/nvidia-container-runtime/config.toml , and setting swarm-resource = \"DOCKER_RESOURCE_GPU\" , it indicates the nvidia-docker runtime that it should watch for this environment variable when deciding which gpu to use. Make the nvidia-docker runtime the default one for this node, replace hamster by gpu and you're good to go as long as you used UUID as your hamster's names. A more in depth guide can be found here . Discreet resources TODO (just put \"node-generic-resources\": [\"hamster=100\"] in the daemon.json, there are too many hamsters to give them names).","title":"Swarm generic resources"},{"location":"user_guide/generic_resources/#docker-swarm-generic-resources","text":"There are two kind of generic resources, discreet and named. Both are declared in /etc/docker/daemon.json and both are accessible in your containers as environment variables.","title":"Docker Swarm generic resources"},{"location":"user_guide/generic_resources/#named-resources","text":"Named resources should be used when you have a small number of things you want accessed. The best example is gpu devices. Each gpu has a UUID, which can be the name of this resources. Actually you could also use an index, and this index would have to be the \"name\" of the gpu. Since we want to show they're generic, let's take something else than GPUs for this example. Let's say you have 5 hamsters connected to your node, making an app run: They are named Robert, Lucie, Annie, James and Stacy. You'll define one service that needs one hamster and one that needs three. We'll call them my_light_service and my_heavy_service . Let's declare the hamsters in the /etc/docker/daemon.json . If this file doesn't exist on your system, you can create it. Mine looks like this, note that you don't need the insecure registries part: { \"insecure-registries\": [\"127.0.0.1:5000\"], \"node-generic-resources\": [ \"hamster=Robert\", \"hamster=Lucie\", \"hamster=Annie\", \"hamster=James\", \"hamster=Stacy\" ] } Restart your Docker daemon with sudo service docker restart . Then create a Docker swarm: docker swarm init The hamster are declared, up and ready to go! You can check they're here with docker node ls and docker node inspect .","title":"Named resources"},{"location":"user_guide/generic_resources/#creating-services-with-the-cli","text":"It's time to create services and hit those hamsters! First we'll create the services with the CLI and then with the command line. $ docker service create --generic-resource \"hamster=1\" --name my_light_service ubuntu bash -c \"env && sleep infinity\" $ docker service create --generic-resource \"hamster=3\" --name my_heavy_service ubuntu bash -c \"env && sleep infinity\" We have one replica for the light and heavy service. They use 4 hamster. Let's try to use moooooooore! $ docker service scale -d my_light_service=10 my_heavy_service=10 $ docker service ls ID NAME MODE REPLICAS IMAGE PORTS tt436bxjtdn7 my_heavy_service replicated 1/10 ubuntu:latest ksiq5x0bxch1 my_light_service replicated 2/10 ubuntu:latest Remember, we only have 5 hamsters, and 3 are needed for the heavy service and one for the light service. Hence here 2 * 1 + 1 * 3 = 5 ! This is what we wanted. So how does each container knows which hamster to use? We asked each container to print the environment variables and sleep for infinity env && sleep infinity . Let's take a look with docker logs : $ docker ps CONTAINER ID IMAGE COMMAND NAMES 1e8932f5a985 ubuntu:latest \"bash -c 'env && sle\u2026\" my_light_service.4.shys2wwxz7jjfjg2g2e0xl1sw 0a5c4ddd303a ubuntu:latest \"bash -c 'env && sle\u2026\" my_heavy_service.1.p39satddgf6j1uhspdiohcyzh e2872006cc97 ubuntu:latest \"bash -c 'env && sle\u2026\" my_light_service.1.bbo0fbi5d5e2zdwozgbse8x57 $ docker logs my_light_service.4.shys2wwxz7jjfjg2g2e0xl1sw DOCKER_RESOURCE_HAMSTER=Stacy HOSTNAME=1e8932f5a985 $ docker logs my_heavy_service.1.p39satddgf6j1uhspdiohcyzh DOCKER_RESOURCE_HAMSTER=Lucie,Annie,James HOSTNAME=0a5c4ddd303a $ docker logs my_light_service.1.bbo0fbi5d5e2zdwozgbse8x57 DOCKER_RESOURCE_HAMSTER=Robert HOSTNAME=e2872006cc97 So we can see that each container is aware of it's hamster with an environment variable. The process running in the container can grab it and then use the correct hamster without making two containers use the same hamster.","title":"Creating services with the CLI"},{"location":"user_guide/generic_resources/#using-hamsters-with-docker-stack","text":"Here is a docker-compose.yml that will declare the services exactly like we did in the CLI: version: \"3.8\" services: my_light_service: command: - bash - -c - env && sleep infinity image: ubuntu deploy: replicas: 10 resources: reservations: generic_resources: - discrete_resource_spec: kind: 'hamster' value: 1 my_heavy_service: command: - bash - -c - env && sleep infinity image: ubuntu deploy: replicas: 10 resources: reservations: generic_resources: - discrete_resource_spec: kind: 'hamster' value: 3 $ docker stack deploy -c docker-compose.yml my_stack_using_hamsters Creating network my_stack_using_hamsters_default Creating service my_stack_using_hamsters_my_heavy_service Creating service my_stack_using_hamsters_my_light_service $ docker service ls ID NAME MODE REPLICAS IMAGE nlhwfnz0d1cx my_stack_using_hamsters_my_heavy_service replicated 1/10 ubuntu:latest c77tv3czzfw2 my_stack_using_hamsters_my_light_service replicated 2/10 ubuntu:latest","title":"Using hamsters with Docker stack"},{"location":"user_guide/generic_resources/#how-does-that-fit-with-nvidia-gpus","text":"Well, if you remember, the Nvidia runtime uses environment variables in the container to know which gpu to use. By modifying the /etc/nvidia-container-runtime/config.toml , and setting swarm-resource = \"DOCKER_RESOURCE_GPU\" , it indicates the nvidia-docker runtime that it should watch for this environment variable when deciding which gpu to use. Make the nvidia-docker runtime the default one for this node, replace hamster by gpu and you're good to go as long as you used UUID as your hamster's names. A more in depth guide can be found here .","title":"How does that fit with Nvidia GPUs?"},{"location":"user_guide/generic_resources/#discreet-resources","text":"TODO (just put \"node-generic-resources\": [\"hamster=100\"] in the daemon.json, there are too many hamsters to give them names).","title":"Discreet resources"},{"location":"user_guide/running_python_on_whales_inside_a_container/","text":"Running python-on-whales inside a container To follow this example, you just need Docker installed, and nothing else! The use case Sometimes you don't want to install Python on your system, but you still would like to use python-on-whales to handle most of the Docker logic. You can then run python-on-whales inside a Docker container. For simplicity, we let the container access the Docker daemon of the host. Let's give you the code example, and we'll explain afterwards where is the magic. Example We want to run this small Python script. It uses python-on-whales. We'll call it main.py # main.py from python_on_whales import docker print(\"We are going to run the hello world docker container\") output = docker.run(\"hello-world\") print(\"Here is the output:\") print(output) print(f\"buildx version: {docker.buildx.version()}\") print(f\"compose version: {docker.compose.version()}\") Next to this main.py , make a Dockerfile . # Dockerfile FROM python:3.9 RUN pip install python-on-whales RUN python-on-whales download-cli # install docker buildx, this step is optional RUN mkdir -p ~/.docker/cli-plugins/ RUN wget https://github.com/docker/buildx/releases/download/v0.6.3/buildx-v0.6.3.linux-amd64 -O ~/.docker/cli-plugins/docker-buildx RUN chmod a+x ~/.docker/cli-plugins/docker-buildx # install docker compose, this step is optional RUN mkdir -p ~/.docker/cli-plugins/ RUN wget https://github.com/docker/compose/releases/download/v2.0.1/docker-compose-linux-x86_64 -O ~/.docker/cli-plugins/docker-compose RUN chmod a+x ~/.docker/cli-plugins/docker-compose COPY ./main.py /main.py CMD python /main.py We're all set! Let's run this Python script, without having Python installed on the system! docker build -t image-with-python-on-whales . docker run -v /var/run/docker.sock:/var/run/docker.sock image-with-python-on-whales You should see this output: We are going to run the hello world docker container Here is the output: Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ buildx version: github.com/docker/buildx v0.6.3 266c0eac611d64fcc0c72d80206aa364e826758d compose version: Docker Compose version v2.0.0-rc.2 How does it work? The main magic here is the sharing of the docker socket between the host and the container. This is done with the -v /var/run/docker.sock:/var/run/docker.sock . With this option, the container can have access to the docker API. But it still needs the binary client in Go. Download it in the dockerfile with python-no-whales download-cli . You can then optionally install buildx and compose. Then you're good to go! Simple as that.","title":"Running python-on-whales inside a container"},{"location":"user_guide/running_python_on_whales_inside_a_container/#running-python-on-whales-inside-a-container","text":"To follow this example, you just need Docker installed, and nothing else!","title":"Running python-on-whales inside a container"},{"location":"user_guide/running_python_on_whales_inside_a_container/#the-use-case","text":"Sometimes you don't want to install Python on your system, but you still would like to use python-on-whales to handle most of the Docker logic. You can then run python-on-whales inside a Docker container. For simplicity, we let the container access the Docker daemon of the host. Let's give you the code example, and we'll explain afterwards where is the magic.","title":"The use case"},{"location":"user_guide/running_python_on_whales_inside_a_container/#example","text":"We want to run this small Python script. It uses python-on-whales. We'll call it main.py # main.py from python_on_whales import docker print(\"We are going to run the hello world docker container\") output = docker.run(\"hello-world\") print(\"Here is the output:\") print(output) print(f\"buildx version: {docker.buildx.version()}\") print(f\"compose version: {docker.compose.version()}\") Next to this main.py , make a Dockerfile . # Dockerfile FROM python:3.9 RUN pip install python-on-whales RUN python-on-whales download-cli # install docker buildx, this step is optional RUN mkdir -p ~/.docker/cli-plugins/ RUN wget https://github.com/docker/buildx/releases/download/v0.6.3/buildx-v0.6.3.linux-amd64 -O ~/.docker/cli-plugins/docker-buildx RUN chmod a+x ~/.docker/cli-plugins/docker-buildx # install docker compose, this step is optional RUN mkdir -p ~/.docker/cli-plugins/ RUN wget https://github.com/docker/compose/releases/download/v2.0.1/docker-compose-linux-x86_64 -O ~/.docker/cli-plugins/docker-compose RUN chmod a+x ~/.docker/cli-plugins/docker-compose COPY ./main.py /main.py CMD python /main.py We're all set! Let's run this Python script, without having Python installed on the system! docker build -t image-with-python-on-whales . docker run -v /var/run/docker.sock:/var/run/docker.sock image-with-python-on-whales You should see this output: We are going to run the hello world docker container Here is the output: Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ buildx version: github.com/docker/buildx v0.6.3 266c0eac611d64fcc0c72d80206aa364e826758d compose version: Docker Compose version v2.0.0-rc.2","title":"Example"},{"location":"user_guide/running_python_on_whales_inside_a_container/#how-does-it-work","text":"The main magic here is the sharing of the docker socket between the host and the container. This is done with the -v /var/run/docker.sock:/var/run/docker.sock . With this option, the container can have access to the docker API. But it still needs the binary client in Go. Download it in the dockerfile with python-no-whales download-cli . You can then optionally install buildx and compose. Then you're good to go! Simple as that.","title":"How does it work?"}]}